['predator_0', 'predator_1', 'predator_2', 'predator_3', 'predator_4', 'prey_0', 'prey_1', 'prey_2', 'prey_3', 'prey_4']
åˆ›å»ºçš„policies: ['predator_0', 'predator_1', 'predator_2', 'predator_3', 'predator_4', 'prey_0', 'prey_1', 'prey_2', 'prey_3', 'prey_4']
åˆ›å»ºçš„RL module specs: ['predator_0', 'predator_1', 'predator_2', 'predator_3', 'predator_4', 'prey_0', 'prey_1', 'prey_2', 'prey_3', 'prey_4']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
å¼€å§‹è®­ç»ƒ...
2025-07-15 14:40:38,687	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-15 14:40:39,275	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-15 14:40:39 (running for 00:00:00.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-15_14-40-38_089884_3017836/artifacts/2025-07-15_14-40-39/PPO_2025-07-15_14-40-39/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_3d3c0_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=3019785)[0m 2025-07-15 14:40:41,344	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
