{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7fdac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from ray.tune.result import TRAINING_ITERATION\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib.core import (\n",
    "    COMPONENT_LEARNER,\n",
    "    COMPONENT_LEARNER_GROUP,\n",
    "    COMPONENT_RL_MODULE,\n",
    ")\n",
    "from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "from ray.rllib.examples.envs.classes.multi_agent import MultiAgentPendulum\n",
    "from ray.rllib.utils.metrics import (\n",
    "    ENV_RUNNER_RESULTS,\n",
    "    EPISODE_RETURN_MEAN,\n",
    "    NUM_ENV_STEPS_SAMPLED_LIFETIME,\n",
    ")\n",
    "from ray.rllib.utils.numpy import convert_to_numpy\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    check,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "\n",
    "from pettingzoo.sisl import waterworld_v4\n",
    "\n",
    "from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "from ray.rllib.core.rl_module.multi_rl_module import MultiRLModuleSpec\n",
    "from ray.rllib.core.rl_module.rl_module import RLModuleSpec\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tree  # pip install dm_tree\n",
    "\n",
    "from ray.rllib.core import DEFAULT_MODULE_ID\n",
    "from ray.rllib.core.columns import Columns\n",
    "from ray.rllib.core.rl_module.rl_module import RLModule\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.numpy import convert_to_numpy, softmax\n",
    "from ray.rllib.utils.metrics import (\n",
    "    ENV_RUNNER_RESULTS,\n",
    "    EPISODE_RETURN_MEAN,\n",
    ")\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1b97d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数设置完成\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = [\n",
    "    'notebook_script.py',\n",
    "    '--enable-new-api-stack',\n",
    "    '--num-agents=2',\n",
    "    # '--no-tune',\n",
    "    '--checkpoint-at-end',\n",
    "    '--stop-reward=200.0',\n",
    "\n",
    "]\n",
    "print(\"参数设置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad4773d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数解析完成: num_agents=2, algo=PPO\n"
     ]
    }
   ],
   "source": [
    "parser = add_rllib_example_script_args(\n",
    "    default_iters=2,\n",
    "    default_timesteps=10000,\n",
    "    default_reward=0.0,\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "assert args.num_agents > 0, \"Must set --num-agents > 0 when running this script!\"\n",
    "assert (\n",
    "    args.enable_new_api_stack\n",
    "), \"Must set --enable-new-api-stack when running this script!\"\n",
    "\n",
    "print(f\"参数解析完成: num_agents={args.num_agents}, algo={args.algo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fbdc5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 15:13:23,307\tINFO worker.py:1917 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-24 15:13:23 (running for 00:00:00.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-24_15-13-22_768088_547330/artifacts/2025-06-24_15-13-23/PPO_2025-06-24_15-13-23/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=552889)\u001b[0m 2025-06-24 15:13:25,316\tWARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(MultiAgentEnvRunner pid=552974)\u001b[0m 2025-06-24 15:13:27,049\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=552889)\u001b[0m Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-24 15:13:28 (running for 00:00:05.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-24_15-13-22_768088_547330/artifacts/2025-06-24_15-13-23/PPO_2025-06-24_15-13-23/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>env_runner_group                               </th><th>env_runners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </th><th>fault_tolerance                                            </th><th>learners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </th><th style=\"text-align: right;\">  num_env_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_training_step_calls_per_iteration</th><th>perf                                                                                                   </th><th>timers                                                                                                                                                                                                                                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_env_55877_00000</td><td>{&#x27;actor_manager_num_outstanding_async_reqs&#x27;: 0}</td><td>{&#x27;module_to_env_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;remove_single_ts_time_rank_from_batch&#x27;: np.float64(9.8477529672102e-07), &#x27;tensor_to_numpy&#x27;: np.float64(3.1459986354376984e-05), &#x27;un_batch_to_individual_items&#x27;: np.float64(1.3426101270532106e-05), &#x27;normalize_and_clip_actions&#x27;: np.float64(3.524928129802899e-05), &#x27;module_to_agent_unmapping&#x27;: np.float64(2.6854698092063245e-06), &#x27;listify_data_for_vector_env&#x27;: np.float64(5.991409915151327e-06), &#x27;get_actions&#x27;: np.float64(8.183217608720008e-05)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.00022520500802222047)}, &#x27;num_env_steps_sampled&#x27;: 4000.0, &#x27;episode_return_min&#x27;: -309.4820964435785, &#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;numpy_to_tensor&#x27;: np.float64(4.1812993003986776e-05), &#x27;add_states_from_episodes_to_batch&#x27;: np.float64(4.945002729073167e-06), &#x27;add_observations_from_episodes_to_batch&#x27;: np.float64(2.724550722632557e-05), &#x27;batch_individual_items&#x27;: np.float64(2.2136999177746475e-05), &#x27;agent_to_module_mapping&#x27;: np.float64(4.642497515305877e-06), &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: np.float64(1.3065495295450091e-05)}}, &#x27;env_to_module_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;numpy_to_tensor&#x27;: np.float64(2.2342237183981633e-05), &#x27;add_states_from_episodes_to_batch&#x27;: np.float64(4.032387564088161e-06), &#x27;batch_individual_items&#x27;: np.float64(1.2592065599674422e-05), &#x27;add_observations_from_episodes_to_batch&#x27;: np.float64(1.5832307610279334e-05), &#x27;agent_to_module_mapping&#x27;: np.float64(3.2720770236916246e-06), &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: np.float64(6.898764856134054e-06)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.00010648422869347633)}, &#x27;num_agent_steps_sampled&#x27;: {&#x27;pursuer_0&#x27;: 2000.0, &#x27;pursuer_1&#x27;: 2004.0}, &#x27;episode_len_mean&#x27;: 1000.0, &#x27;num_episodes&#x27;: 4.0, &#x27;episode_len_max&#x27;: 1000, &#x27;num_module_steps_sampled&#x27;: {&#x27;pursuer_1&#x27;: 2004.0, &#x27;pursuer_0&#x27;: 2000.0}, &#x27;num_agent_steps_sampled_lifetime&#x27;: {&#x27;pursuer_0&#x27;: 4000.0, &#x27;pursuer_1&#x27;: 4008.0}, &#x27;env_reset_timer&#x27;: np.float64(0.0015643125007045455), &#x27;env_to_module_sum_episodes_length_in&#x27;: np.float64(891.0423566894266), &#x27;module_episode_returns_mean&#x27;: {&#x27;pursuer_1&#x27;: -200.61821661608354, &#x27;pursuer_0&#x27;: -80.28831977246807}, &#x27;num_env_steps_sampled_lifetime&#x27;: 8000.0, &#x27;episode_duration_sec_mean&#x27;: 0.9735575072536449, &#x27;sample&#x27;: np.float64(1.9717855798754318), &#x27;num_episodes_lifetime&#x27;: 8.0, &#x27;env_step_timer&#x27;: np.float64(0.00037825293347200026), &#x27;episode_return_mean&#x27;: -280.9065363885516, &#x27;weights_seq_no&#x27;: 1.0, &#x27;agent_episode_returns_mean&#x27;: {&#x27;pursuer_1&#x27;: -200.61821661608354, &#x27;pursuer_0&#x27;: -80.28831977246807}, &#x27;episode_return_max&#x27;: -245.02516651073142, &#x27;num_module_steps_sampled_lifetime&#x27;: {&#x27;pursuer_1&#x27;: 4008.0, &#x27;pursuer_0&#x27;: 4000.0}, &#x27;agent_steps&#x27;: {&#x27;pursuer_1&#x27;: 500.0, &#x27;pursuer_0&#x27;: 500.0}, &#x27;env_to_module_sum_episodes_length_out&#x27;: np.float64(891.0423566894266), &#x27;connector_pipeline_timer&#x27;: np.float64(0.0002976039977511391), &#x27;rlmodule_inference_timer&#x27;: np.float64(9.30752296218829e-05), &#x27;episode_len_min&#x27;: 1000, &#x27;time_between_sampling&#x27;: np.float64(2.8215732675016625), &#x27;num_env_steps_sampled_lifetime_throughput&#x27;: np.float64(1123.3565347627766)}</td><td>{&#x27;num_healthy_workers&#x27;: 2, &#x27;num_remote_worker_restarts&#x27;: 0}</td><td>{&#x27;pursuer_1&#x27;: {&#x27;num_module_steps_trained_lifetime&#x27;: 120320, &#x27;num_trainable_parameters&#x27;: 129285, &#x27;weights_seq_no&#x27;: 2.0, &#x27;vf_loss&#x27;: np.float32(9.69729), &#x27;num_module_steps_trained&#x27;: 60160, &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;curr_kl_coeff&#x27;: 0.20000000298023224, &#x27;policy_loss&#x27;: np.float32(-0.00037758052), &#x27;vf_explained_var&#x27;: np.float32(-0.001319766), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;entropy&#x27;: np.float32(2.853284), &#x27;vf_loss_unclipped&#x27;: np.float32(956.07336), &#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;mean_kl_loss&#x27;: np.float32(0.007978439), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(1.9866033), &#x27;total_loss&#x27;: np.float32(0.049704555), &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 24692.41143070298}, &#x27;pursuer_0&#x27;: {&#x27;weights_seq_no&#x27;: 2.0, &#x27;vf_loss&#x27;: np.float32(9.249876), &#x27;num_module_steps_trained&#x27;: 60160, &#x27;curr_kl_coeff&#x27;: 0.20000000298023224, &#x27;policy_loss&#x27;: np.float32(-0.13106476), &#x27;vf_explained_var&#x27;: np.float32(0.0022791028), &#x27;total_loss&#x27;: np.float32(-0.082742795), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;entropy&#x27;: np.float32(2.7130752), &#x27;vf_loss_unclipped&#x27;: np.float32(223.16127), &#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;mean_kl_loss&#x27;: np.float32(0.0103629045), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(1.5659665), &#x27;num_module_steps_trained_lifetime&#x27;: 120320, &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;num_trainable_parameters&#x27;: 129285, &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 24692.44718781971}, &#x27;__all_modules__&#x27;: {&#x27;num_module_steps_trained_lifetime&#x27;: 240640, &#x27;num_trainable_parameters&#x27;: 258570, &#x27;learner_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;general_advantage_estimation&#x27;: 0.05297795948485145, &#x27;numpy_to_tensor&#x27;: 0.001045497815212002, &#x27;add_states_from_episodes_to_batch&#x27;: 5.787231057183817e-06, &#x27;add_observations_from_episodes_to_batch&#x27;: 6.77131382690277e-05, &#x27;add_one_ts_to_episodes_and_truncate&#x27;: 0.002992387117119506, &#x27;add_columns_from_episodes_to_train_batch&#x27;: 0.03416252369221184, &#x27;batch_individual_items&#x27;: 0.020610537535685577, &#x27;agent_to_module_mapping&#x27;: 0.0018119708621816243, &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: 1.840470897150226e-05}}, &#x27;connector_pipeline_timer&#x27;: 0.1140123584367393}, &#x27;learner_connector_sum_episodes_length_out&#x27;: 4000.0, &#x27;num_env_steps_trained_lifetime&#x27;: 3760000, &#x27;num_module_steps_trained&#x27;: 120320, &#x27;learner_connector_sum_episodes_length_in&#x27;: 4000.0, &#x27;num_non_trainable_parameters&#x27;: 0, &#x27;num_env_steps_trained&#x27;: 1880000, &#x27;num_env_steps_trained_lifetime_throughput&#x27;: 771628.3038593859, &#x27;num_module_steps_trained_throughput&#x27;: 1393469.6262184388, &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 1440742.9745197273}}</td><td style=\"text-align: right;\">                            8000</td><td style=\"text-align: right;\">                                      1</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(6.471428571428572), &#x27;ram_util_percent&#x27;: np.float64(15.299999999999999)}</td><td>{&#x27;training_iteration&#x27;: 4.772400589327736, &#x27;restore_env_runners&#x27;: 2.14390225301031e-05, &#x27;training_step&#x27;: 4.77221894985225, &#x27;env_runner_sampling_timer&#x27;: 1.9855565452729933, &#x27;learner_update_timer&#x27;: 2.7836972756551406, &#x27;synch_weights&#x27;: 0.002741748797125183, &#x27;synch_env_connectors&#x27;: 0.0014315750013338402}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-06-24 15:13:33,206 E 551413 551443] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-24_15-13-22_768088_547330 is over 95% full, available space: 5.50169 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(PPO pid=552889)\u001b[0m 2025-06-24 15:13:27,123\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-24 15:13:33 (running for 00:00:10.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-24_15-13-22_768088_547330/artifacts/2025-06-24_15-13-23/PPO_2025-06-24_15-13-23/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 15:13:37,141\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-06-24_15-13-23' in 0.0112s.\n",
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=552889)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-06-24_15-13-23/PPO_env_55877_00000_0_2025-06-24_15-13-23/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-24 15:13:37 (running for 00:00:13.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-24_15-13-22_768088_547330/artifacts/2025-06-24_15-13-23/PPO_2025-06-24_15-13-23/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+---------------------+------------+---------------------+--------+------------------+------+-------------------+--------------------+--------------------+\n",
      "| Trial name          | status     | loc                 |   iter |   total time (s) |   ts |   combined return |   return pursuer_0 |   return pursuer_1 |\n",
      "|---------------------+------------+---------------------+--------+------------------+------+-------------------+--------------------+--------------------|\n",
      "| PPO_env_55877_00000 | TERMINATED | 192.168.0.25:552889 |      2 |          9.28754 | 8000 |          -280.907 |           -80.2883 |           -200.618 |\n",
      "+---------------------+------------+---------------------+--------+------------------+------+-------------------+--------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 15:13:37,634\tINFO tune.py:1041 -- Total run time: 13.91 seconds (13.39 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境注册和配置完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-06-24 15:13:43,213 E 551413 551443] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-24_15-13-22_768088_547330 is over 95% full, available space: 5.49796 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-24 15:13:53,221 E 551413 551443] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-24_15-13-22_768088_547330 is over 95% full, available space: 5.49795 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-24 15:14:03,229 E 551413 551443] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-24_15-13-22_768088_547330 is over 95% full, available space: 5.49794 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-24 15:14:13,236 E 551413 551443] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-24_15-13-22_768088_547330 is over 95% full, available space: 5.49793 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-24 15:14:23,244 E 551413 551443] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-24_15-13-22_768088_547330 is over 95% full, available space: 5.49773 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(PPO pid=553224)\u001b[0m 2025-06-24 15:14:23,481\tWARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(MultiAgentEnvRunner pid=553291)\u001b[0m 2025-06-24 15:14:25,212\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=553224)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=553224)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-06-24_15-14-21/PPO_env_783e9_00000_0_2025-06-24_15-14-21/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=553224)\u001b[0m 2025-06-24 15:14:25,281\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 注册环境和配置算法\n",
    "# Here, we use the \"Agent Environment Cycle\" (AEC) PettingZoo environment type.\n",
    "# For a \"Parallel\" environment example, see the rock paper scissors examples\n",
    "# in this same repository folder.\n",
    "# Here, we use the \"Agent Environment Cycle\" (AEC) PettingZoo environment type.\n",
    "# For a \"Parallel\" environment example, see the rock paper scissors examples\n",
    "# in this same repository folder.\n",
    "register_env(\"env\", lambda _: PettingZooEnv(waterworld_v4.env()))\n",
    "\n",
    "# Policies are called just like the agents (exact 1:1 mapping).\n",
    "policies = {f\"pursuer_{i}\" for i in range(args.num_agents)}\n",
    "\n",
    "base_config = (\n",
    "    get_trainable_cls(args.algo)\n",
    "    .get_default_config()\n",
    "    .environment(\"env\")\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        # Exact 1:1 mapping from AgentID to ModuleID.\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .training(\n",
    "        vf_loss_coeff=0.005,\n",
    "    )\n",
    "    .rl_module(\n",
    "        rl_module_spec=MultiRLModuleSpec(\n",
    "            rl_module_specs={p: RLModuleSpec() for p in policies},\n",
    "        ),\n",
    "        model_config=DefaultModelConfig(vf_share_layers=True),\n",
    "    )\n",
    ")\n",
    "\n",
    "# run_rllib_example_script_experiment(base_config, args)\n",
    "results = run_rllib_example_script_experiment(base_config, args, keep_ray_up=True)\n",
    "print(\"环境注册和配置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab01ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Now swap in the RLModule weights for policy 0.\n",
    "    chkpt_path = results.get_best_result().checkpoint.path\n",
    "    p_0_module_state_path = (\n",
    "        Path(chkpt_path)  # <- algorithm's checkpoint dir\n",
    "        / COMPONENT_LEARNER_GROUP  # <- learner group\n",
    "        / COMPONENT_LEARNER  # <- learner\n",
    "        / COMPONENT_RL_MODULE  # <- MultiRLModule\n",
    "        / \"pursuer_0\"  # <- (single) RLModule\n",
    "    )\n",
    "\n",
    "    class LoadP0OnAlgoInitCallback(DefaultCallbacks):\n",
    "        def on_algorithm_init(self, *, algorithm, **kwargs):\n",
    "            module_p0 = algorithm.get_module(\"pursuer_0\")\n",
    "            weight_before = convert_to_numpy(next(iter(module_p0.parameters())))\n",
    "            algorithm.restore_from_path(\n",
    "                p_0_module_state_path,\n",
    "                component=(\n",
    "                    COMPONENT_LEARNER_GROUP\n",
    "                    + \"/\"\n",
    "                    + COMPONENT_LEARNER\n",
    "                    + \"/\"\n",
    "                    + COMPONENT_RL_MODULE\n",
    "                    + \"/pursuer_0\"\n",
    "                ),\n",
    "            )\n",
    "            # Make sure weights were updated.\n",
    "            weight_after = convert_to_numpy(next(iter(module_p0.parameters())))\n",
    "            check(weight_before, weight_after, false=True)\n",
    "\n",
    "    base_config.callbacks(LoadP0OnAlgoInitCallback)\n",
    "\n",
    "    # Define stopping criteria.\n",
    "    stop = {\n",
    "        f\"{ENV_RUNNER_RESULTS}/{EPISODE_RETURN_MEAN}\": -800.0,\n",
    "        f\"{ENV_RUNNER_RESULTS}/{NUM_ENV_STEPS_SAMPLED_LIFETIME}\": 100000,\n",
    "        TRAINING_ITERATION: 100,\n",
    "    }\n",
    "\n",
    "    # Run the experiment again with the restored MultiRLModule.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40a12fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 15:14:21,969\tINFO worker.py:1747 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-24 15:14:22 (running for 00:00:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-24_15-13-22_768088_547330/artifacts/2025-06-24_15-14-21/PPO_2025-06-24_15-14-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-06-24 15:14:27 (running for 00:00:05.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-24_15-13-22_768088_547330/artifacts/2025-06-24_15-14-21/PPO_2025-06-24_15-14-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>env_runner_group                               </th><th>env_runners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </th><th>fault_tolerance                                            </th><th>learners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </th><th style=\"text-align: right;\">  num_env_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_training_step_calls_per_iteration</th><th>perf                                                                                                  </th><th>timers                                                                                                                                                                                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_env_783e9_00000</td><td>{&#x27;actor_manager_num_outstanding_async_reqs&#x27;: 0}</td><td>{&#x27;episode_return_mean&#x27;: -268.5760928226974, &#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;add_states_from_episodes_to_batch&#x27;: np.float64(5.258996679913253e-06), &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: np.float64(1.3854005374014378e-05), &#x27;batch_individual_items&#x27;: np.float64(2.0836996554862708e-05), &#x27;add_observations_from_episodes_to_batch&#x27;: np.float64(2.7727000997401774e-05), &#x27;numpy_to_tensor&#x27;: np.float64(4.313700628699735e-05), &#x27;agent_to_module_mapping&#x27;: np.float64(4.517001798376441e-06)}}, &#x27;env_step_timer&#x27;: np.float64(0.0003814526646025043), &#x27;module_to_env_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;listify_data_for_vector_env&#x27;: np.float64(5.942108929210167e-06), &#x27;get_actions&#x27;: np.float64(8.389884802789747e-05), &#x27;remove_single_ts_time_rank_from_batch&#x27;: np.float64(1.0195315071435456e-06), &#x27;un_batch_to_individual_items&#x27;: np.float64(1.3324286282875254e-05), &#x27;module_to_agent_unmapping&#x27;: np.float64(2.590691764361659e-06), &#x27;tensor_to_numpy&#x27;: np.float64(3.194252529286243e-05), &#x27;normalize_and_clip_actions&#x27;: np.float64(3.5813801194417956e-05)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.00022830546882528512)}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.00030506049370160326), &#x27;rlmodule_inference_timer&#x27;: np.float64(9.454647176123216e-05), &#x27;num_episodes&#x27;: 4.0, &#x27;num_episodes_lifetime&#x27;: 4.0, &#x27;episode_duration_sec_mean&#x27;: 0.9844869287517213, &#x27;env_to_module_sum_episodes_length_out&#x27;: np.float64(891.0423550617884), &#x27;env_to_module_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;numpy_to_tensor&#x27;: np.float64(2.298203175429458e-05), &#x27;agent_to_module_mapping&#x27;: np.float64(3.51070875931226e-06), &#x27;add_states_from_episodes_to_batch&#x27;: np.float64(4.080696212233653e-06), &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: np.float64(7.276576194437507e-06), &#x27;batch_individual_items&#x27;: np.float64(1.2931267538449835e-05), &#x27;add_observations_from_episodes_to_batch&#x27;: np.float64(1.5947523682306034e-05)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.00010796216440645115)}, &#x27;num_module_steps_sampled&#x27;: {&#x27;pursuer_0&#x27;: 2000.0, &#x27;pursuer_1&#x27;: 2004.0}, &#x27;num_agent_steps_sampled&#x27;: {&#x27;pursuer_0&#x27;: 2000.0, &#x27;pursuer_1&#x27;: 2004.0}, &#x27;num_env_steps_sampled_lifetime&#x27;: 4000.0, &#x27;episode_return_max&#x27;: -242.96889415168536, &#x27;episode_len_max&#x27;: 1000, &#x27;weights_seq_no&#x27;: 0.0, &#x27;env_reset_timer&#x27;: np.float64(0.0015530124946963042), &#x27;num_agent_steps_sampled_lifetime&#x27;: {&#x27;pursuer_0&#x27;: 2000.0, &#x27;pursuer_1&#x27;: 2004.0}, &#x27;env_to_module_sum_episodes_length_in&#x27;: np.float64(891.0423550617884), &#x27;agent_steps&#x27;: {&#x27;pursuer_0&#x27;: 500.0, &#x27;pursuer_1&#x27;: 500.0}, &#x27;agent_episode_returns_mean&#x27;: {&#x27;pursuer_0&#x27;: -95.10862909562223, &#x27;pursuer_1&#x27;: -173.4674637270751}, &#x27;episode_len_mean&#x27;: 1000.0, &#x27;module_episode_returns_mean&#x27;: {&#x27;pursuer_0&#x27;: -95.10862909562223, &#x27;pursuer_1&#x27;: -173.4674637270751}, &#x27;sample&#x27;: np.float64(1.9823065269956714), &#x27;num_module_steps_sampled_lifetime&#x27;: {&#x27;pursuer_0&#x27;: 2000.0, &#x27;pursuer_1&#x27;: 2004.0}, &#x27;episode_len_min&#x27;: 1000, &#x27;num_env_steps_sampled&#x27;: 4000.0, &#x27;episode_return_min&#x27;: -298.266061570744, &#x27;num_env_steps_sampled_lifetime_throughput&#x27;: np.float64(1120.1655487619191)}</td><td>{&#x27;num_healthy_workers&#x27;: 2, &#x27;num_remote_worker_restarts&#x27;: 0}</td><td>{&#x27;__all_modules__&#x27;: {&#x27;learner_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;add_observations_from_episodes_to_batch&#x27;: 6.593498983420432e-05, &#x27;add_one_ts_to_episodes_and_truncate&#x27;: 0.0029576039960375056, &#x27;numpy_to_tensor&#x27;: 0.0010344220063416287, &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: 1.7400991055183113e-05, &#x27;batch_individual_items&#x27;: 0.020714743004646152, &#x27;add_states_from_episodes_to_batch&#x27;: 5.59899490326643e-06, &#x27;agent_to_module_mapping&#x27;: 0.001833588001318276, &#x27;add_columns_from_episodes_to_train_batch&#x27;: 0.034032218987704255, &#x27;general_advantage_estimation&#x27;: 0.053947927997796796}}, &#x27;connector_pipeline_timer&#x27;: 0.11501642699295189}, &#x27;learner_connector_sum_episodes_length_in&#x27;: 4000, &#x27;num_module_steps_trained_lifetime&#x27;: 120320, &#x27;num_non_trainable_parameters&#x27;: 0, &#x27;num_module_steps_trained&#x27;: 120320, &#x27;num_env_steps_trained_lifetime&#x27;: 1880000, &#x27;num_trainable_parameters&#x27;: 258570, &#x27;num_env_steps_trained&#x27;: 1880000, &#x27;learner_connector_sum_episodes_length_out&#x27;: 4000, &#x27;num_env_steps_trained_lifetime_throughput&#x27;: 759360.9367990067, &#x27;num_module_steps_trained_throughput&#x27;: 1344522.4867405982, &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 1386590.2866753954}, &#x27;pursuer_0&#x27;: {&#x27;num_module_steps_trained_lifetime&#x27;: 60160, &#x27;mean_kl_loss&#x27;: np.float32(0.0067999354), &#x27;num_module_steps_trained&#x27;: 60160, &#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;num_trainable_parameters&#x27;: 129285, &#x27;vf_loss_unclipped&#x27;: np.float32(206.2298), &#x27;policy_loss&#x27;: np.float32(0.016337782), &#x27;vf_explained_var&#x27;: np.float32(0.004850447), &#x27;curr_kl_coeff&#x27;: 0.20000000298023224, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;weights_seq_no&#x27;: 1.0, &#x27;entropy&#x27;: np.float32(2.703402), &#x27;total_loss&#x27;: np.float32(0.064138055), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;vf_loss&#x27;: np.float32(9.288061), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(1.4412357), &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 24297.270113286664}, &#x27;pursuer_1&#x27;: {&#x27;num_module_steps_trained_lifetime&#x27;: 60160, &#x27;mean_kl_loss&#x27;: np.float32(0.007260373), &#x27;total_loss&#x27;: np.float32(0.013625271), &#x27;num_module_steps_trained&#x27;: 60160, &#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;policy_loss&#x27;: np.float32(-0.0363617), &#x27;vf_explained_var&#x27;: np.float32(0.0012221932), &#x27;curr_kl_coeff&#x27;: 0.20000000298023224, &#x27;num_trainable_parameters&#x27;: 129285, &#x27;vf_loss_unclipped&#x27;: np.float32(929.5851), &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;weights_seq_no&#x27;: 1.0, &#x27;entropy&#x27;: np.float32(3.1846786), &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;vf_loss&#x27;: np.float32(9.7069845), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(1.4107062), &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 24298.31798190703}}</td><td style=\"text-align: right;\">                            4000</td><td style=\"text-align: right;\">                                      1</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(5.714285714285714), &#x27;ram_util_percent&#x27;: np.float64(14.97142857142857)}</td><td>{&#x27;training_iteration&#x27;: 4.805108229003963, &#x27;restore_env_runners&#x27;: 1.4025994460098445e-05, &#x27;training_step&#x27;: 4.80497099198692, &#x27;env_runner_sampling_timer&#x27;: 1.9941081529977964, &#x27;learner_update_timer&#x27;: 2.8083153249899624, &#x27;synch_weights&#x27;: 0.00232674898870755}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 15:14:30,777\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-06-24_15-14-21' in 0.0092s.\n",
      "2025-06-24 15:14:30,860\tINFO tune.py:1041 -- Total run time: 8.89 seconds (8.79 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-06-24 15:14:30 (running for 00:00:08.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-06-24_15-13-22_768088_547330/artifacts/2025-06-24_15-14-21/PPO_2025-06-24_15-14-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+---------------------+------------+---------------------+--------+------------------+------+-------------------+--------------------+--------------------+\n",
      "| Trial name          | status     | loc                 |   iter |   total time (s) |   ts |   combined return |   return pursuer_0 |   return pursuer_1 |\n",
      "|---------------------+------------+---------------------+--------+------------------+------+-------------------+--------------------+--------------------|\n",
      "| PPO_env_783e9_00000 | TERMINATED | 192.168.0.25:553224 |      1 |          4.80809 | 4000 |          -268.576 |           -95.1086 |           -173.467 |\n",
      "+---------------------+------------+---------------------+--------+------------------+------+-------------------+--------------------+--------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={'timers': {'training_iteration': 4.805108229003963, 'restore_env_runners': 1.4025994460098445e-05, 'training_step': 4.80497099198692, 'env_runner_sampling_timer': 1.9941081529977964, 'learner_update_timer': 2.8083153249899624, 'synch_weights': 0.00232674898870755}, 'env_runners': {'episode_return_mean': -268.5760928226974, 'timers': {'connectors': {'add_states_from_episodes_to_batch': np.float64(5.258996679913253e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(1.3854005374014378e-05), 'batch_individual_items': np.float64(2.0836996554862708e-05), 'add_observations_from_episodes_to_batch': np.float64(2.7727000997401774e-05), 'numpy_to_tensor': np.float64(4.313700628699735e-05), 'agent_to_module_mapping': np.float64(4.517001798376441e-06)}}, 'env_step_timer': np.float64(0.0003814526646025043), 'module_to_env_connector': {'timers': {'connectors': {'listify_data_for_vector_env': np.float64(5.942108929210167e-06), 'get_actions': np.float64(8.389884802789747e-05), 'remove_single_ts_time_rank_from_batch': np.float64(1.0195315071435456e-06), 'un_batch_to_individual_items': np.float64(1.3324286282875254e-05), 'module_to_agent_unmapping': np.float64(2.590691764361659e-06), 'tensor_to_numpy': np.float64(3.194252529286243e-05), 'normalize_and_clip_actions': np.float64(3.5813801194417956e-05)}}, 'connector_pipeline_timer': np.float64(0.00022830546882528512)}, 'connector_pipeline_timer': np.float64(0.00030506049370160326), 'rlmodule_inference_timer': np.float64(9.454647176123216e-05), 'num_episodes': 4.0, 'num_episodes_lifetime': 4.0, 'episode_duration_sec_mean': 0.9844869287517213, 'env_to_module_sum_episodes_length_out': np.float64(891.0423550617884), 'env_to_module_connector': {'timers': {'connectors': {'numpy_to_tensor': np.float64(2.298203175429458e-05), 'agent_to_module_mapping': np.float64(3.51070875931226e-06), 'add_states_from_episodes_to_batch': np.float64(4.080696212233653e-06), 'add_time_dim_to_batch_and_zero_pad': np.float64(7.276576194437507e-06), 'batch_individual_items': np.float64(1.2931267538449835e-05), 'add_observations_from_episodes_to_batch': np.float64(1.5947523682306034e-05)}}, 'connector_pipeline_timer': np.float64(0.00010796216440645115)}, 'num_module_steps_sampled': {'pursuer_0': 2000.0, 'pursuer_1': 2004.0}, 'num_agent_steps_sampled': {'pursuer_0': 2000.0, 'pursuer_1': 2004.0}, 'num_env_steps_sampled_lifetime': 4000.0, 'episode_return_max': -242.96889415168536, 'episode_len_max': 1000, 'weights_seq_no': 0.0, 'env_reset_timer': np.float64(0.0015530124946963042), 'num_agent_steps_sampled_lifetime': {'pursuer_0': 2000.0, 'pursuer_1': 2004.0}, 'env_to_module_sum_episodes_length_in': np.float64(891.0423550617884), 'agent_steps': {'pursuer_0': 500.0, 'pursuer_1': 500.0}, 'agent_episode_returns_mean': {'pursuer_0': -95.10862909562223, 'pursuer_1': -173.4674637270751}, 'episode_len_mean': 1000.0, 'module_episode_returns_mean': {'pursuer_0': -95.10862909562223, 'pursuer_1': -173.4674637270751}, 'sample': np.float64(1.9823065269956714), 'num_module_steps_sampled_lifetime': {'pursuer_0': 2000.0, 'pursuer_1': 2004.0}, 'episode_len_min': 1000, 'num_env_steps_sampled': 4000.0, 'episode_return_min': -298.266061570744, 'num_env_steps_sampled_lifetime_throughput': np.float64(1120.1655487619191)}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_observations_from_episodes_to_batch': 6.593498983420432e-05, 'add_one_ts_to_episodes_and_truncate': 0.0029576039960375056, 'numpy_to_tensor': 0.0010344220063416287, 'add_time_dim_to_batch_and_zero_pad': 1.7400991055183113e-05, 'batch_individual_items': 0.020714743004646152, 'add_states_from_episodes_to_batch': 5.59899490326643e-06, 'agent_to_module_mapping': 0.001833588001318276, 'add_columns_from_episodes_to_train_batch': 0.034032218987704255, 'general_advantage_estimation': 0.053947927997796796}}, 'connector_pipeline_timer': 0.11501642699295189}, 'learner_connector_sum_episodes_length_in': 4000, 'num_module_steps_trained_lifetime': 120320, 'num_non_trainable_parameters': 0, 'num_module_steps_trained': 120320, 'num_env_steps_trained_lifetime': 1880000, 'num_trainable_parameters': 258570, 'num_env_steps_trained': 1880000, 'learner_connector_sum_episodes_length_out': 4000, 'num_env_steps_trained_lifetime_throughput': 759360.9367990067, 'num_module_steps_trained_throughput': 1344522.4867405982, 'num_module_steps_trained_lifetime_throughput': 1386590.2866753954}, 'pursuer_0': {'num_module_steps_trained_lifetime': 60160, 'mean_kl_loss': np.float32(0.0067999354), 'num_module_steps_trained': 60160, 'default_optimizer_learning_rate': 5e-05, 'num_trainable_parameters': 129285, 'vf_loss_unclipped': np.float32(206.2298), 'policy_loss': np.float32(0.016337782), 'vf_explained_var': np.float32(0.004850447), 'curr_kl_coeff': 0.20000000298023224, 'module_train_batch_size_mean': 128.0, 'weights_seq_no': 1.0, 'entropy': np.float32(2.703402), 'total_loss': np.float32(0.064138055), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'curr_entropy_coeff': 0.0, 'vf_loss': np.float32(9.288061), 'gradients_default_optimizer_global_norm': np.float32(1.4412357), 'num_module_steps_trained_lifetime_throughput': 24297.270113286664}, 'pursuer_1': {'num_module_steps_trained_lifetime': 60160, 'mean_kl_loss': np.float32(0.007260373), 'total_loss': np.float32(0.013625271), 'num_module_steps_trained': 60160, 'default_optimizer_learning_rate': 5e-05, 'policy_loss': np.float32(-0.0363617), 'vf_explained_var': np.float32(0.0012221932), 'curr_kl_coeff': 0.20000000298023224, 'num_trainable_parameters': 129285, 'vf_loss_unclipped': np.float32(929.5851), 'module_train_batch_size_mean': 128.0, 'weights_seq_no': 1.0, 'entropy': np.float32(3.1846786), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'curr_entropy_coeff': 0.0, 'vf_loss': np.float32(9.7069845), 'gradients_default_optimizer_global_norm': np.float32(1.4107062), 'num_module_steps_trained_lifetime_throughput': 24298.31798190703}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 4000.0, 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'perf': {'cpu_util_percent': np.float64(5.714285714285714), 'ram_util_percent': np.float64(14.97142857142857)}},\n",
       "    path='/home/qrbao/ray_results/PPO_2025-06-24_15-14-21/PPO_env_783e9_00000_0_2025-06-24_15-14-21',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-06-24_15-14-21/PPO_env_783e9_00000_0_2025-06-24_15-14-21/checkpoint_000000)\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rllib_example_script_experiment(base_config, args, stop=stop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
