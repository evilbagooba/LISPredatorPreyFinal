['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-01 23:10:07,047	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-01 23:10:07,636	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-01 23:10:07 (running for 00:00:00.13)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_17aba_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=3373861)[0m 2025-07-01 23:10:09,916	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(PPO pid=3373861)[0m 2025-07-01 23:10:12,416	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
== Status ==
Current time: 2025-07-01 23:10:12 (running for 00:00:05.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_17aba_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=3373861)[0m Install gputil for GPU system monitoring.


[36m(MultiAgentEnvRunner pid=3374185)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=3374356)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts/PPO_env_17aba_00000_0_2025-07-01_23-10-07/wandb/run-20250701_231015-17aba_00000
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Syncing run PPO_env_17aba_00000
[36m(_WandbLoggingActor pid=3374356)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=3374356)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/17aba_00000
[33m(raylet)[0m [2025-07-01 23:10:17,037 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.9451 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:10:17 (running for 00:00:10.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+
| Trial name          | status   | loc                  |
|---------------------+----------+----------------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |
+---------------------+----------+----------------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=4000.0,env_runners/episode_return_mean=-480.25260788968774 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000000)
[36m(MultiAgentEnvRunner pid=3374186)[0m 2025-07-01 23:10:12,341	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12105x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000000)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:10:22 (running for 00:00:15.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      1 |          5.83389 | 4000 |          -480.253 |        -97.6041 |            -77.6324 |            -87.9155 |        -217.101 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=8000.0,env_runners/episode_return_mean=-467.0621995318667 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000001)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12183x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000001)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:10:27,042 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.9174 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:10:27 (running for 00:00:20.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      2 |          10.9658 | 8000 |          -467.062 |        -101.537 |            -79.8274 |            -81.8315 |        -203.866 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=12000.0,env_runners/episode_return_mean=-454.7732532056677 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000002)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000002)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:10:32 (running for 00:00:25.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      3 |          16.2406 | 12000 |          -454.773 |        -91.5154 |            -82.5228 |            -80.9422 |        -199.793 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=16000.0,env_runners/episode_return_mean=-463.8790528264959 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000003)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000003)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:10:37,047 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.8882 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:10:38 (running for 00:00:30.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      4 |          21.2084 | 16000 |          -463.879 |        -90.9314 |            -84.3576 |              -87.54 |         -201.05 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=20000.0,env_runners/episode_return_mean=-457.2025970407923 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000004)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11892x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000004)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:10:43 (running for 00:00:35.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      5 |          26.3275 | 20000 |          -457.203 |        -91.8533 |            -85.5888 |            -84.9165 |        -194.844 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=24000.0,env_runners/episode_return_mean=-460.99431785515657 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000005)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000005)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:10:47,051 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.8601 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:10:48 (running for 00:00:40.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      6 |          31.3866 | 24000 |          -460.994 |        -89.7262 |            -87.5182 |            -87.9359 |        -195.814 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=28000.0,env_runners/episode_return_mean=-468.289764836173 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000006)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12096x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:10:53 (running for 00:00:45.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      7 |          36.7361 | 28000 |           -468.29 |        -91.5573 |            -90.6623 |            -88.8007 |        -197.269 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:10:57,057 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.845 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=32000.0,env_runners/episode_return_mean=-474.60428985287047 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000007)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11970x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000007)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:10:58 (running for 00:00:50.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      8 |           42.402 | 32000 |          -474.604 |        -90.6217 |            -92.1121 |            -91.9869 |        -199.884 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=36000.0,env_runners/episode_return_mean=-473.5354986063784 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000008)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000008)...
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12148x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:11:03 (running for 00:00:55.69)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |      9 |          47.3703 | 36000 |          -473.535 |        -88.5109 |            -92.8669 |            -90.7035 |        -201.454 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:11:07,062 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.8164 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=40000.0,env_runners/episode_return_mean=-476.7036564434764 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000009)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11774x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000009)...
== Status ==
Current time: 2025-07-01 23:11:08 (running for 00:01:00.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     10 |          52.8569 | 40000 |          -476.704 |         -86.821 |            -95.1095 |            -92.0905 |        -202.683 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=44000.0,env_runners/episode_return_mean=-471.47180803759477 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000010)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12136x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000010)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:11:13 (running for 00:01:05.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     11 |          57.8886 | 44000 |          -471.472 |        -85.2455 |            -93.2714 |            -89.4979 |        -203.457 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:11:17,067 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.7819 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=48000.0,env_runners/episode_return_mean=-470.2484814460434 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
== Status ==
Current time: 2025-07-01 23:11:18 (running for 00:01:10.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     12 |          62.9865 | 48000 |          -470.248 |         -84.423 |            -93.3132 |            -88.9403 |        -203.572 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000011)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11972x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000011)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:11:23 (running for 00:01:15.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     12 |          62.9865 | 48000 |          -470.248 |         -84.423 |            -93.3132 |            -88.9403 |        -203.572 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=52000.0,env_runners/episode_return_mean=-469.8763267967543 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000012)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12030x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000012)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:11:27,072 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.7536 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:11:28 (running for 00:01:20.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     13 |           68.158 | 52000 |          -469.876 |        -84.8115 |            -92.5673 |            -89.0713 |        -203.426 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=56000.0,env_runners/episode_return_mean=-472.8901188899591 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000013)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12114x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000013)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:11:33 (running for 00:01:26.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     14 |          73.5184 | 56000 |           -472.89 |        -86.1056 |            -93.9251 |             -88.744 |        -204.115 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=60000.0,env_runners/episode_return_mean=-471.11621749236 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initi
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000014)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11877x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000014)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:11:37,077 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.7254 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:11:38 (running for 00:01:31.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     15 |          78.7417 | 60000 |          -471.116 |        -84.6727 |            -94.0874 |            -89.2437 |        -203.112 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=64000.0,env_runners/episode_return_mean=-471.5261277208326 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000015)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12003x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000015)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:11:43 (running for 00:01:36.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     16 |          83.8582 | 64000 |          -471.526 |        -84.9864 |            -94.6578 |            -90.2188 |        -201.663 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=68000.0,env_runners/episode_return_mean=-472.0020592303327 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000016)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12096x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000016)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:11:47,083 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.6972 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:11:48 (running for 00:01:41.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     17 |          88.9899 | 68000 |          -472.002 |        -83.9606 |            -95.2884 |            -90.8011 |        -201.952 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=72000.0,env_runners/episode_return_mean=-470.5549733068571 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000017)
[36m(MultiAgentEnvRunner pid=3374186)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000017)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:11:53 (running for 00:01:46.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     18 |          94.2857 | 72000 |          -470.555 |        -84.1776 |            -94.6646 |            -91.0118 |        -200.701 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=76000.0,env_runners/episode_return_mean=-469.9011743791868 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000018)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000018)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:11:57,088 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.6692 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:11:58 (running for 00:01:51.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     19 |          99.4712 | 76000 |          -469.901 |        -84.4186 |            -92.9673 |            -92.6101 |        -199.905 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=80000.0,env_runners/episode_return_mean=-467.39268744474646 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000019)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12007x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000019)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:12:03 (running for 00:01:56.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     20 |           104.64 | 80000 |          -467.393 |        -83.6527 |            -91.4559 |            -93.1615 |        -199.123 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=84000.0,env_runners/episode_return_mean=-465.078722088922 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000020)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12221x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000020)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:12:07,093 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.6466 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:12:09 (running for 00:02:01.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     21 |          109.735 | 84000 |          -465.079 |        -83.8653 |            -90.4822 |            -93.2115 |         -197.52 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=88000.0,env_runners/episode_return_mean=-464.2151170665336 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000021)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11914x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000021)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:12:14 (running for 00:02:06.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     22 |          114.967 | 88000 |          -464.215 |        -83.8392 |            -90.0289 |            -93.0456 |        -197.301 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=92000.0,env_runners/episode_return_mean=-464.3124837595501 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000022)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11942x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000022)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:12:17,099 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.6185 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:12:19 (running for 00:02:11.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     23 |          120.063 | 92000 |          -464.312 |         -82.206 |            -90.5587 |             -94.174 |        -197.374 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=96000.0,env_runners/episode_return_mean=-463.71045203593235 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000023)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12156x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000023)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:12:24 (running for 00:02:16.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     24 |          125.184 | 96000 |           -463.71 |        -81.9889 |            -90.6742 |            -94.6144 |        -196.433 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=100000.0,env_runners/episode_return_mean=-462.84195530915696 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000024)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000024)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:12:27,104 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.5906 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:12:29 (running for 00:02:21.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     25 |          130.338 | 100000 |          -462.842 |        -81.3338 |            -91.0704 |            -94.8442 |        -195.594 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=104000.0,env_runners/episode_return_mean=-461.3381504999247 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000025)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12010x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000025)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:12:34 (running for 00:02:26.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     26 |          135.516 | 104000 |          -461.338 |        -80.7743 |            -90.8839 |            -94.8314 |        -194.849 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=108000.0,env_runners/episode_return_mean=-460.20730801875385 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000026)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11834x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000026)...
[33m(raylet)[0m [2025-07-01 23:12:37,110 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.5625 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:12:39 (running for 00:02:31.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     27 |          140.723 | 108000 |          -460.207 |        -78.8631 |             -91.674 |            -95.8682 |        -193.802 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=112000.0,env_runners/episode_return_mean=-459.6701048725993 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000027)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12064x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000027)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:12:44 (running for 00:02:36.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     28 |          145.869 | 112000 |           -459.67 |        -78.8659 |             -91.985 |            -96.1921 |        -192.627 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:12:47,115 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.5407 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=116000.0,env_runners/episode_return_mean=-456.00154060502774 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000028)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12068x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000028)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:12:49 (running for 00:02:41.69)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     29 |          151.014 | 116000 |          -456.002 |        -77.7819 |            -91.8574 |            -95.7233 |        -190.639 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=120000.0,env_runners/episode_return_mean=-455.01252983738067 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000029)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11968x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000029)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:12:54 (running for 00:02:46.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     30 |          156.223 | 120000 |          -455.013 |        -76.1403 |            -91.9802 |            -96.1958 |        -190.696 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:12:57,120 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.5185 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=124000.0,env_runners/episode_return_mean=-454.09532695764955 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000030)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12212x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000030)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:12:59 (running for 00:02:51.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     31 |          161.229 | 124000 |          -454.095 |        -75.8565 |            -91.4404 |            -96.9477 |        -189.851 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=128000.0,env_runners/episode_return_mean=-451.42736376218556 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000031)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11844x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000031)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:04 (running for 00:02:56.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     32 |          166.373 | 128000 |          -451.427 |        -75.1433 |            -90.8423 |            -96.9959 |        -188.446 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:13:07,125 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.4903 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=132000.0,env_runners/episode_return_mean=-448.353795556673 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000032)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11991x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000032)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:13:09 (running for 00:03:01.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     33 |          171.546 | 132000 |          -448.354 |        -75.3416 |            -90.0704 |            -95.7047 |        -187.237 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=136000.0,env_runners/episode_return_mean=-448.50700344605053 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000033)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12069x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000033)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:14 (running for 00:03:07.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     34 |          176.621 | 136000 |          -448.507 |        -75.0943 |            -89.9337 |            -96.4974 |        -186.982 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:13:17,130 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.4556 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=140000.0,env_runners/episode_return_mean=-445.61853523803353 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000034)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12192x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000034)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:19 (running for 00:03:12.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     35 |          181.803 | 140000 |          -445.619 |        -75.4564 |            -88.6847 |            -96.2164 |        -185.261 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=144000.0,env_runners/episode_return_mean=-449.3736497549963 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000035)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11820x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000035)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:24 (running for 00:03:17.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     36 |          186.962 | 144000 |          -449.374 |        -74.5624 |            -90.1133 |            -98.0246 |        -186.673 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:13:27,135 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.4271 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=148000.0,env_runners/episode_return_mean=-447.49954483056933 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000036)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12072x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000036)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:29 (running for 00:03:22.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     37 |          192.127 | 148000 |            -447.5 |        -73.8125 |            -89.6685 |            -97.9296 |        -186.089 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=152000.0,env_runners/episode_return_mean=-445.4388591378681 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000037)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000037)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:34 (running for 00:03:27.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     38 |          197.281 | 152000 |          -445.439 |        -72.7341 |            -90.3065 |            -98.3069 |        -184.091 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
[33m(raylet)[0m [2025-07-01 23:13:37,139 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.399 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=156000.0,env_runners/episode_return_mean=-442.24511750453297 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000038)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000038)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:39 (running for 00:03:32.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     39 |          202.517 | 156000 |          -442.245 |        -71.5475 |            -89.3181 |            -98.7931 |        -182.586 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=160000.0,env_runners/episode_return_mean=-440.7242900960326 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000039)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11968x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000039)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:44 (running for 00:03:37.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     40 |          207.608 | 160000 |          -440.724 |        -72.2813 |            -88.7768 |            -98.8608 |        -180.805 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:13:47,144 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.3711 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=164000.0,env_runners/episode_return_mean=-435.9695493074978 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000040)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12032x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000040)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:13:50 (running for 00:03:42.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     41 |          212.689 | 164000 |           -435.97 |        -69.7422 |            -87.2763 |            -97.4492 |        -181.502 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=168000.0,env_runners/episode_return_mean=-431.75080786149346 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
== Status ==
Current time: 2025-07-01 23:13:55 (running for 00:03:47.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     42 |          217.855 | 168000 |          -431.751 |        -70.3048 |            -86.4846 |            -96.5013 |         -178.46 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000041)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000041)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:13:57,149 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.3429 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:14:00 (running for 00:03:52.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     42 |          217.855 | 168000 |          -431.751 |        -70.3048 |            -86.4846 |            -96.5013 |         -178.46 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=172000.0,env_runners/episode_return_mean=-431.9584024474644 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000042)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11979x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000042)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:14:05 (running for 00:03:57.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     43 |          223.062 | 172000 |          -431.958 |        -69.9879 |            -86.2122 |            -96.9095 |        -178.849 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000043)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000043)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12277x across cluster][0m
[33m(raylet)[0m [2025-07-01 23:14:07,153 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.315 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:14:10 (running for 00:04:02.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     44 |          227.965 | 176000 |          -431.807 |        -69.3473 |            -87.1359 |            -96.1591 |        -179.165 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=180000.0,env_runners/episode_return_mean=-433.93153434891246 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000044)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11732x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000044)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:14:15 (running for 00:04:07.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     45 |          233.157 | 180000 |          -433.932 |        -69.5025 |             -88.086 |            -96.2908 |        -180.052 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=184000.0,env_runners/episode_return_mean=-435.3237486660648 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000045)
[36m(MultiAgentEnvRunner pid=3374185)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12203x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000045)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:14:17,158 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.2864 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:14:20 (running for 00:04:12.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     46 |          238.263 | 184000 |          -435.324 |        -69.2725 |            -87.5604 |            -96.6307 |         -181.86 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=188000.0,env_runners/episode_return_mean=-433.8929434793119 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000046)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11833x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000046)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:14:25 (running for 00:04:17.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     47 |          243.302 | 188000 |          -433.893 |        -69.3216 |            -87.6695 |            -96.0698 |        -180.832 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=192000.0,env_runners/episode_return_mean=-432.0172850314919 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000047)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12132x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000047)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:14:27,163 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.2643 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:14:30 (running for 00:04:22.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     48 |          248.437 | 192000 |          -432.017 |        -71.2341 |             -86.802 |            -94.1628 |        -179.818 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=196000.0,env_runners/episode_return_mean=-432.14988328452455 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000048)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12108x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000048)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
[36m(MultiAgentEnvRunner pid=3374186)[0m
[36m(MultiAgentEnvRunner pid=3374186)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:14:35 (running for 00:04:27.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     49 |          253.583 | 196000 |           -432.15 |        -71.9897 |            -85.8783 |            -93.9705 |        -180.311 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000049)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000049)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12106x across cluster][0m
[33m(raylet)[0m [2025-07-01 23:14:37,168 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.2363 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:14:40 (running for 00:04:32.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     50 |          258.506 | 200000 |           -430.28 |        -72.0732 |            -85.6354 |            -93.9026 |        -178.669 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=204000.0,env_runners/episode_return_mean=-428.98005026939785 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000050)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11817x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000050)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:14:45 (running for 00:04:37.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     51 |          263.884 | 204000 |           -428.98 |        -71.8632 |            -85.8958 |            -94.5931 |        -176.628 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=208000.0,env_runners/episode_return_mean=-429.0999380483912 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000051)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12149x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000051)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:14:47,173 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.2082 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:14:50 (running for 00:04:42.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     52 |          269.111 | 208000 |            -429.1 |        -72.9066 |             -85.763 |            -94.3475 |        -176.083 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000052)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12048x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000052)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:14:55 (running for 00:04:47.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     53 |           274.06 | 212000 |          -428.668 |        -73.1316 |            -84.8955 |            -95.0141 |        -175.627 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=216000.0,env_runners/episode_return_mean=-431.72806474210483 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000053)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11796x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000053)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:14:57,177 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.1801 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:15:00 (running for 00:04:52.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     54 |           279.12 | 216000 |          -431.728 |        -73.8583 |            -85.5784 |            -96.0363 |        -176.255 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=220000.0,env_runners/episode_return_mean=-430.0694574572667 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000054)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000054)...
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12252x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:15:05 (running for 00:04:57.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     55 |          284.306 | 220000 |          -430.069 |        -74.0045 |            -84.7577 |            -97.1228 |        -174.184 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:15:07,182 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.1645 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=224000.0,env_runners/episode_return_mean=-427.6161955166574 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000055)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000055)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:10 (running for 00:05:03.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     56 |          289.511 | 224000 |          -427.616 |        -72.6709 |            -84.3059 |            -96.4337 |        -174.206 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=228000.0,env_runners/episode_return_mean=-428.7698235775998 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000056)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11892x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000056)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:15 (running for 00:05:08.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     57 |          294.625 | 228000 |           -428.77 |        -72.6343 |             -85.455 |            -96.8409 |         -173.84 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:15:17,187 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.1358 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=232000.0,env_runners/episode_return_mean=-427.452770638687 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000057)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12156x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000057)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:15:20 (running for 00:05:13.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     58 |           299.85 | 232000 |          -427.453 |        -72.1781 |            -84.6115 |            -97.7313 |        -172.932 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=236000.0,env_runners/episode_return_mean=-427.02192628032935 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000058)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11904x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000058)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:25 (running for 00:05:18.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     59 |          304.988 | 236000 |          -427.022 |        -72.7599 |            -84.4076 |            -98.2671 |        -171.587 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:15:27,192 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.1077 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=240000.0,env_runners/episode_return_mean=-425.3462579247111 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000059)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000059)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:30 (running for 00:05:23.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     60 |          310.178 | 240000 |          -425.346 |        -72.3131 |            -84.4502 |            -96.6034 |         -171.98 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=244000.0,env_runners/episode_return_mean=-420.3007841034414 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000060)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000060)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:35 (running for 00:05:28.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     61 |          315.347 | 244000 |          -420.301 |        -73.6009 |            -84.1138 |            -95.8762 |         -166.71 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:15:37,197 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.0734 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=248000.0,env_runners/episode_return_mean=-419.96158507985075 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000061)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12091x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000061)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:15:40 (running for 00:05:33.33)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     62 |          320.593 | 248000 |          -419.962 |        -73.7991 |            -83.6467 |            -97.2741 |        -165.242 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=252000.0,env_runners/episode_return_mean=-418.46429690560586 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000062)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11945x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000062)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:45 (running for 00:05:38.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     63 |           325.79 | 252000 |          -418.464 |        -73.5283 |            -82.9506 |            -97.5979 |        -164.388 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:15:47,202 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.0452 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=256000.0,env_runners/episode_return_mean=-419.6420001281734 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000063)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12228x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000063)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:51 (running for 00:05:43.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     64 |          330.986 | 256000 |          -419.642 |        -73.4547 |            -82.3526 |            -98.6216 |        -165.213 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=260000.0,env_runners/episode_return_mean=-420.0955593139993 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000064)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11904x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000064)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:15:56 (running for 00:05:48.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     65 |          336.213 | 260000 |          -420.096 |        -72.4851 |            -83.5782 |            -97.1168 |        -166.915 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:15:57,207 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 15.017 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=264000.0,env_runners/episode_return_mean=-419.36463609115924 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000065)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12132x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000065)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:01 (running for 00:05:53.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     66 |          341.467 | 264000 |          -419.365 |        -74.0455 |            -83.4715 |             -97.005 |        -164.843 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=268000.0,env_runners/episode_return_mean=-421.3714465785623 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000066)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000066)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:06 (running for 00:05:58.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     67 |          346.555 | 268000 |          -421.371 |        -73.4008 |            -84.0747 |            -97.7299 |        -166.166 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:16:07,211 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.9888 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=272000.0,env_runners/episode_return_mean=-420.2129324521206 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000067)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11928x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000067)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:11 (running for 00:06:03.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     68 |          351.577 | 272000 |          -420.213 |        -72.6862 |            -85.4463 |            -96.8134 |        -165.267 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=276000.0,env_runners/episode_return_mean=-420.48799002481684 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000068)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000068)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:16 (running for 00:06:08.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     69 |          356.786 | 276000 |          -420.488 |        -72.3631 |            -86.2794 |            -96.9502 |        -164.895 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:16:17,216 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.9603 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=280000.0,env_runners/episode_return_mean=-417.3632361155785 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000069)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12048x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000069)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:16:21 (running for 00:06:13.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     70 |          361.845 | 280000 |          -417.363 |        -72.2936 |             -86.268 |             -95.114 |        -163.688 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=284000.0,env_runners/episode_return_mean=-415.4480940939078 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000070)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000070)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:26 (running for 00:06:18.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     71 |          366.911 | 284000 |          -415.448 |         -71.735 |             -87.381 |            -94.8495 |        -161.483 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:16:27,220 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.932 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=288000.0,env_runners/episode_return_mean=-417.35272469975416 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000071)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000071)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:16:31 (running for 00:06:23.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     72 |            372.1 | 288000 |          -417.353 |        -72.1623 |            -86.5205 |            -96.7758 |        -161.894 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=292000.0,env_runners/episode_return_mean=-415.6148176997705 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000072)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12168x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000072)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:36 (running for 00:06:28.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     73 |          377.153 | 292000 |          -415.615 |        -69.7853 |            -86.5004 |            -96.8295 |          -162.5 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:16:37,225 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.9092 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=296000.0,env_runners/episode_return_mean=-413.1688674085775 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000073)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11947x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000073)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:41 (running for 00:06:33.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     74 |           382.37 | 296000 |          -413.169 |        -67.7349 |            -87.0676 |            -95.9561 |         -162.41 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
[36m(MultiAgentEnvRunner pid=3374186)[0m warning: velocites provided but types or ids not provided, returning only
[36m(MultiAgentEnvRunner pid=3374186)[0m distance and velocity values
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=300000.0,env_runners/episode_return_mean=-407.9202494155598 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000074)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12184x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000074)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:46 (running for 00:06:39.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     75 |          387.576 | 300000 |           -407.92 |        -67.4397 |            -84.5271 |            -92.9756 |        -162.978 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:16:47,230 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.8816 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=304000.0,env_runners/episode_return_mean=-407.106436263363 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000075)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11967x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000075)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:16:51 (running for 00:06:44.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     76 |          392.585 | 304000 |          -407.106 |         -66.874 |            -85.2662 |            -91.8421 |        -163.124 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=308000.0,env_runners/episode_return_mean=-405.52101904785917 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000076)
== Status ==
Current time: 2025-07-01 23:16:56 (running for 00:06:49.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     77 |          397.711 | 308000 |          -405.521 |        -65.9798 |             -85.332 |            -91.1413 |        -163.068 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12093x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000076)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:16:57,234 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.8537 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=312000.0,env_runners/episode_return_mean=-403.4571873462699 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
== Status ==
Current time: 2025-07-01 23:17:01 (running for 00:06:54.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     78 |          402.852 | 312000 |          -403.457 |          -64.25 |            -85.0087 |            -89.9187 |         -164.28 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000077)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11820x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000077)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m warning: velocites provided but type
[36m(MultiAgentEnvRunner pid=3374186)[0m s or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-01 23:17:06 (running for 00:06:59.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     78 |          402.852 | 312000 |          -403.457 |          -64.25 |            -85.0087 |            -89.9187 |         -164.28 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=316000.0,env_runners/episode_return_mean=-402.110411202666 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000078)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12107x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000078)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:17:07,239 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.8254 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided b
[36m(MultiAgentEnvRunner pid=3374185)[0m ut types or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-01 23:17:11 (running for 00:07:04.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     79 |          407.999 | 316000 |           -402.11 |        -63.7695 |            -84.0111 |            -89.0249 |        -165.305 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=320000.0,env_runners/episode_return_mean=-404.6759544140225 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000079)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12119x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000079)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:17:17 (running for 00:07:09.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     80 |           413.15 | 320000 |          -404.676 |        -64.3755 |            -84.0928 |            -88.7443 |        -167.463 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:17:17,244 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.8094 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=324000.0,env_runners/episode_return_mean=-405.5582227774724 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000080)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11847x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000080)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:17:22 (running for 00:07:14.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     81 |          418.203 | 324000 |          -405.558 |        -64.7457 |            -84.7672 |            -88.4225 |        -167.623 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=328000.0,env_runners/episode_return_mean=-403.00147843923315 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000081)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12201x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000081)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:17:27 (running for 00:07:19.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     82 |          423.331 | 328000 |          -403.001 |        -63.8126 |            -83.4764 |            -87.4954 |        -168.217 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:17:27,249 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.7812 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=332000.0,env_runners/episode_return_mean=-402.93205099918157 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000082)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11842x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000082)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:17:32 (running for 00:07:24.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     83 |          428.588 | 332000 |          -402.932 |        -62.9641 |            -83.9823 |            -88.3631 |        -167.623 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=336000.0,env_runners/episode_return_mean=-401.6499448650071 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000083)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12177x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000083)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:17:37 (running for 00:07:29.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     84 |          433.707 | 336000 |           -401.65 |        -61.3769 |            -84.0091 |            -87.5416 |        -168.722 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:17:37,254 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.7529 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=340000.0,env_runners/episode_return_mean=-400.45600145183255 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000084)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11897x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000084)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:17:42 (running for 00:07:34.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     85 |          438.924 | 340000 |          -400.456 |        -61.2619 |            -82.9223 |            -88.5102 |        -167.762 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000085)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000085)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12372x across cluster][0m
[36m(MultiAgentEnvRunner pid=3374185)[0m warning:
[36m(MultiAgentEnvRunner pid=3374185)[0m velocites provided but types or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-01 23:17:47 (running for 00:07:39.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     86 |            443.8 | 344000 |          -398.417 |        -59.9402 |            -81.1266 |            -87.8401 |        -169.511 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:17:47,258 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.7247 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=348000.0,env_runners/episode_return_mean=-398.32745235502165 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000086)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11627x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000086)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:17:52 (running for 00:07:44.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     87 |           449.09 | 348000 |          -398.327 |        -59.5029 |            -81.3778 |            -86.5727 |        -170.874 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=352000.0,env_runners/episode_return_mean=-393.88127470093195 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000087)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000087)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:17:57,263 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.6903 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:17:57 (running for 00:07:49.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     88 |          454.247 | 352000 |          -393.881 |        -59.7332 |            -81.4219 |            -82.6536 |        -170.073 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=356000.0,env_runners/episode_return_mean=-390.33971156210185 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000088)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000088)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:18:02 (running for 00:07:54.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     89 |          459.304 | 356000 |           -390.34 |        -58.7116 |             -81.935 |            -81.4913 |        -168.202 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=360000.0,env_runners/episode_return_mean=-387.6825298075232 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000089)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12054x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000089)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:18:07,268 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.6617 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:18:07 (running for 00:07:59.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     90 |          464.483 | 360000 |          -387.683 |        -57.6389 |            -79.8195 |            -82.5283 |        -167.696 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=364000.0,env_runners/episode_return_mean=-389.9971923986197 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000090)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11895x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000090)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:18:12 (running for 00:08:04.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     91 |          469.716 | 364000 |          -389.997 |        -56.9918 |             -80.257 |            -82.7502 |        -169.998 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=368000.0,env_runners/episode_return_mean=-387.744547636832 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000091)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12183x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000091)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:18:17,273 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.6332 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:18:17 (running for 00:08:09.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     92 |          474.914 | 368000 |          -387.745 |        -56.6227 |            -79.5434 |            -80.7481 |         -170.83 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=372000.0,env_runners/episode_return_mean=-386.2921726719526 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000092)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000092)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:18:22 (running for 00:08:15.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     93 |           480.07 | 372000 |          -386.292 |        -55.8949 |            -77.9073 |            -81.0051 |        -171.485 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=376000.0,env_runners/episode_return_mean=-384.26209260640985 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000093)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11952x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000093)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:18:27,277 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.605 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:18:27 (running for 00:08:20.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     94 |          485.164 | 376000 |          -384.262 |        -55.2493 |             -75.956 |            -79.8016 |        -173.255 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=380000.0,env_runners/episode_return_mean=-384.52729650512845 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000094)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000094)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but typ
[36m(MultiAgentEnvRunner pid=3374185)[0m es or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-01 23:18:32 (running for 00:08:25.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     95 |          490.439 | 380000 |          -384.527 |        -53.7831 |            -76.2107 |            -80.1516 |        -174.382 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=384000.0,env_runners/episode_return_mean=-383.6027249245357 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000095)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12059x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000095)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:18:37,282 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.5769 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:18:37 (running for 00:08:30.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     96 |          495.487 | 384000 |          -383.603 |        -53.7313 |            -75.4075 |            -78.5294 |        -175.934 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=388000.0,env_runners/episode_return_mean=-383.26970966164197 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000096)
[36m(MultiAgentEnvRunner pid=3374185)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12058x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000096)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:18:42 (running for 00:08:35.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     97 |          500.741 | 388000 |           -383.27 |        -52.6131 |            -76.6024 |            -75.0957 |        -178.959 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=392000.0,env_runners/episode_return_mean=-382.99364956644 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000097)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11954x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000097)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:18:47,287 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.5544 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:18:47 (running for 00:08:40.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     98 |          505.949 | 392000 |          -382.994 |        -53.3288 |            -75.5588 |            -75.7453 |        -178.361 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=396000.0,env_runners/episode_return_mean=-381.7385861926412 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000098)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000098)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:18:52 (running for 00:08:45.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |     99 |          511.204 | 396000 |          -381.739 |        -52.6745 |            -75.5483 |            -76.3665 |        -177.149 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=400000.0,env_runners/episode_return_mean=-387.3309983735338 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000099)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000099)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:18:57,292 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.5269 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:18:58 (running for 00:08:50.37)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    100 |          516.792 | 400000 |          -387.331 |        -52.3432 |            -78.1022 |             -76.892 |        -179.994 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000100)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000100)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:19:03 (running for 00:08:55.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    101 |          521.729 | 404000 |          -386.701 |        -51.7612 |            -77.9303 |            -75.9556 |        -181.054 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:19:07,297 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.5114 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=408000.0,env_runners/episode_return_mean=-384.5234978797451 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000101)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11916x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000101)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:19:08 (running for 00:09:00.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    102 |          527.257 | 408000 |          -384.523 |        -51.8141 |            -76.6423 |             -75.255 |        -180.812 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=412000.0,env_runners/episode_return_mean=-384.0887883984795 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
== Status ==
Current time: 2025-07-01 23:19:13 (running for 00:09:05.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    103 |          532.774 | 412000 |          -384.089 |        -51.9629 |            -77.1673 |            -73.8465 |        -181.112 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000102)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12211x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000102)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:19:17,302 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.483 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:19:18 (running for 00:09:10.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    103 |          532.774 | 412000 |          -384.089 |        -51.9629 |            -77.1673 |            -73.8465 |        -181.112 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=416000.0,env_runners/episode_return_mean=-382.9742691197249 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000103)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11993x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000103)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:19:23 (running for 00:09:15.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    104 |           538.16 | 416000 |          -382.974 |        -50.8251 |            -77.4188 |            -73.0284 |        -181.702 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=420000.0,env_runners/episode_return_mean=-379.8727885014803 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000104)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000104)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:19:27,307 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.4487 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:19:28 (running for 00:09:20.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    105 |           543.42 | 420000 |          -379.873 |        -49.7254 |            -77.4193 |             -71.761 |        -180.967 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=424000.0,env_runners/episode_return_mean=-379.3877502825594 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000105)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11960x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000105)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:19:33 (running for 00:09:25.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    106 |          548.714 | 424000 |          -379.388 |        -49.8695 |            -75.1735 |            -71.3401 |        -183.005 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=428000.0,env_runners/episode_return_mean=-380.3365857545541 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000106)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11908x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000106)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not p
[36m(MultiAgentEnvRunner pid=3374185)[0m rovided, returning only distance and velocity values
[33m(raylet)[0m [2025-07-01 23:19:37,313 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.4203 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:19:38 (running for 00:09:30.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    107 |          553.929 | 428000 |          -380.337 |        -49.3478 |            -75.0149 |            -70.3163 |        -185.658 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=432000.0,env_runners/episode_return_mean=-378.58961343269533 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000107)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11987x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000107)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:19:43 (running for 00:09:35.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    108 |           559.34 | 432000 |           -378.59 |        -49.0771 |            -74.9957 |            -67.1494 |        -187.368 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=436000.0,env_runners/episode_return_mean=-378.0803027079106 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000108)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12180x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000108)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:19:47,318 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.3924 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:19:48 (running for 00:09:40.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    109 |          564.455 | 436000 |           -378.08 |        -48.5344 |            -74.7165 |            -67.9737 |        -186.856 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=440000.0,env_runners/episode_return_mean=-379.9726386021824 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000109)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11928x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000109)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but type
[36m(MultiAgentEnvRunner pid=3374185)[0m s or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-01 23:19:53 (running for 00:09:45.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    110 |          570.076 | 440000 |          -379.973 |         -47.634 |            -75.6151 |            -66.8095 |        -189.914 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=444000.0,env_runners/episode_return_mean=-383.7417330856624 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000110)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12035x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000110)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:19:57,323 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.3703 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:19:58 (running for 00:09:50.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    111 |          575.444 | 444000 |          -383.742 |        -47.7895 |            -76.7509 |            -66.5081 |        -192.693 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=448000.0,env_runners/episode_return_mean=-382.2692963071796 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000111)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000111)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:20:03 (running for 00:09:55.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    112 |          580.944 | 448000 |          -382.269 |        -48.0443 |            -76.3194 |            -64.7667 |        -193.139 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=452000.0,env_runners/episode_return_mean=-389.4075765219168 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000112)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12048x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000112)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:20:07,328 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.3422 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:20:08 (running for 00:10:01.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    113 |           586.32 | 452000 |          -389.408 |        -48.1555 |            -75.7537 |            -67.8215 |        -197.677 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000113)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000113)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12612x across cluster][0m
== Status ==
Current time: 2025-07-01 23:20:13 (running for 00:10:06.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    114 |          591.166 | 456000 |          -390.433 |        -48.6861 |             -75.711 |            -65.8414 |        -200.195 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:20:17,333 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.3265 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=460000.0,env_runners/episode_return_mean=-389.9366449856692 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000114)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11448x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000114)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:20:18 (running for 00:10:11.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    115 |          596.769 | 460000 |          -389.937 |        -49.3915 |            -75.6021 |            -64.5093 |        -200.434 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=464000.0,env_runners/episode_return_mean=-389.2628917629055 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000115)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11964x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000115)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:20:23 (running for 00:10:16.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    116 |          602.056 | 464000 |          -389.263 |        -49.0264 |            -74.4291 |            -64.2421 |        -201.565 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
[33m(raylet)[0m [2025-07-01 23:20:27,338 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.2983 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=468000.0,env_runners/episode_return_mean=-391.0051451795816 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000116)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12036x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000116)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:20:28 (running for 00:10:21.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    117 |          607.346 | 468000 |          -391.005 |         -49.572 |            -73.3855 |            -65.3067 |        -202.741 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=472000.0,env_runners/episode_return_mean=-391.7384078208246 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000117)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12132x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000117)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:20:33 (running for 00:10:26.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    118 |          612.471 | 472000 |          -391.738 |        -50.1916 |            -73.3405 |             -64.358 |        -203.848 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:20:37,343 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.2702 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=476000.0,env_runners/episode_return_mean=-395.00607998691635 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000118)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11988x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000118)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:20:39 (running for 00:10:31.37)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    119 |          617.682 | 476000 |          -395.006 |         -50.325 |            -74.5453 |            -66.1222 |        -204.014 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=480000.0,env_runners/episode_return_mean=-398.2716213902799 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
== Status ==
Current time: 2025-07-01 23:20:44 (running for 00:10:36.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    120 |          622.827 | 480000 |          -398.272 |        -52.0591 |            -73.8624 |            -66.8531 |        -205.497 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000119)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12130x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000119)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:20:47,348 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.2358 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:20:49 (running for 00:10:41.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    120 |          622.827 | 480000 |          -398.272 |        -52.0591 |            -73.8624 |            -66.8531 |        -205.497 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=484000.0,env_runners/episode_return_mean=-398.24247998180203 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000120)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11954x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000120)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:20:54 (running for 00:10:46.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    121 |          628.031 | 484000 |          -398.242 |        -51.4985 |            -73.8896 |            -67.3725 |        -205.482 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=488000.0,env_runners/episode_return_mean=-395.50412345250095 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000121)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000121)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:20:57,353 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.2075 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:20:59 (running for 00:10:51.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    122 |          633.204 | 488000 |          -395.504 |        -50.8925 |            -72.9984 |            -67.8757 |        -203.737 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=492000.0,env_runners/episode_return_mean=-395.3042350400296 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000122)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12040x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000122)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:21:04 (running for 00:10:56.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    123 |          638.568 | 492000 |          -395.304 |        -50.7335 |            -73.3418 |            -67.0657 |        -204.163 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=496000.0,env_runners/episode_return_mean=-395.292381561869 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000123)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12032x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000123)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:21:07,358 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.1849 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:21:09 (running for 00:11:01.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    124 |          643.833 | 496000 |          -395.292 |        -51.2038 |            -72.4506 |             -67.277 |        -204.361 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=500000.0,env_runners/episode_return_mean=-395.0680275168722 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000124)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12036x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000124)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:21:14 (running for 00:11:06.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    125 |          649.101 | 500000 |          -395.068 |        -51.3833 |            -70.6488 |            -69.3806 |        -203.655 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=504000.0,env_runners/episode_return_mean=-395.5229524310383 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000125)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000125)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:21:17,363 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.1507 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:21:19 (running for 00:11:11.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    126 |          654.318 | 504000 |          -395.523 |        -51.2758 |            -69.2252 |            -69.1391 |        -205.883 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=508000.0,env_runners/episode_return_mean=-395.04112828532413 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000126)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000126)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:21:24 (running for 00:11:16.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    127 |          659.595 | 508000 |          -395.041 |        -50.0035 |             -69.274 |            -69.0168 |        -206.747 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=512000.0,env_runners/episode_return_mean=-394.18891832397406 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000127)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11990x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000127)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:21:27,368 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.1286 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:21:29 (running for 00:11:21.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    128 |          664.778 | 512000 |          -394.189 |        -49.8192 |            -69.2236 |            -71.8379 |        -203.308 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=516000.0,env_runners/episode_return_mean=-390.52928400005953 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000128)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12094x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000128)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:21:34 (running for 00:11:27.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    129 |          670.149 | 516000 |          -390.529 |        -50.4684 |            -67.4125 |            -70.6065 |        -202.042 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=520000.0,env_runners/episode_return_mean=-390.6876677093192 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[33m(raylet)[0m [2025-07-01 23:21:37,373 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.1134 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000129)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11997x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000129)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:21:39 (running for 00:11:32.13)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    130 |          675.622 | 520000 |          -390.688 |        -50.2001 |             -67.096 |            -70.2993 |        -203.092 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=524000.0,env_runners/episode_return_mean=-389.6162087584299 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000130)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11943x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000130)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:21:44 (running for 00:11:37.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    131 |          680.606 | 524000 |          -389.616 |         -50.283 |            -68.9569 |            -69.7812 |        -200.595 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:21:47,378 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.0853 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=528000.0,env_runners/episode_return_mean=-383.56580941328866 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000131)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12168x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000131)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:21:49 (running for 00:11:42.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    132 |          686.057 | 528000 |          -383.566 |        -50.5632 |             -65.832 |             -70.549 |        -196.622 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=532000.0,env_runners/episode_return_mean=-386.2948949424717 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000132)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11964x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000132)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:21:54 (running for 00:11:47.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    133 |          691.547 | 532000 |          -386.295 |        -51.0088 |            -65.1312 |            -71.9674 |        -198.188 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:21:57,383 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.057 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=536000.0,env_runners/episode_return_mean=-383.37049185231126 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000133)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11952x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000133)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:21:59 (running for 00:11:52.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    134 |          697.457 | 536000 |           -383.37 |        -52.5696 |            -65.1903 |             -68.622 |        -196.989 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


== Status ==
Current time: 2025-07-01 23:22:04 (running for 00:11:57.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    134 |          697.457 | 536000 |           -383.37 |        -52.5696 |            -65.1903 |             -68.622 |        -196.989 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=540000.0,env_runners/episode_return_mean=-381.3354593472209 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000134)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12096x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000134)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:22:07,388 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.0229 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:22:09 (running for 00:12:02.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    135 |          703.112 | 540000 |          -381.335 |        -53.1816 |            -65.2272 |            -68.0848 |        -194.842 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=544000.0,env_runners/episode_return_mean=-377.25465909938373 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000135)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12027x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000135)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:22:14 (running for 00:12:07.37)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    136 |          708.804 | 544000 |          -377.255 |        -53.7403 |            -62.7393 |            -66.8947 |         -193.88 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=548000.0,env_runners/episode_return_mean=-377.69838689164055 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000136)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12117x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000136)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:22:17,393 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 14.0007 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:22:20 (running for 00:12:12.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    137 |          714.243 | 548000 |          -377.698 |        -54.2545 |            -62.4677 |            -67.0223 |        -193.954 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=552000.0,env_runners/episode_return_mean=-373.1882948899354 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000137)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11808x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000137)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:22:25 (running for 00:12:17.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    138 |          719.842 | 552000 |          -373.188 |        -53.2317 |            -61.5484 |            -66.9889 |        -191.419 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:22:27,398 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.9852 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=556000.0,env_runners/episode_return_mean=-373.62811490880154 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000138)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12196x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000138)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:22:30 (running for 00:12:22.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    139 |          725.753 | 556000 |          -373.628 |        -53.0133 |            -60.1165 |            -69.2512 |        -191.247 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=560000.0,env_runners/episode_return_mean=-374.94994275724565 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000139)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11852x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000139)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:22:35 (running for 00:12:27.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    140 |          731.635 | 560000 |           -374.95 |        -52.9774 |            -60.3208 |            -69.7077 |        -191.944 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:22:37,404 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.9508 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


== Status ==
Current time: 2025-07-01 23:22:40 (running for 00:12:32.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    140 |          731.635 | 560000 |           -374.95 |        -52.9774 |            -60.3208 |            -69.7077 |        -191.944 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=564000.0,env_runners/episode_return_mean=-373.8733915417349 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000140)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12168x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000140)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:22:45 (running for 00:12:37.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    141 |          737.846 | 564000 |          -373.873 |        -54.6046 |            -61.4399 |            -69.2685 |         -188.56 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=568000.0,env_runners/episode_return_mean=-372.8753281692165 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000141)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000141)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:22:47,410 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.9294 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:22:50 (running for 00:12:42.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    142 |          743.672 | 568000 |          -372.875 |        -53.2886 |            -61.9973 |            -70.7006 |        -186.889 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=572000.0,env_runners/episode_return_mean=-369.7686077187329 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000142)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000142)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:22:55 (running for 00:12:47.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    143 |          749.224 | 572000 |          -369.769 |        -50.8205 |            -61.7795 |            -72.7115 |        -184.457 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:22:57,415 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.9142 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=576000.0,env_runners/episode_return_mean=-364.62370194887575 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000143)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11916x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000143)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:23:00 (running for 00:12:52.79)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    144 |          755.059 | 576000 |          -364.624 |        -51.2399 |            -61.4102 |            -69.5615 |        -182.412 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=580000.0,env_runners/episode_return_mean=-358.36567889054305 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000144)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000144)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:23:05 (running for 00:12:57.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    145 |          760.158 | 580000 |          -358.366 |        -49.7532 |            -60.4784 |            -67.2515 |        -180.883 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:23:07,420 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.8859 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=584000.0,env_runners/episode_return_mean=-356.20630539504754 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000145)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000145)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:23:10 (running for 00:13:02.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    146 |          765.453 | 584000 |          -356.206 |        -49.5695 |            -60.5553 |            -66.7873 |        -179.294 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=588000.0,env_runners/episode_return_mean=-353.24218222237226 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000146)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000146)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:23:15 (running for 00:13:07.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    147 |          771.104 | 588000 |          -353.242 |        -48.8015 |            -59.1694 |            -66.5259 |        -178.745 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:23:17,425 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.8513 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=592000.0,env_runners/episode_return_mean=-353.97458616399456 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000147)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000147)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:23:20 (running for 00:13:12.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    148 |          776.848 | 592000 |          -353.975 |        -48.6302 |            -59.3154 |            -66.4864 |        -179.543 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=596000.0,env_runners/episode_return_mean=-353.3101853754309 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000148)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12026x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000148)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:23:25 (running for 00:13:18.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    149 |          782.372 | 596000 |           -353.31 |         -49.484 |            -58.3078 |            -64.0419 |        -181.477 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:23:27,430 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.8235 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=600000.0,env_runners/episode_return_mean=-354.42978337836604 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
== Status ==
Current time: 2025-07-01 23:23:30 (running for 00:13:23.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    150 |          787.694 | 600000 |           -354.43 |        -48.7484 |            -58.6665 |             -64.761 |        -182.254 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000149)


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12115x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000149)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:23:35 (running for 00:13:28.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    150 |          787.694 | 600000 |           -354.43 |        -48.7484 |            -58.6665 |             -64.761 |        -182.254 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=604000.0,env_runners/episode_return_mean=-352.9468591775748 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000150)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12135x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000150)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:23:37,436 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.7955 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:23:40 (running for 00:13:33.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    151 |          792.852 | 604000 |          -352.947 |        -48.0541 |            -58.4987 |            -66.3541 |         -180.04 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=608000.0,env_runners/episode_return_mean=-357.36622950187643 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000151)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11935x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000151)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:23:45 (running for 00:13:38.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    152 |          797.957 | 608000 |          -357.366 |        -48.9022 |            -58.9304 |            -68.1367 |        -181.397 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=612000.0,env_runners/episode_return_mean=-359.6105712587827 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000152)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12029x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000152)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:23:47,440 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.7734 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:23:50 (running for 00:13:43.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    153 |          803.123 | 612000 |          -359.611 |         -50.668 |            -56.9911 |            -65.8033 |        -186.148 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=616000.0,env_runners/episode_return_mean=-362.32590928758555 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000153)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11871x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000153)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:23:55 (running for 00:13:48.33)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    154 |          808.267 | 616000 |          -362.326 |        -50.6104 |            -58.0869 |            -66.6041 |        -187.024 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000154)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000154)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12453x across cluster][0m
[33m(raylet)[0m [2025-07-01 23:23:57,445 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.7455 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:24:00 (running for 00:13:53.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    155 |          813.115 | 620000 |          -363.354 |        -51.4451 |            -58.7026 |            -65.6465 |         -187.56 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=624000.0,env_runners/episode_return_mean=-360.64221926918947 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000155)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11820x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000155)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:24:06 (running for 00:13:58.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    156 |          818.362 | 624000 |          -360.642 |        -50.8513 |            -57.0151 |            -64.7031 |        -188.073 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=628000.0,env_runners/episode_return_mean=-362.8613986590102 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000156)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11862x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000156)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:24:07,449 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.717 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:24:11 (running for 00:14:03.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    157 |          823.494 | 628000 |          -362.861 |        -51.2396 |             -58.971 |            -64.8356 |        -187.815 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=632000.0,env_runners/episode_return_mean=-360.15103370125865 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000157)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12187x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000157)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:24:16 (running for 00:14:08.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    158 |          828.793 | 632000 |          -360.151 |        -50.5367 |            -58.9327 |            -62.4397 |        -188.242 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:24:17,454 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.7015 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=636000.0,env_runners/episode_return_mean=-360.86860888933626 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000158)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11963x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000158)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:24:21 (running for 00:14:13.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    159 |           834.18 | 636000 |          -360.869 |        -50.8493 |            -57.6317 |            -62.4376 |         -189.95 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=640000.0,env_runners/episode_return_mean=-359.05373619321864 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000159)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12096x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000159)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:24:26 (running for 00:14:18.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    160 |          839.422 | 640000 |          -359.054 |        -50.5002 |            -56.4302 |             -63.593 |         -188.53 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:24:27,459 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.6729 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=644000.0,env_runners/episode_return_mean=-359.6874438554967 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000160)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11808x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000160)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:24:31 (running for 00:14:23.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    161 |          844.787 | 644000 |          -359.687 |        -49.0853 |            -57.2885 |             -64.869 |        -188.445 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=648000.0,env_runners/episode_return_mean=-355.4938071147889 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000161)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12216x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000161)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:24:36 (running for 00:14:28.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    162 |          850.287 | 648000 |          -355.494 |        -48.6775 |            -56.1277 |            -64.0001 |        -186.688 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:24:37,464 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.6387 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=652000.0,env_runners/episode_return_mean=-360.6756016079412 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000162)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11868x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000162)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:24:41 (running for 00:14:33.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    163 |          855.515 | 652000 |          -360.676 |        -49.4411 |            -55.9129 |            -65.2821 |        -190.039 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=656000.0,env_runners/episode_return_mean=-361.0758099337119 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000163)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12190x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000163)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:24:46 (running for 00:14:38.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    164 |          860.615 | 656000 |          -361.076 |        -48.9966 |            -56.2969 |            -64.9912 |        -190.791 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:24:47,469 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.6105 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=660000.0,env_runners/episode_return_mean=-360.9507979123907 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000164)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11930x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000164)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:24:51 (running for 00:14:43.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    165 |           865.82 | 660000 |          -360.951 |        -48.6041 |            -55.6045 |            -66.2872 |        -190.455 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=664000.0,env_runners/episode_return_mean=-359.8832468976208 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000165)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11904x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000165)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:24:56 (running for 00:14:48.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    166 |          870.932 | 664000 |          -359.883 |        -47.1703 |            -55.1618 |            -65.9312 |         -191.62 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:24:57,474 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.582 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=668000.0,env_runners/episode_return_mean=-355.66615783693624 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000166)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12144x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000166)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:25:01 (running for 00:14:53.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    167 |          876.175 | 668000 |          -355.666 |        -47.0212 |            -54.4889 |            -62.5174 |        -191.639 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000167)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000167)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12574x across cluster][0m
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:25:06 (running for 00:14:58.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    168 |          881.028 | 672000 |          -354.854 |        -48.1344 |            -53.6564 |            -60.1386 |        -192.924 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:25:07,478 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.5536 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=676000.0,env_runners/episode_return_mean=-356.7257657899091 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000168)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11364x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000168)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374186)[0m
== Status ==
Current time: 2025-07-01 23:25:11 (running for 00:15:04.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    169 |           886.26 | 676000 |          -356.726 |        -46.9828 |            -51.5452 |            -62.7611 |        -195.437 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000169)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000169)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12686x across cluster][0m
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:25:16 (running for 00:15:09.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    170 |          891.078 | 680000 |          -357.885 |        -47.9422 |            -51.2612 |            -63.4658 |        -195.216 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
[33m(raylet)[0m [2025-07-01 23:25:17,483 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.5249 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=684000.0,env_runners/episode_return_mean=-359.6120114818879 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000170)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11568x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000170)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:25:21 (running for 00:15:14.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    171 |          896.339 | 684000 |          -359.612 |        -48.7074 |             -48.934 |            -62.8213 |        -199.149 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=688000.0,env_runners/episode_return_mean=-361.1980731274362 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000171)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11856x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000171)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:25:26 (running for 00:15:19.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    172 |          901.476 | 688000 |          -361.198 |        -50.4548 |            -48.8849 |             -63.441 |        -198.417 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:25:27,488 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.497 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=692000.0,env_runners/episode_return_mean=-361.3245610513175 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000172)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11989x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000172)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:25:31 (running for 00:15:24.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    173 |           906.58 | 692000 |          -361.325 |        -50.6361 |            -48.5086 |            -63.8617 |        -198.318 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=696000.0,env_runners/episode_return_mean=-360.99658790689136 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000173)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12143x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000173)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:25:36 (running for 00:15:29.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    174 |          911.728 | 696000 |          -360.997 |        -49.5097 |            -48.7424 |             -65.677 |        -197.068 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:25:37,493 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.4687 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=700000.0,env_runners/episode_return_mean=-359.5694730007817 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000174)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000174)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:25:41 (running for 00:15:34.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    175 |          916.876 | 700000 |          -359.569 |        -50.3566 |            -47.9661 |            -63.0056 |        -198.241 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000175)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000175)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12888x across cluster][0m
== Status ==
Current time: 2025-07-01 23:25:46 (running for 00:15:39.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    176 |          921.692 | 704000 |          -362.093 |        -50.9579 |             -47.937 |            -63.4032 |        -199.795 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:25:47,498 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.4406 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=708000.0,env_runners/episode_return_mean=-355.49748048583234 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000176)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11051x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000176)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:25:52 (running for 00:15:44.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    177 |           926.87 | 708000 |          -355.497 |        -48.6189 |            -46.6824 |            -62.4322 |        -197.764 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374185)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=712000.0,env_runners/episode_return_mean=-352.61116434367125 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000177)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12013x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000177)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:25:57 (running for 00:15:49.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    178 |          932.024 | 712000 |          -352.611 |        -47.1579 |            -47.0764 |            -60.9858 |        -197.391 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:25:57,503 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.4183 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=716000.0,env_runners/episode_return_mean=-353.17860716836054 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000178)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12132x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000178)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:26:02 (running for 00:15:54.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    179 |          937.078 | 716000 |          -353.179 |        -46.7842 |            -44.6885 |            -62.6128 |        -199.093 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


[36m(MultiAgentEnvRunner pid=3374186)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=720000.0,env_runners/episode_return_mean=-352.1983860353468 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000179)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11904x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000179)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
== Status ==
Current time: 2025-07-01 23:26:07 (running for 00:15:59.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    180 |          942.227 | 720000 |          -352.198 |        -45.5363 |            -42.5092 |            -65.3839 |        -198.769 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:26:07,508 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.3897 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=724000.0,env_runners/episode_return_mean=-352.5635058383494 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000180)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12150x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000180)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:26:12 (running for 00:16:04.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    181 |          947.372 | 724000 |          -352.564 |        -45.5886 |            -42.5478 |            -66.1864 |        -198.241 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000181)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000181)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12450x across cluster][0m
== Status ==
Current time: 2025-07-01 23:26:17 (running for 00:16:09.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    182 |          952.244 | 728000 |          -352.824 |        -45.4724 |            -41.6655 |            -66.0847 |        -199.601 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[33m(raylet)[0m [2025-07-01 23:26:17,513 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.3614 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


[36m(MultiAgentEnvRunner pid=3374186)[0m
Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=732000.0,env_runners/episode_return_mean=-348.7804771113791 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000182)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11556x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000182)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:26:22 (running for 00:16:14.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    183 |          957.533 | 732000 |           -348.78 |        -45.4436 |            -41.3797 |            -66.6999 |        -195.257 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


== Status ==
Current time: 2025-07-01 23:26:27 (running for 00:16:19.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    183 |          957.533 | 732000 |           -348.78 |        -45.4436 |            -41.3797 |            -66.6999 |        -195.257 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=736000.0,env_runners/episode_return_mean=-347.87790796376123 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[33m(raylet)[0m [2025-07-01 23:26:27,517 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.3463 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000183)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12046x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000183)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:26:32 (running for 00:16:24.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    184 |          962.788 | 736000 |          -347.878 |        -46.5448 |            -40.3338 |            -68.6866 |        -192.313 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=740000.0,env_runners/episode_return_mean=-348.35714827091346 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000184)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000184)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12218x across cluster][0m
[33m(raylet)[0m [2025-07-01 23:26:37,522 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.3187 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:26:37 (running for 00:16:29.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    185 |          967.747 | 740000 |          -348.357 |        -46.5511 |            -38.8923 |            -68.9849 |        -193.929 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=744000.0,env_runners/episode_return_mean=-349.2613087988642 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000185)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11731x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000185)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:26:42 (running for 00:16:34.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    186 |          973.014 | 744000 |          -349.261 |        -47.6182 |            -38.5873 |            -67.9776 |        -195.078 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=748000.0,env_runners/episode_return_mean=-352.1476577302085 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000186)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12113x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000186)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:26:47,527 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.2906 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:26:47 (running for 00:16:40.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    187 |          978.159 | 748000 |          -352.148 |        -47.4822 |            -37.8691 |            -70.0953 |        -196.701 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=752000.0,env_runners/episode_return_mean=-346.8926653265072 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000187)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11952x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000187)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:26:52 (running for 00:16:45.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    188 |          983.263 | 752000 |          -346.893 |        -47.2163 |            -37.5627 |            -68.1488 |        -193.965 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=756000.0,env_runners/episode_return_mean=-344.89957819974427 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000188)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000188)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:26:57,532 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.2623 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:26:57 (running for 00:16:50.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    189 |          988.482 | 756000 |            -344.9 |        -46.6103 |            -36.4446 |            -67.6499 |        -194.195 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=760000.0,env_runners/episode_return_mean=-342.7013043915786 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000189)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12240x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000189)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provi
[36m(MultiAgentEnvRunner pid=3374185)[0m ded, returning only distance and velocity values
== Status ==
Current time: 2025-07-01 23:27:02 (running for 00:16:55.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    190 |          993.669 | 760000 |          -342.701 |        -47.1844 |            -34.8947 |            -65.4437 |        -195.178 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=764000.0,env_runners/episode_return_mean=-344.8389547840359 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000190)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11855x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000190)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3374185)[0m
[33m(raylet)[0m [2025-07-01 23:27:07,537 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.2274 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:27:07 (running for 00:17:00.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    191 |          998.824 | 764000 |          -344.839 |        -47.4786 |            -34.2741 |            -67.7726 |        -195.314 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=768000.0,env_runners/episode_return_mean=-347.81684426425943 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000191)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000191)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:27:12 (running for 00:17:05.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    192 |          1004.01 | 768000 |          -347.817 |        -47.6655 |            -34.0154 |            -69.7828 |        -196.353 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000192)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000192)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12609x across cluster][0m
[33m(raylet)[0m [2025-07-01 23:27:17,541 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.1992 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:27:18 (running for 00:17:10.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    193 |          1008.85 | 772000 |          -346.486 |        -49.0228 |            -33.6735 |            -68.4358 |        -195.354 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=776000.0,env_runners/episode_return_mean=-345.96199500451314 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000193)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11403x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000193)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:27:23 (running for 00:17:15.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    194 |          1014.07 | 776000 |          -345.962 |        -50.6631 |             -33.586 |             -66.514 |        -195.199 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=780000.0,env_runners/episode_return_mean=-342.1731043586322 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000194)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12070x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000194)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:27:27,546 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.1711 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:27:28 (running for 00:17:20.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    195 |          1019.33 | 780000 |          -342.173 |        -50.8854 |            -32.7549 |            -66.0106 |        -192.522 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=784000.0,env_runners/episode_return_mean=-343.5569546100529 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000195)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11930x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000195)...
[36m(_WandbLoggingActor pid=3374356)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 23:27:33 (running for 00:17:25.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    196 |          1024.53 | 784000 |          -343.557 |        -49.3045 |            -34.6525 |            -67.5468 |        -192.053 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=788000.0,env_runners/episode_return_mean=-347.02579976196137 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000196)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12048x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000196)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:27:37,552 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.1428 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:27:38 (running for 00:17:30.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    197 |           1029.7 | 788000 |          -347.026 |        -48.6445 |            -35.1886 |            -69.0757 |        -194.117 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=792000.0,env_runners/episode_return_mean=-344.1924290115702 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000197)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12048x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000197)... Done. 0.0s
== Status ==
Current time: 2025-07-01 23:27:43 (running for 00:17:35.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    198 |          1034.77 | 792000 |          -344.192 |        -47.6769 |            -34.2824 |            -67.6388 |        -194.594 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=796000.0,env_runners/episode_return_mean=-343.85591258592683 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000198)
[36m(MultiAgentEnvRunner pid=3374185)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12192x across cluster][0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000198)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 23:27:47,557 E 3372377 3372407] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886 is over 95% full, available space: 13.1147 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 23:27:48 (running for 00:17:40.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | RUNNING  | 192.168.0.25:3373861 |    199 |          1039.89 | 796000 |          -343.856 |        -48.7747 |            -33.7281 |             -65.305 |        -196.048 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+


Trial PPO_env_17aba_00000 reported env_runners/episode_len_mean=2000.0,num_env_steps_sampled_lifetime=800000.0,env_runners/episode_return_mean=-343.16396334286225 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3373861)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000199)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_23-10-07/PPO_env_17aba_00000_0_2025-07-01_23-10-07/checkpoint_000199)... Done. 0.0s
2025-07-01 23:27:50,779	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-07-01_23-10-07' in 0.0955s.
== Status ==
Current time: 2025-07-01 23:27:50 (running for 00:17:43.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_23-10-06_506274_3371886/artifacts/2025-07-01_23-10-07/PPO_2025-07-01_23-10-07/driver_artifacts
Number of trials: 1/1 (1 TERMINATED)
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
| Trial name          | status     | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return predator_0 |   return predator_1 |   return prey_1 |
|---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------|
| PPO_env_17aba_00000 | TERMINATED | 192.168.0.25:3373861 |    200 |          1045.09 | 800000 |          -343.164 |        -47.0185 |            -34.3519 |            -66.4988 |        -195.295 |
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+---------------------+---------------------+-----------------+
[36m(_WandbLoggingActor pid=3374356)[0m wandb: uploading artifact checkpoint_PPO_env_17aba_00000
2025-07-01 23:27:54,536	INFO tune.py:1041 -- Total run time: 1066.92 seconds (1063.05 seconds for the tuning loop).
[36m(_WandbLoggingActor pid=3374356)[0m wandb:
[36m(_WandbLoggingActor pid=3374356)[0m wandb:
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Run history:
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    env_runners/agent_steps/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    env_runners/agent_steps/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/agent_steps/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/agent_steps/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  env_runners/connector_pipeline_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           env_runners/env_reset_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ


ËÆ≠ÁªÉÂÆåÊàê
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            env_runners/env_step_timer ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 env_runners/episode_duration_sec_mean ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           env_runners/episode_len_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                          env_runners/episode_len_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           env_runners/episode_len_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/episode_return_max ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                       env_runners/episode_return_mean ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/episode_return_min ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñá‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÇ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñá‚ñá‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     env_runners/num_env_steps_sampled ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                              env_runners/num_episodes ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     env_runners/num_episodes_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  env_runners/rlmodule_inference_timer ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                    env_runners/sample ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     env_runners/time_between_sampling ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[0m
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            env_runners/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                   fault_tolerance/num_healthy_workers ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                              iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_0/entropy ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÖ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/predator_0/mean_kl_loss ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                       learners/predator_0/policy_loss ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/predator_0/total_loss ‚ñÜ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  learners/predator_0/vf_explained_var ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_0/vf_loss ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/predator_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÇ‚ñÖ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_1/entropy ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/predator_1/mean_kl_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                       learners/predator_1/policy_loss ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/predator_1/total_loss ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  learners/predator_1/vf_explained_var ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñà‚ñÉ‚ñá‚ñÖ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_1/vf_loss ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/predator_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_0/entropy ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñÖ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñá‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                          learners/prey_0/mean_kl_loss ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/prey_0/policy_loss ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            learners/prey_0/total_loss ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/prey_0/vf_explained_var ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÉ‚ñá‚ñÅ‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_0/vf_loss ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/prey_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_1/entropy ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÅ‚ñá‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñá‚ñà‚ñÖ‚ñá‚ñà‚ñÇ‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                          learners/prey_1/mean_kl_loss ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/prey_1/policy_loss ‚ñà‚ñÜ‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            learners/prey_1/total_loss ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/prey_1/vf_explained_var ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñà‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÉ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_1/vf_loss ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñá‚ñá‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÉ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñà‚ñÇ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñÇ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/prey_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 num_training_step_calls_per_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                 perf/cpu_util_percent ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                 perf/ram_util_percent ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                    time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                      time_this_iter_s ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                          time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      timers/env_runner_sampling_timer ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           timers/learner_update_timer ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            timers/restore_env_runners ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           timers/synch_env_connectors ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                  timers/synch_weights ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                             timers/training_iteration ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                  timers/training_step ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                             timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                    training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3374356)[0m wandb:
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Run summary:
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 -34.35193
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 -66.49882
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 -47.01845
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 -195.29476
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    env_runners/agent_steps/predator_0 500
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    env_runners/agent_steps/predator_1 500
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/agent_steps/prey_0 500
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/agent_steps/prey_1 500
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.00039
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           env_runners/env_reset_timer 0.0027
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            env_runners/env_step_timer 0.00046
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00013
[36m(_WandbLoggingActor pid=3374356)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 3e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 1881.0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 1881.0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 env_runners/episode_duration_sec_mean 2.32551
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           env_runners/episode_len_max 2000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                          env_runners/episode_len_mean 2000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           env_runners/episode_len_min 2000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/episode_return_max -212.32067
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                       env_runners/episode_return_mean -343.16396
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        env_runners/episode_return_min -468.03089
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 -34.35193
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 -66.49882
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 -47.01845
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 -195.29476
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00026
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 0.0001
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 4e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 200000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 200400
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 200400
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 200400
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 800000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 1066.37274
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                              env_runners/num_episodes 2
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     env_runners/num_episodes_lifetime 400
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 200000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 200400
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 200400
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 200400
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.00014
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                    env_runners/sample 2.39698
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     env_runners/time_between_sampling 3.20318
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 4e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 3e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 7e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            env_runners/weights_seq_no 199
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                              iterations_since_restore 200
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.08229
[36m(_WandbLoggingActor pid=3374356)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03569
[36m(_WandbLoggingActor pid=3374356)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 8e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.00248
[36m(_WandbLoggingActor pid=3374356)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 3e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.00199
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.02958
[36m(_WandbLoggingActor pid=3374356)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.0108
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.00138
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 940000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 188000000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 356941.57697
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 120320
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 24064000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 1980575.61156
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 1949710.40292
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 517140
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 0.4871
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_0/entropy -1.01123
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 9.1452
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.00391
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 11422.41653
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_0/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                       learners/predator_0/policy_loss 0.14792
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/predator_0/total_loss 0.16202
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  learners/predator_0/vf_explained_var 0.49148
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_0/vf_loss 2.05746
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 4.28245
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/predator_0/weights_seq_no 200
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 1.33461
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_1/entropy 5.26361
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 9.44608
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.00865
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 11422.59603
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/predator_1/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                       learners/predator_1/policy_loss -0.149
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/predator_1/total_loss -0.10168
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                  learners/predator_1/vf_explained_var 0.16413
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/predator_1/vf_loss 7.15448
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 55.74588
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/predator_1/weights_seq_no 200
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 1.09597
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_0/entropy -2.1976
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 20.00668
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.01062
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 11422.22499
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_0/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/prey_0/policy_loss -0.04252
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            learners/prey_0/total_loss -0.00884
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/prey_0/vf_explained_var 0.09789
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_0/vf_loss 4.40763
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 26.76854
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/prey_0/weights_seq_no 200
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 0.62489
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_1/entropy 12.18077
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 0.4702
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.00222
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 11422.35316
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                              learners/prey_1/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           learners/prey_1/policy_loss 0.03951
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            learners/prey_1/total_loss 0.09157
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      learners/prey_1/vf_explained_var -0.06463
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                               learners/prey_1/vf_loss 9.85653
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 1090.94934
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        learners/prey_1/weights_seq_no 200
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                        num_env_steps_sampled_lifetime 800000
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                 num_training_step_calls_per_iteration 1
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                 perf/cpu_util_percent 14.11429
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                 perf/ram_util_percent 76.01429
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                    time_since_restore 1045.09069
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                      time_this_iter_s 5.19607
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                          time_total_s 1045.09069
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                      timers/env_runner_sampling_timer 2.42972
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           timers/learner_update_timer 2.87365
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                            timers/restore_env_runners 2e-05
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                           timers/synch_env_connectors 0.00157
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                  timers/synch_weights 0.00342
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                             timers/training_iteration 5.30758
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                  timers/training_step 5.30724
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                             timestamp 1751380070
[36m(_WandbLoggingActor pid=3374356)[0m wandb:                                                                                    training_iteration 200
[36m(_WandbLoggingActor pid=3374356)[0m wandb:
[36m(_WandbLoggingActor pid=3374356)[0m wandb: üöÄ View run PPO_env_17aba_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/17aba_00000
[36m(_WandbLoggingActor pid=3374356)[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 1427 artifact file(s) and 0 other file(s)
[36m(_WandbLoggingActor pid=3374356)[0m wandb: Find logs at: ./wandb/run-20250701_231015-17aba_00000/logs
