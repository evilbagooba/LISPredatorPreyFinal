['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-04 18:03:05,201	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-04 18:03:05,628	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-04 18:03:05 (running for 00:00:00.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_b2888_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=56037)[0m 2025-07-04 18:03:07,722	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
[36m(MultiAgentEnvRunner pid=56143)[0m 2025-07-04 18:03:09,937	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
[36m(PPO pid=56037)[0m Install gputil for GPU system monitoring.


== Status ==
Current time: 2025-07-04 18:03:10 (running for 00:00:05.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+
| Trial name          | status   | loc                |
|---------------------+----------+--------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |
+---------------------+----------+--------------------+
[36m(_WandbLoggingActor pid=56311)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(_WandbLoggingActor pid=56311)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=56311)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=56311)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=56311)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts/PPO_env_b2888_00000_0_2025-07-04_18-03-05/wandb/run-20250704_180313-b2888_00000
[36m(_WandbLoggingActor pid=56311)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=56311)[0m wandb: Syncing run PPO_env_b2888_00000
[36m(_WandbLoggingActor pid=56311)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=56311)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/b2888_00000


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=4000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-439.274615086837 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initi
== Status ==
Current time: 2025-07-04 18:03:17 (running for 00:00:11.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      1 |          4.96321 | 4000 |          -439.275 |            -82.4377 |        -193.205 |        -86.0227 |            -77.6095 |
+---------------------+----------+--------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000000)
[36m(PPO pid=56037)[0m 2025-07-04 18:03:10,005	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000000)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000001)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000001)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:22 (running for 00:00:16.67)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      2 |          9.79385 | 8000 |          -422.121 |            -77.8222 |        -190.925 |        -81.2996 |            -72.0739 |
+---------------------+----------+--------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=12000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-422.85627620842115 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000002)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000002)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:27 (running for 00:00:21.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      3 |          14.5115 | 12000 |          -422.856 |            -80.3836 |        -183.259 |         -78.772 |            -80.4416 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000003)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000003)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:32 (running for 00:00:26.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      4 |          19.2241 | 16000 |          -399.231 |            -63.5106 |        -186.957 |        -77.4125 |            -71.3508 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=20000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-378.5267508869001 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000004)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000004)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:37 (running for 00:00:31.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      5 |          23.8936 | 20000 |          -378.527 |            -51.3874 |        -192.204 |        -75.0847 |            -59.8506 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000005)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000005)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:42 (running for 00:00:36.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      6 |          28.4361 | 24000 |          -335.947 |            -23.6774 |        -195.953 |         -74.029 |            -42.2875 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=28000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-282.51727155437214 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000006)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:47 (running for 00:00:42.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      7 |          33.2515 | 28000 |          -282.517 |            -1.73222 |        -195.321 |        -73.4462 |            -12.0178 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000007)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000007)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:52 (running for 00:00:47.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      8 |          37.7742 | 32000 |          -262.374 |             8.20311 |        -191.761 |        -72.6433 |            -6.17262 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=36000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-250.98764536630682 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000008)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000008)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:03:57 (running for 00:00:52.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |      9 |           42.417 | 36000 |          -250.988 |             12.1015 |        -188.614 |        -72.9374 |            -1.53737 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000009)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000009)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:02 (running for 00:00:57.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     10 |          47.0536 | 40000 |          -242.964 |             13.0563 |        -185.527 |        -73.4324 |             2.93904 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=44000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-237.48537578204815 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000010)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000010)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:07 (running for 00:01:02.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     11 |          51.5823 | 44000 |          -237.485 |             13.8593 |        -183.807 |        -70.4908 |             2.95268 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000011)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000011)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:12 (running for 00:01:07.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     12 |          56.3459 | 48000 |          -232.522 |             16.4727 |        -184.125 |         -71.301 |             6.43191 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=52000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-227.31319574648208 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000012)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000012)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:17 (running for 00:01:12.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     13 |          60.9151 | 52000 |          -227.313 |             18.5466 |        -184.017 |        -70.8615 |             9.01861 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000013)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000013)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:22 (running for 00:01:17.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     14 |          65.5895 | 56000 |          -226.503 |             18.8286 |        -184.649 |        -71.2071 |             10.5244 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=60000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-220.02688690823297 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000014)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000014)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000015)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000015)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:28 (running for 00:01:22.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     16 |          74.8037 | 64000 |          -210.164 |              24.266 |        -184.685 |        -67.9362 |             18.1917 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=68000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-202.45691550952867 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000016)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000016)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:33 (running for 00:01:27.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     17 |          79.5401 | 68000 |          -202.457 |             29.5371 |        -185.263 |        -69.6687 |             22.9377 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000017)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000017)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:38 (running for 00:01:32.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     18 |          84.0461 | 72000 |          -199.679 |             31.5738 |        -185.543 |         -70.565 |              24.855 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=76000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-182.6282213915613 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000018)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000018)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:43 (running for 00:01:37.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     19 |          88.6543 | 76000 |          -182.628 |             39.9168 |        -183.882 |        -71.6155 |             32.9525 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000019)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000019)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:48 (running for 00:01:42.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     20 |           93.243 | 80000 |          -171.487 |             43.6727 |         -182.99 |        -72.6616 |             40.4917 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=84000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-166.40622680248904 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000020)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000020)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:53 (running for 00:01:47.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     21 |          97.7731 | 84000 |          -166.406 |             46.3159 |        -183.527 |          -72.08 |             42.8849 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000021)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000021)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:04:58 (running for 00:01:52.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     22 |          102.458 | 88000 |          -174.145 |             43.8483 |        -185.567 |        -72.6562 |             40.2299 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=92000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-170.6540060510275 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000022)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000022)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:03 (running for 00:01:57.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     23 |          107.003 | 92000 |          -170.654 |             47.8606 |        -187.284 |         -73.157 |             41.9261 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000023)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000023)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:08 (running for 00:02:02.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     24 |          111.543 | 96000 |          -166.763 |             49.5649 |        -188.941 |        -72.0928 |             44.7064 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=100000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-141.26603203532528 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000024)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000024)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:13 (running for 00:02:07.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     25 |          116.164 | 100000 |          -141.266 |              63.591 |        -190.164 |        -72.5217 |             57.8287 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000025)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000025)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:18 (running for 00:02:12.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     26 |          120.723 | 104000 |          -127.098 |             70.8428 |        -190.157 |        -72.5451 |             64.7616 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=108000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-109.44785182139714 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000026)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000026)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:23 (running for 00:02:18.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     27 |          125.582 | 108000 |          -109.448 |             81.1167 |        -190.122 |        -72.1052 |             71.6628 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000027)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000027)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=116000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-86.15227985246197 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000028)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000028)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:28 (running for 00:02:23.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     29 |           134.68 | 116000 |          -86.1523 |             93.4382 |          -192.4 |        -71.7054 |             84.5148 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000029)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000029)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:33 (running for 00:02:28.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     30 |           139.38 | 120000 |          -77.2397 |             98.2294 |        -192.874 |        -72.3514 |             89.7563 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=124000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-72.4966430103587 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000030)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000030)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:38 (running for 00:02:33.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     31 |           143.95 | 124000 |          -72.4966 |             99.1431 |        -191.663 |        -71.3048 |             91.3283 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000031)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000031)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:43 (running for 00:02:38.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     32 |          148.694 | 128000 |          -80.2238 |             96.3541 |        -192.163 |        -71.4156 |             87.0008 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=132000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-65.47851252879869 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000032)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000032)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:48 (running for 00:02:43.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     33 |          153.243 | 132000 |          -65.4785 |             103.836 |        -193.608 |        -72.5553 |             96.8492 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000033)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000033)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:53 (running for 00:02:48.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     34 |          157.775 | 136000 |          -64.9563 |             104.796 |         -195.23 |        -73.0783 |             98.5557 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=140000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-63.657784231821985 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000034)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000034)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:05:59 (running for 00:02:53.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     35 |          162.481 | 140000 |          -63.6578 |             107.066 |        -197.955 |        -73.0994 |             100.331 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000035)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000035)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:04 (running for 00:02:58.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     36 |          167.083 | 144000 |          -58.1495 |             107.856 |        -197.211 |         -74.948 |             106.153 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=148000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-53.90782503021499 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000036)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000036)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:09 (running for 00:03:03.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     37 |          171.761 | 148000 |          -53.9078 |             110.625 |        -197.887 |        -74.7014 |             108.055 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000037)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000037)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:14 (running for 00:03:08.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     38 |          176.337 | 152000 |          -19.4835 |             126.968 |        -197.065 |        -75.8022 |             126.416 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=156000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-12.541461990980551 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000038)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000038)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:19 (running for 00:03:13.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     39 |          180.923 | 156000 |          -12.5415 |             130.873 |        -196.127 |        -75.9361 |             128.648 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000039)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000039)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:24 (running for 00:03:18.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     40 |          185.624 | 160000 |            3.7152 |             139.099 |        -195.284 |        -77.1686 |             137.069 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=164000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=15.3739423662035 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000040)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000040)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000041)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000041)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:29 (running for 00:03:23.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     42 |          194.907 | 168000 |            11.134 |             143.867 |        -193.783 |        -77.2977 |             138.348 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=172000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=25.15272455873019 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000042)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000042)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:34 (running for 00:03:28.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     43 |          199.435 | 172000 |           25.1527 |              151.62 |        -193.554 |        -77.3089 |             144.395 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000043)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000043)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:39 (running for 00:03:33.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     44 |          204.015 | 176000 |           18.1552 |             148.414 |        -194.825 |        -77.1311 |             141.698 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=180000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=44.02112278463802 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len':
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000044)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000044)... Done. 0.0s

== Status ==
Current time: 2025-07-04 18:06:44 (running for 00:03:39.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     45 |          208.744 | 180000 |           44.0211 |             162.546 |          -194.3 |        -77.5409 |             153.316 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000045)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000045)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:49 (running for 00:03:44.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     46 |          213.336 | 184000 |           49.2656 |             165.418 |         -192.24 |        -78.4845 |             154.572 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=188000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=65.04651480154436 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000046)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000046)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:54 (running for 00:03:49.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     47 |          218.065 | 188000 |           65.0465 |             172.425 |         -189.96 |         -78.255 |             160.837 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000047)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000047)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:06:59 (running for 00:03:54.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     48 |          222.632 | 192000 |           79.4137 |             178.281 |        -188.307 |        -78.3624 |             167.802 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=196000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=95.50647160974584 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000048)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000048)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:04 (running for 00:03:59.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     49 |           227.21 | 196000 |           95.5065 |             188.347 |        -188.487 |        -79.2679 |             174.914 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000049)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000049)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:09 (running for 00:04:04.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     50 |          231.925 | 200000 |           86.5649 |             183.322 |        -185.737 |        -77.9276 |             166.908 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=204000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=90.38152938328898 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000050)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000050)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:14 (running for 00:04:09.37)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     51 |          236.528 | 204000 |           90.3815 |             189.018 |        -185.268 |        -77.9976 |             164.629 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000051)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000051)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:20 (running for 00:04:14.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     52 |          241.154 | 208000 |           88.0954 |             183.458 |         -181.73 |        -76.2664 |             162.634 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=212000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=109.46251201377058 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000052)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000052)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:25 (running for 00:04:19.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     53 |          245.746 | 212000 |           109.463 |             196.488 |        -179.424 |        -78.5934 |             170.992 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000053)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000053)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=220000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=112.42695240214874 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000054)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000054)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:30 (running for 00:04:24.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     55 |           254.96 | 220000 |           112.427 |             196.816 |         -177.03 |        -76.8954 |             169.535 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000055)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000055)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:35 (running for 00:04:29.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     56 |          259.557 | 224000 |           118.626 |             200.455 |        -177.238 |         -77.018 |             172.427 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=228000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=118.72262542955063 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000056)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000056)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:40 (running for 00:04:34.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     57 |          264.185 | 228000 |           118.723 |             199.532 |        -175.752 |        -76.8912 |             171.834 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000057)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000057)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:45 (running for 00:04:39.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     58 |          268.716 | 232000 |           104.323 |             193.185 |        -175.726 |        -76.3418 |             163.205 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=236000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=107.94131755779162 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000058)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000058)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:50 (running for 00:04:44.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     59 |          273.319 | 236000 |           107.941 |             194.205 |        -173.942 |        -76.0142 |             163.692 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000059)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000059)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:07:55 (running for 00:04:49.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     60 |          278.049 | 240000 |            112.23 |             194.982 |        -171.834 |        -74.9127 |             163.995 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=244000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=114.73666955365806 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000060)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000060)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:00 (running for 00:04:54.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     61 |          282.653 | 244000 |           114.737 |             196.157 |        -170.326 |        -72.3726 |             161.279 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000061)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000061)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:05 (running for 00:04:59.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     62 |          287.286 | 248000 |           122.018 |             199.862 |          -169.9 |        -71.4976 |             163.554 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=252000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=94.66287034120276 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000062)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000062)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:10 (running for 00:05:04.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     63 |          291.953 | 252000 |           94.6629 |             186.049 |        -170.021 |         -69.873 |             148.509 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000063)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000063)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:15 (running for 00:05:10.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     64 |          296.492 | 256000 |           98.8001 |             188.817 |        -172.011 |         -69.361 |             151.355 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=260000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=83.72893689160466 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000064)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000064)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:20 (running for 00:05:15.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     65 |          301.244 | 260000 |           83.7289 |             182.265 |        -174.416 |        -68.4704 |              144.35 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000065)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000065)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:25 (running for 00:05:20.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     66 |          305.874 | 264000 |           68.6138 |             173.837 |        -175.375 |        -67.5568 |             137.709 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=268000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=73.84556328580321 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000066)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000066)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:30 (running for 00:05:25.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     68 |          315.134 | 272000 |           71.3965 |             174.136 |        -176.604 |        -67.6709 |             141.536 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000067)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000067)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=276000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=94.63225367209445 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000068)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000068)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:35 (running for 00:05:30.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     69 |          319.776 | 276000 |           94.6323 |             184.594 |        -177.594 |        -67.5635 |             155.196 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000069)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000069)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:40 (running for 00:05:35.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     70 |          324.499 | 280000 |           75.4109 |             172.702 |        -176.115 |        -64.6876 |             143.512 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=284000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=91.46568005649307 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000070)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000070)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:45 (running for 00:05:40.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     71 |          329.089 | 284000 |           91.4657 |             179.818 |         -177.88 |        -64.8373 |             154.365 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000071)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000071)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:50 (running for 00:05:45.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     72 |          333.732 | 288000 |           97.1031 |             182.386 |        -179.905 |        -65.1845 |             159.807 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=292000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=81.98309627341295 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000072)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000072)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:08:55 (running for 00:05:50.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     73 |          338.288 | 292000 |           81.9831 |             174.062 |        -180.701 |        -63.8558 |             152.477 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000073)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000073)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:00 (running for 00:05:55.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     74 |          342.903 | 296000 |            62.391 |             162.834 |        -180.501 |        -63.5635 |             143.622 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=300000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=50.671684689007265 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000074)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000074)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:06 (running for 00:06:00.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     75 |           347.67 | 300000 |           50.6717 |             154.211 |         -180.54 |        -61.8091 |             138.809 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000075)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000075)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:11 (running for 00:06:05.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     76 |          352.276 | 304000 |           53.8215 |             152.029 |        -183.072 |        -61.0042 |             145.868 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=308000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=53.48536523601484 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000076)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000076)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:16 (running for 00:06:10.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     77 |          356.955 | 308000 |           53.4854 |             152.675 |        -184.255 |        -61.4348 |               146.5 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000077)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000077)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:21 (running for 00:06:15.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     78 |          361.569 | 312000 |           32.3036 |             139.984 |        -187.969 |        -58.4975 |             138.786 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=316000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=37.76952857441276 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000078)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000078)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:26 (running for 00:06:20.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     79 |          366.112 | 316000 |           37.7695 |             139.857 |        -185.462 |        -55.9508 |             139.325 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000079)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000079)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:31 (running for 00:06:25.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     80 |          370.855 | 320000 |           36.5077 |             131.595 |        -177.699 |        -51.6605 |             134.272 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=324000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=28.463250714836196 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000080)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000080)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000081)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000081)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:36 (running for 00:06:30.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     82 |          380.011 | 328000 |           42.7235 |              128.43 |        -172.123 |        -45.8811 |             132.297 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=332000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=40.82004304798403 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000082)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000082)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:41 (running for 00:06:35.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     83 |          384.669 | 332000 |             40.82 |             124.461 |        -170.821 |        -43.9697 |             131.149 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000083)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000083)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:46 (running for 00:06:40.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     84 |          389.225 | 336000 |           40.9113 |             124.373 |        -170.966 |        -43.0894 |             130.594 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=340000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=37.63931432907645 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000084)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000084)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:51 (running for 00:06:45.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     85 |          393.929 | 340000 |           37.6393 |             122.882 |         -171.93 |        -44.1452 |             130.833 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000085)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000085)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:09:56 (running for 00:06:51.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     86 |          398.527 | 344000 |           36.9771 |             126.202 |        -176.742 |        -45.2293 |             132.747 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=348000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=37.575044609592275 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000086)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000086)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:01 (running for 00:06:56.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     87 |          403.312 | 348000 |            37.575 |             123.435 |        -173.803 |        -42.8364 |              130.78 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000087)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000087)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:06 (running for 00:07:01.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     88 |          407.914 | 352000 |           35.8354 |             120.488 |        -171.574 |        -41.1122 |             128.033 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=356000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=33.31712831085708 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000088)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000088)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:11 (running for 00:07:06.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     89 |          412.465 | 356000 |           33.3171 |             118.591 |        -170.887 |        -41.4969 |              127.11 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000089)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000089)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:16 (running for 00:07:11.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     90 |          417.241 | 360000 |           44.7718 |             125.843 |        -171.272 |        -42.6402 |             132.841 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=364000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=58.180034994503245 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000090)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000090)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:21 (running for 00:07:16.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     91 |          421.816 | 364000 |             58.18 |             135.121 |        -169.517 |        -42.8549 |             135.431 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000091)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000091)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:26 (running for 00:07:21.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     92 |          426.475 | 368000 |           63.8294 |             136.184 |        -167.606 |        -40.7695 |             136.021 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=372000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=63.935520360345144 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000092)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000092)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:31 (running for 00:07:26.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     93 |          430.994 | 372000 |           63.9355 |             130.611 |        -161.197 |        -36.2269 |             130.748 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000093)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000093)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:37 (running for 00:07:31.41)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     94 |          435.647 | 376000 |           41.0272 |             120.467 |        -161.257 |         -36.146 |             117.962 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=380000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=35.26258648170899 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000094)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000094)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000095)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000095)...
== Status ==
Current time: 2025-07-04 18:10:42 (running for 00:07:36.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     96 |          444.973 | 384000 |           12.7207 |             102.332 |        -157.305 |         -30.338 |              98.031 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=388000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=26.884128097838502 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000096)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000096)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:47 (running for 00:07:41.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     97 |          449.663 | 388000 |           26.8841 |             111.801 |        -155.315 |          -29.37 |             99.7682 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000097)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000097)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:52 (running for 00:07:46.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     98 |          454.252 | 392000 |           41.1474 |              120.46 |        -154.519 |        -29.9743 |             105.181 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=396000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=60.03088409360749 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000098)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000098)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:10:57 (running for 00:07:51.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |     99 |          458.969 | 396000 |           60.0309 |             126.661 |        -152.245 |        -29.0673 |             114.683 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000099)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000099)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:02 (running for 00:07:56.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    100 |           463.71 | 400000 |           65.7647 |              133.55 |        -153.693 |        -31.5086 |             117.416 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=404000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=79.10319025875111 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000100)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000100)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:07 (running for 00:08:01.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    101 |          468.287 | 404000 |           79.1032 |             135.565 |        -147.835 |        -28.4961 |             119.869 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000101)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000101)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:12 (running for 00:08:06.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    102 |          472.978 | 408000 |           82.4993 |             138.982 |        -150.486 |        -29.3811 |             123.384 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=412000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=84.45061309799219 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000102)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000102)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:17 (running for 00:08:11.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    103 |          477.586 | 412000 |           84.4506 |             141.122 |        -149.347 |        -30.7539 |             123.429 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000103)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000103)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:22 (running for 00:08:16.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    104 |          482.144 | 416000 |           89.7727 |             140.833 |        -146.203 |        -26.9412 |             122.084 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=420000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=99.96086341286126 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000104)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000104)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:27 (running for 00:08:21.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    105 |          486.929 | 420000 |           99.9609 |             150.948 |        -152.105 |        -31.3893 |             132.507 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000105)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000105)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:32 (running for 00:08:26.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    106 |          491.475 | 424000 |           99.7898 |             152.782 |        -154.334 |        -33.1976 |             134.539 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=428000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=85.18064355795944 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000106)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000106)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:37 (running for 00:08:31.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    107 |          496.119 | 428000 |           85.1806 |             149.932 |        -160.387 |        -35.7569 |             131.392 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000107)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000107)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:42 (running for 00:08:37.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    108 |          500.719 | 432000 |           83.2247 |             153.037 |        -163.515 |        -37.2716 |             130.974 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=436000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=81.38943154377267 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000108)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000108)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:47 (running for 00:08:42.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    110 |          510.015 | 440000 |            80.774 |             154.928 |        -167.665 |        -35.3032 |             128.814 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000109)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000109)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=444000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=72.74969483284951 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000110)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000110)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:52 (running for 00:08:47.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    111 |           514.68 | 444000 |           72.7497 |             148.839 |         -165.93 |        -35.3596 |               125.2 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000111)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000111)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:11:57 (running for 00:08:52.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    112 |          519.319 | 448000 |            60.343 |             143.422 |          -168.1 |        -37.1277 |             122.149 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=452000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=62.17577099773351 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000112)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000112)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:02 (running for 00:08:57.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    113 |          523.917 | 452000 |           62.1758 |             146.791 |        -171.014 |        -38.6067 |             125.005 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000113)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000113)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:07 (running for 00:09:02.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    114 |           528.43 | 456000 |           65.1528 |             144.571 |        -168.379 |        -35.4297 |              124.39 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=460000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=51.39841781344292 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000114)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000114)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:12 (running for 00:09:07.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    115 |          533.199 | 460000 |           51.3984 |             136.382 |        -168.541 |        -34.4366 |             117.994 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000115)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000115)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:18 (running for 00:09:12.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    116 |          537.792 | 464000 |           45.8775 |             129.289 |        -169.324 |        -32.4419 |             118.355 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=468000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=38.9402083230124 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000116)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000116)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:23 (running for 00:09:17.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    117 |          542.419 | 468000 |           38.9402 |             129.426 |        -173.839 |        -34.8633 |             118.217 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000117)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000117)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:28 (running for 00:09:22.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    118 |          547.025 | 472000 |           27.2665 |             129.169 |        -182.306 |        -38.0336 |             118.437 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=476000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=22.988014531120186 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000118)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000118)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:33 (running for 00:09:27.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    119 |           551.66 | 476000 |            22.988 |             125.686 |        -181.414 |        -36.0458 |             114.762 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000119)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000119)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:38 (running for 00:09:32.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    120 |          556.368 | 480000 |           17.4683 |             128.005 |        -186.894 |        -38.4035 |             114.761 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=484000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=27.750487840828885 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000120)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000120)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:43 (running for 00:09:37.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    121 |          560.943 | 484000 |           27.7505 |             134.158 |        -187.442 |        -39.9854 |              121.02 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000121)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000121)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:48 (running for 00:09:42.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    122 |          565.499 | 488000 |          0.707371 |             117.227 |        -188.904 |        -39.3026 |             111.687 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=492000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-10.455270588079054 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000122)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000122)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000123)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000123)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:53 (running for 00:09:47.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    124 |           574.79 | 496000 |          -24.3064 |             104.733 |        -189.819 |        -39.7584 |             100.538 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=500000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-29.7178100244714 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000124)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000124)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:12:58 (running for 00:09:52.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    125 |          579.476 | 500000 |          -29.7178 |              101.19 |         -191.22 |        -39.6491 |             99.9622 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000125)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000125)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:03 (running for 00:09:57.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    126 |          584.073 | 504000 |          -48.9753 |             94.7321 |        -195.383 |        -41.1583 |             92.8343 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=508000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-46.771563429334435 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000126)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000126)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:08 (running for 00:10:02.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    127 |          588.723 | 508000 |          -46.7716 |             91.7989 |        -191.196 |        -37.0596 |             89.6849 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000127)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000127)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:13 (running for 00:10:08.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    128 |          593.293 | 512000 |           -46.798 |             91.3341 |        -191.399 |        -36.8815 |             90.1488 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=516000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-51.537581009191115 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000128)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000128)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:18 (running for 00:10:13.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    129 |          597.838 | 516000 |          -51.5376 |             96.5367 |        -201.047 |         -43.055 |             96.0274 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000129)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000129)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:23 (running for 00:10:18.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    130 |          602.618 | 520000 |          -68.8332 |             87.2756 |        -200.963 |        -43.4736 |             88.3279 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=524000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-73.17825926303432 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000130)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000130)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:28 (running for 00:10:23.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    131 |           607.26 | 524000 |          -73.1783 |             83.2643 |        -199.487 |        -44.6104 |             87.6547 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000131)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000131)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:33 (running for 00:10:28.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    132 |          611.836 | 528000 |          -77.7981 |              79.823 |        -198.854 |        -46.8057 |             88.0385 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=532000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-58.759667750206646 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000132)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000132)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:38 (running for 00:10:33.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    133 |          616.508 | 532000 |          -58.7597 |             80.2236 |        -188.555 |        -40.7538 |             90.3259 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000133)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000133)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:44 (running for 00:10:38.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    134 |          621.085 | 536000 |           -61.796 |             74.3085 |        -183.861 |        -39.9369 |             87.6933 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=540000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-68.84953866931106 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000134)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000134)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:49 (running for 00:10:43.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    135 |          625.874 | 540000 |          -68.8495 |             68.6965 |        -184.043 |        -39.8516 |             86.3488 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000135)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000135)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=548000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-49.65056640501112 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000136)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000136)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:54 (running for 00:10:48.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    137 |          634.934 | 548000 |          -49.6506 |             71.5363 |        -174.358 |        -34.3823 |             87.5534 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000137)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000137)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:13:59 (running for 00:10:53.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    138 |          639.551 | 552000 |          -53.0187 |              70.211 |         -176.37 |        -34.7388 |             87.8792 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=556000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-54.479320568162365 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000138)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000138)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:04 (running for 00:10:58.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    139 |          644.173 | 556000 |          -54.4793 |             73.3712 |        -179.296 |        -37.5664 |             89.0117 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000139)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000139)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:09 (running for 00:11:03.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    140 |          648.844 | 560000 |          -43.9409 |             74.4626 |        -174.392 |        -35.9434 |             91.9321 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=564000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-55.13146419021472 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000140)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000140)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:14 (running for 00:11:08.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    141 |          653.398 | 564000 |          -55.1315 |             69.7137 |        -176.385 |        -36.7179 |             88.2576 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000141)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000141)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:19 (running for 00:11:13.79)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    142 |          658.017 | 568000 |          -53.9827 |             66.0188 |        -172.205 |        -33.3024 |             85.5058 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=572000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-49.074664584489746 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000142)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000142)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:24 (running for 00:11:18.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    143 |          662.757 | 572000 |          -49.0747 |             65.9409 |        -169.179 |        -32.7971 |              86.961 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000143)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000143)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:29 (running for 00:11:23.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    144 |          667.391 | 576000 |          -49.6466 |             66.4842 |        -169.375 |        -33.8618 |             87.1061 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=580000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-40.25329467662639 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000144)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000144)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:34 (running for 00:11:28.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    145 |           672.13 | 580000 |          -40.2533 |             66.9284 |        -165.769 |        -31.2406 |             89.8275 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000145)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000145)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:39 (running for 00:11:33.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    146 |           676.68 | 584000 |          -52.2083 |             64.5957 |        -170.388 |        -33.7118 |             87.2955 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=588000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-45.33395534212257 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000146)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000146)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:44 (running for 00:11:38.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    147 |          681.367 | 588000 |           -45.334 |             67.0135 |        -166.518 |        -32.6598 |             86.8305 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000147)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000147)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:49 (running for 00:11:44.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    148 |          685.991 | 592000 |          -53.6072 |             62.5209 |        -167.923 |        -32.0191 |             83.8135 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=596000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-56.052485239448636 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000148)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000148)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:54 (running for 00:11:49.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    149 |           690.53 | 596000 |          -56.0525 |             62.2546 |        -170.528 |        -30.9151 |             83.1356 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000149)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000149)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=604000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-46.04826392517364 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000150)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000150)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:14:59 (running for 00:11:54.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    151 |          699.752 | 604000 |          -46.0483 |             59.0563 |        -160.162 |        -26.5666 |             81.6241 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000151)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000151)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:04 (running for 00:11:59.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    152 |          704.273 | 608000 |          -55.3405 |             58.4928 |        -165.671 |        -29.7764 |             81.6138 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=612000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-56.755077655288645 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000152)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000152)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:09 (running for 00:12:04.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    153 |          708.906 | 612000 |          -56.7551 |             56.4779 |        -165.633 |        -29.0704 |             81.4702 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000153)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000153)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:14 (running for 00:12:09.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    154 |          713.468 | 616000 |           -53.818 |             53.6712 |         -160.71 |        -26.1894 |               79.41 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=620000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-51.17031211679295 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000154)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000154)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:20 (running for 00:12:14.41)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    155 |          718.146 | 620000 |          -51.1703 |             57.1779 |        -163.092 |        -25.1755 |             79.9192 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000155)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000155)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:25 (running for 00:12:19.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    156 |          722.661 | 624000 |          -41.2422 |                54.7 |        -156.185 |        -17.2847 |             77.5279 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=628000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-26.088872055478113 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000156)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000156)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:30 (running for 00:12:24.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    157 |          727.183 | 628000 |          -26.0889 |             64.7013 |        -156.347 |        -15.8477 |             81.4046 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000157)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000157)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:35 (running for 00:12:29.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    158 |          731.874 | 632000 |          -49.8806 |             59.0964 |        -165.605 |        -21.2831 |             77.9116 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=636000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-44.855886759391495 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000158)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000158)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:40 (running for 00:12:34.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    159 |          736.452 | 636000 |          -44.8559 |              61.148 |        -165.341 |        -20.4168 |              79.754 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000159)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000159)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:45 (running for 00:12:39.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    160 |          741.099 | 640000 |          -28.3056 |             65.3627 |        -158.374 |        -16.0153 |             80.7208 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=644000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-8.063090157198554 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000160)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000160)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:50 (running for 00:12:44.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    161 |          745.676 | 644000 |          -8.06309 |             67.6568 |        -150.263 |          -8.983 |             83.5263 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000161)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000161)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=652000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-26.02158607586989 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000162)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000162)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:15:55 (running for 00:12:49.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    163 |          754.838 | 652000 |          -26.0216 |             65.7537 |        -160.168 |        -13.2839 |              81.677 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000163)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000163)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:00 (running for 00:12:54.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    164 |          759.386 | 656000 |          -41.8346 |             57.0617 |        -161.838 |        -12.9762 |             75.9177 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=660000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-52.484685473555786 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000164)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000164)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:05 (running for 00:12:59.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    165 |          763.997 | 660000 |          -52.4847 |             52.0141 |        -163.446 |        -11.4873 |             70.4342 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000165)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000165)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:10 (running for 00:13:04.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    166 |          768.503 | 664000 |          -50.2621 |             52.9974 |        -162.083 |        -11.3173 |             70.1409 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=668000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-52.43752314104124 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000166)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000166)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:15 (running for 00:13:09.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    167 |          773.048 | 668000 |          -52.4375 |             54.8271 |        -165.328 |        -13.6735 |             71.7372 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000167)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000167)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:20 (running for 00:13:15.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    168 |          777.806 | 672000 |          -56.8025 |             54.9522 |        -167.805 |        -14.6233 |             70.6731 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=676000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-59.199582527035936 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000168)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000168)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:25 (running for 00:13:20.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    169 |          782.455 | 676000 |          -59.1996 |             53.9403 |        -168.348 |        -15.1379 |             70.3456 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000169)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000169)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:30 (running for 00:13:25.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    170 |          787.136 | 680000 |          -75.2784 |             48.4476 |         -171.97 |        -17.3319 |             65.5761 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=684000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-70.59233797272586 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000170)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000170)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:35 (running for 00:13:30.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    171 |          791.785 | 684000 |          -70.5923 |              46.051 |        -167.566 |        -13.6942 |             64.6165 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000171)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000171)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:40 (running for 00:13:35.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    172 |          796.291 | 688000 |          -75.7409 |             46.2907 |        -172.561 |        -15.4051 |             65.9342 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=692000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-69.25630099136006 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000172)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000172)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:45 (running for 00:13:40.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    173 |          800.988 | 692000 |          -69.2563 |             47.1269 |        -168.009 |        -13.2536 |             64.8796 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000173)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000173)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:51 (running for 00:13:45.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    174 |          805.473 | 696000 |          -67.1668 |             47.8227 |        -166.555 |        -14.2644 |             65.8302 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=700000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-76.19093913827399 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000174)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000174)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000175)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000175)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:16:56 (running for 00:13:50.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    176 |          814.742 | 704000 |           -88.706 |             42.5064 |        -177.193 |         -17.838 |             63.8188 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=708000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-78.58784721816322 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000176)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000176)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:01 (running for 00:13:55.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    177 |          819.285 | 708000 |          -78.5878 |             41.0284 |        -169.722 |        -14.0792 |             64.1848 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000177)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000177)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:06 (running for 00:14:00.61)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    178 |          824.007 | 712000 |          -68.0733 |             41.6168 |        -163.604 |         -9.9058 |             63.8196 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=716000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-73.62339565858355 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000178)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000178)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:11 (running for 00:14:05.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    179 |          828.508 | 716000 |          -73.6234 |             40.8349 |        -165.843 |        -12.0042 |             63.3893 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000179)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000179)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:16 (running for 00:14:10.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    180 |          833.058 | 720000 |           -71.357 |             39.7537 |        -163.258 |        -11.4448 |             63.5925 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=724000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-67.77254398916236 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000180)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000180)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:21 (running for 00:14:15.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    181 |          837.604 | 724000 |          -67.7725 |             43.3367 |        -163.392 |         -13.248 |             65.5308 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000181)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000181)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:26 (running for 00:14:20.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    182 |          842.187 | 728000 |          -78.3223 |             37.1039 |        -164.899 |        -13.4814 |             62.9541 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=732000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-63.34903479739859 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000182)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000182)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:31 (running for 00:14:25.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    183 |          847.124 | 732000 |           -63.349 |             41.7364 |        -160.421 |        -10.9299 |             66.2652 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000183)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000183)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:36 (running for 00:14:30.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    184 |           851.74 | 736000 |          -66.6564 |             42.6197 |        -164.091 |        -12.8395 |             67.6541 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=740000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-76.30108551983827 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000184)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000184)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:41 (running for 00:14:35.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    185 |          856.377 | 740000 |          -76.3011 |              42.402 |        -171.137 |        -17.5011 |              69.935 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000185)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000185)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:46 (running for 00:14:40.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    186 |          860.952 | 744000 |          -95.3316 |             40.4669 |        -180.536 |        -24.6726 |             69.4099 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=748000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-80.88759307367745 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000186)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000186)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:51 (running for 00:14:45.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    187 |          865.469 | 748000 |          -80.8876 |             44.7631 |        -176.005 |        -22.3932 |             72.7473 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000187)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000187)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=756000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-56.96372853412329 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000188)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000188)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:17:56 (running for 00:14:50.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    189 |          874.744 | 756000 |          -56.9637 |             49.0327 |        -163.594 |         -18.135 |             75.7327 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000189)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000189)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:01 (running for 00:14:56.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    190 |          879.391 | 760000 |          -49.8746 |             54.8304 |        -165.383 |        -20.5873 |             81.2656 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=764000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-35.21487925275264 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000190)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000190)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:06 (running for 00:15:01.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    191 |          883.999 | 764000 |          -35.2149 |              57.181 |        -160.135 |        -17.1877 |              84.927 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000191)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000191)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:11 (running for 00:15:06.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    192 |          888.577 | 768000 |          -36.5305 |             54.0427 |        -157.791 |        -16.7698 |             83.9873 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=772000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-23.36313228798299 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000192)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000192)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:16 (running for 00:15:11.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    193 |          893.284 | 772000 |          -23.3631 |             55.1288 |         -150.46 |        -11.8079 |             83.7764 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000193)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000193)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:21 (running for 00:15:16.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    194 |          897.897 | 776000 |           1.54681 |             57.3697 |        -140.027 |        -3.00572 |             87.2098 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=780000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=19.457265111209143 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000194)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000194)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:27 (running for 00:15:21.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    195 |          902.541 | 780000 |           19.4573 |             62.1736 |        -133.907 |         0.90999 |             90.2805 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000195)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000195)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:32 (running for 00:15:26.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    196 |          907.162 | 784000 |            21.861 |             64.2234 |        -134.324 |       0.0444399 |             91.9167 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=788000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=30.6727110299734 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000196)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000196)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:37 (running for 00:15:31.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    197 |          911.685 | 788000 |           30.6727 |             64.1499 |        -129.217 |         3.42051 |             92.3195 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000197)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000197)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:42 (running for 00:15:36.61)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    198 |           916.49 | 792000 |           35.0601 |             66.5815 |        -129.718 |         2.53731 |             95.6594 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=796000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=43.60530762257424 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000198)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000198)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:47 (running for 00:15:41.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    199 |          921.055 | 796000 |           43.6053 |             68.2757 |        -125.853 |         5.29653 |             95.8865 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000199)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000199)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:52 (running for 00:15:46.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    200 |          925.725 | 800000 |           46.3846 |             71.6588 |        -127.109 |         5.26268 |             96.5721 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=804000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=57.40311998891557 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000200)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000200)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000201)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000201)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:18:57 (running for 00:15:51.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    202 |          934.879 | 808000 |           65.3489 |              79.224 |        -122.415 |         7.41649 |             101.123 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=812000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=62.10538416629239 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000202)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000202)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:02 (running for 00:15:56.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    203 |          939.607 | 812000 |           62.1054 |              80.129 |        -125.697 |         5.56314 |              102.11 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000203)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000203)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:07 (running for 00:16:01.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    204 |          944.191 | 816000 |           69.4795 |              82.147 |        -124.524 |         7.57953 |             104.277 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=820000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=81.66520321064468 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000204)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000204)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:12 (running for 00:16:06.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    205 |          948.786 | 820000 |           81.6652 |             82.6143 |        -117.936 |         11.7767 |              105.21 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000205)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000205)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:17 (running for 00:16:12.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    206 |          953.386 | 824000 |           74.3512 |             85.4078 |        -125.001 |         7.22923 |             106.715 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=828000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=88.71944971728065 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000206)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000206)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:22 (running for 00:16:17.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    207 |          957.989 | 828000 |           88.7194 |             88.6135 |         -120.37 |         10.1644 |             110.312 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000207)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000207)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:27 (running for 00:16:22.13)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    208 |          962.683 | 832000 |           96.7005 |             90.1762 |        -119.167 |         12.0534 |             113.637 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=836000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=111.34845697732199 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000208)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000208)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:32 (running for 00:16:27.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    209 |          967.276 | 836000 |           111.348 |             93.8755 |        -114.221 |          15.122 |             116.572 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000209)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000209)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:37 (running for 00:16:32.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    210 |          971.866 | 840000 |           125.075 |             96.7286 |        -107.884 |          19.913 |             116.317 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=844000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=130.47819534338544 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000210)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000210)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:42 (running for 00:16:37.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    211 |          976.492 | 844000 |           130.478 |             100.645 |        -108.701 |         20.1648 |             118.369 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000211)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000211)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:47 (running for 00:16:42.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    212 |           981.01 | 848000 |           136.881 |             102.217 |          -107.1 |         22.0487 |             119.715 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=852000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=131.08098787399837 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000212)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000212)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:52 (running for 00:16:47.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    213 |          985.684 | 852000 |           131.081 |             104.432 |        -114.616 |          19.391 |             121.874 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000213)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000213)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=860000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=125.37393731193502 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000214)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000214)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:19:58 (running for 00:16:52.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    215 |          994.794 | 860000 |           125.374 |             106.326 |        -120.666 |          16.888 |             122.826 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000215)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000215)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:03 (running for 00:16:57.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    216 |          999.413 | 864000 |           126.238 |             107.069 |        -119.827 |         16.7701 |             122.225 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=868000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=150.84665782609645 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000216)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000216)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:08 (running for 00:17:02.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    217 |           1003.9 | 868000 |           150.847 |             113.573 |         -112.76 |         23.2835 |              126.75 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000217)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000217)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:13 (running for 00:17:07.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    218 |          1008.63 | 872000 |           147.247 |             115.812 |        -117.482 |         19.7297 |             129.187 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=876000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=143.59536771705498 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000218)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000218)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:18 (running for 00:17:12.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    219 |          1013.36 | 876000 |           143.595 |             119.217 |        -122.763 |         16.1457 |             130.995 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000219)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000219)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:23 (running for 00:17:17.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    220 |          1017.91 | 880000 |           144.158 |               120.4 |        -123.382 |         14.8195 |             132.321 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=884000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=149.43298570464967 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000220)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000220)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:28 (running for 00:17:22.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    221 |          1022.63 | 884000 |           149.433 |             122.509 |        -122.281 |         15.3554 |              133.85 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000221)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000221)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:33 (running for 00:17:27.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    222 |          1027.22 | 888000 |           149.901 |             123.055 |        -122.584 |         14.8975 |             134.532 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=892000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=154.39724499943878 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000222)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000222)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:38 (running for 00:17:32.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    223 |          1031.95 | 892000 |           154.397 |             125.049 |        -122.593 |         14.8467 |             137.094 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000223)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000223)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:43 (running for 00:17:37.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    224 |          1036.49 | 896000 |           147.139 |              124.74 |        -128.003 |         12.9246 |             137.478 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=900000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=151.43677828982408 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000224)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000224)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:48 (running for 00:17:42.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    225 |          1041.03 | 900000 |           151.437 |             125.607 |        -125.517 |         12.9538 |             138.393 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000225)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000225)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:53 (running for 00:17:47.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    226 |           1045.7 | 904000 |           155.019 |              125.21 |        -123.044 |           15.22 |             137.633 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=908000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=150.61409703834667 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000226)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000226)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000227)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000227)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:20:58 (running for 00:17:53.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    228 |          1054.91 | 912000 |           165.106 |             127.442 |        -118.961 |          17.581 |             139.045 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=916000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=160.10309275443825 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000228)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000228)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:03 (running for 00:17:58.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    229 |          1059.46 | 916000 |           160.103 |             127.079 |        -120.411 |          16.119 |             137.316 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000229)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000229)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:08 (running for 00:18:03.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    230 |          1063.96 | 920000 |           166.115 |             127.953 |        -117.976 |         18.2247 |             137.914 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=924000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=164.79143271789195 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000230)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000230)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:13 (running for 00:18:08.13)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    231 |          1068.76 | 924000 |           164.791 |             128.349 |        -119.527 |         17.7667 |             138.203 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000231)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000231)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:18 (running for 00:18:13.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    232 |          1073.35 | 928000 |            162.58 |             127.339 |        -119.155 |         17.6784 |             136.718 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=932000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=158.6731283561275 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000232)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000232)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:23 (running for 00:18:18.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    233 |          1078.09 | 932000 |           158.673 |              127.76 |        -121.168 |         16.2388 |             135.843 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000233)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000233)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:28 (running for 00:18:23.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    234 |          1082.63 | 936000 |           151.672 |             128.882 |        -127.269 |         13.4894 |              136.57 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=940000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=150.16939839028538 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000234)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000234)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:33 (running for 00:18:28.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    235 |          1087.19 | 940000 |           150.169 |             129.008 |         -128.35 |         11.7908 |             137.721 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000235)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000235)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:38 (running for 00:18:33.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    236 |          1091.93 | 944000 |           149.832 |             129.963 |        -128.213 |         10.6672 |             137.414 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=948000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=139.77792456826114 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000236)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000236)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:44 (running for 00:18:38.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    237 |           1096.5 | 948000 |           139.778 |             130.039 |        -133.795 |         6.69483 |             136.839 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000237)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000237)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:49 (running for 00:18:43.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    238 |          1101.15 | 952000 |           142.989 |             131.753 |        -133.756 |         7.60082 |             137.391 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=956000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=151.52057447930713 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000238)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000238)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:21:54 (running for 00:18:48.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    239 |          1105.68 | 956000 |           151.521 |             133.032 |        -129.799 |          9.3104 |             138.977 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000239)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000239)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=964000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=164.0341567864374 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000240)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®== Status ==
Current time: 2025-07-04 18:21:59 (running for 00:18:53.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    241 |          1114.92 | 964000 |           164.034 |             137.966 |        -128.331 |         11.3737 |             143.026 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000240)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000241)



[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000241)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:04 (running for 00:18:58.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    242 |          1119.41 | 968000 |           157.854 |             139.935 |        -132.394 |           7.943 |              142.37 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=972000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=153.75920204938987 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000242)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000242)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:09 (running for 00:19:03.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    243 |          1124.17 | 972000 |           153.759 |             139.809 |        -134.749 |         6.43452 |             142.264 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000243)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000243)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:14 (running for 00:19:08.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    244 |          1128.82 | 976000 |           152.903 |             139.672 |        -134.309 |         5.90371 |             141.636 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=980000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=157.57288820532187 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000244)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000244)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:19 (running for 00:19:13.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    245 |          1133.37 | 980000 |           157.573 |             139.398 |        -131.875 |         8.27789 |             141.773 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000245)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000245)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:24 (running for 00:19:18.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    246 |          1138.12 | 984000 |           156.679 |             140.178 |        -133.582 |         7.88349 |             142.199 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=988000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=159.77567503840325 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000246)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000246)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:29 (running for 00:19:23.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    247 |          1142.63 | 988000 |           159.776 |             142.423 |        -134.628 |         9.20457 |             142.777 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000247)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000247)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:34 (running for 00:19:28.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    248 |          1147.31 | 992000 |           158.492 |             142.391 |        -135.436 |         8.33054 |             143.207 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=996000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=161.56467125523923 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000248)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000248)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:39 (running for 00:19:33.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    249 |          1151.91 | 996000 |           161.565 |             143.268 |        -133.666 |         7.84843 |             144.114 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000249)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000249)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:44 (running for 00:19:38.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    250 |          1156.49 | 1e+06 |           166.092 |              144.67 |         -132.86 |         9.09201 |             145.191 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=1004000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=159.44629925160334 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000250)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000250)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:49 (running for 00:19:43.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    251 |          1161.23 | 1.004e+06 |           159.446 |             146.404 |        -138.472 |         4.80056 |             146.714 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000251)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000251)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:54 (running for 00:19:49.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    252 |          1165.75 | 1.008e+06 |           149.179 |             146.732 |        -144.582 |        0.331144 |             146.698 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=1012000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=142.6780522026133 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000252)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000252)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:22:59 (running for 00:19:54.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    253 |          1170.38 | 1.012e+06 |           142.678 |             148.161 |        -149.544 |        -2.97843 |             147.039 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000253)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000253)... Done. 0.0s
Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=1020000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=145.46312622464924 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000254)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000254)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:04 (running for 00:19:59.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |       ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    255 |          1179.59 | 1.02e+06 |           145.463 |              152.18 |        -153.294 |        -4.75038 |             151.328 |
+---------------------+----------+--------------------+--------+------------------+----------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000255)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000255)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:09 (running for 00:20:04.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    256 |          1184.36 | 1.024e+06 |           161.852 |             154.261 |        -146.933 |        0.220582 |             154.303 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=1028000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=169.90244165993937 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000256)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000256)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:14 (running for 00:20:09.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    257 |          1188.91 | 1.028e+06 |           169.902 |             156.355 |        -144.779 |         2.27508 |             156.052 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000257)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000257)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:19 (running for 00:20:14.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    258 |          1193.56 | 1.032e+06 |           175.228 |             157.553 |        -143.317 |         4.37557 |             156.616 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=1036000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=177.13291846195244 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000258)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000258)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:25 (running for 00:20:19.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    259 |          1198.11 | 1.036e+06 |           177.133 |             157.852 |         -141.85 |         4.12331 |             157.008 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000259)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000259)... Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:30 (running for 00:20:24.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |       ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    260 |          1202.61 | 1.04e+06 |            170.51 |             159.625 |        -147.093 |         1.30457 |             156.674 |
+---------------------+----------+--------------------+--------+------------------+----------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=1044000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=178.59387240192882 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000260)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000260)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:35 (running for 00:20:29.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    261 |          1207.36 | 1.044e+06 |           178.594 |             158.769 |        -143.258 |         5.95431 |             157.129 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000261)


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000261)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 18:23:40 (running for 00:20:34.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | RUNNING  | 192.168.0.25:56037 |    262 |          1211.95 | 1.048e+06 |           198.056 |             160.282 |        -133.057 |         12.8127 |             158.019 |
+---------------------+----------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+


Trial PPO_env_b2888_00000 reported num_env_steps_sampled_lifetime=1052000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=203.02635887652792 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000262)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=56037)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(_WandbLoggingActor pid=56311)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_18-03-05/PPO_env_b2888_00000_0_2025-07-04_18-03-05/checkpoint_000262)...
[36m(_WandbLoggingActor pid=56311)[0m Done. 0.0s
2025-07-04 18:23:42,134	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-07-04_18-03-05' in 0.1506s.
== Status ==
Current time: 2025-07-04 18:23:42 (running for 00:20:36.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_18-03-04_566696_54274/artifacts/2025-07-04_18-03-05/PPO_2025-07-04_18-03-05/driver_artifacts
Number of trials: 1/1 (1 TERMINATED)
+---------------------+------------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status     | loc                |   iter |   total time (s) |        ts |   combined return |   return predator_0 |   return prey_1 |   return prey_0 |   return predator_1 |
|---------------------+------------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_b2888_00000 | TERMINATED | 192.168.0.25:56037 |    263 |          1216.63 | 1.052e+06 |           203.026 |             161.119 |        -129.914 |         13.1758 |             158.645 |
+---------------------+------------+--------------------+--------+------------------+-----------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(_WandbLoggingActor pid=56311)[0m wandb: uploading artifact checkpoint_PPO_env_b2888_00000; uploading artifact checkpoint_PPO_env_b2888_00000
[36m(_WandbLoggingActor pid=56311)[0m wandb: uploading artifact checkpoint_PPO_env_b2888_00000; uploading history steps 259-262, summary, console lines 260-262
[36m(_WandbLoggingActor pid=56311)[0m wandb: uploading artifact checkpoint_PPO_env_b2888_00000
2025-07-04 18:23:48,878	INFO tune.py:1041 -- Total run time: 1243.27 seconds (1236.36 seconds for the tuning loop).
[36m(_WandbLoggingActor pid=56311)[0m wandb:
[36m(_WandbLoggingActor pid=56311)[0m wandb:
[36m(_WandbLoggingActor pid=56311)[0m wandb: Run history:
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    env_runners/agent_steps/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    env_runners/agent_steps/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/agent_steps/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/agent_steps/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  env_runners/connector_pipeline_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           env_runners/env_reset_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            env_runners/env_step_timer ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ


ËÆ≠ÁªÉÂÆåÊàê
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ
Ëé∑ÂèñÊúÄ‰Ω≥checkpoint...
[36m(_WandbLoggingActor pid=56311)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
Âä†ËΩΩÊâÄÊúâÊô∫ËÉΩ‰ΩìÁöÑRLModule...
[36m(_WandbLoggingActor pid=56311)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 env_runners/episode_duration_sec_mean ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           env_runners/episode_len_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                          env_runners/episode_len_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           env_runners/episode_len_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/episode_return_max ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                       env_runners/episode_return_mean ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/episode_return_min ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ
2025-07-04 18:23:48,966	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñá‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñÖ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñá‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñà‚ñÑ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ‚ñÜ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     env_runners/num_env_steps_sampled ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                              env_runners/num_episodes ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     env_runners/num_episodes_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  env_runners/rlmodule_inference_timer ‚ñÑ‚ñá‚ñÇ‚ñÉ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                    env_runners/sample ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     env_runners/time_between_sampling ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            env_runners/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                   fault_tolerance/num_healthy_workers ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                              iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÑ
ÊàêÂäüÂä†ËΩΩ predator_0 ÁöÑÊ®°Âûã
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_0/entropy ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÇ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/predator_0/mean_kl_loss ‚ñÇ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñÅ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                       learners/predator_0/policy_loss ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÅ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñá‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/predator_0/total_loss ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  learners/predator_0/vf_explained_var ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_0/vf_loss ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/predator_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_1/entropy ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñà‚ñà‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/predator_1/mean_kl_loss ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                       learners/predator_1/policy_loss ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñà‚ñÜ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/predator_1/total_loss ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñá‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  learners/predator_1/vf_explained_var ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñá‚ñà‚ñÅ‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÅ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_1/vf_loss ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÜ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/predator_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_0/entropy ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÜ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                          learners/prey_0/mean_kl_loss ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/prey_0/policy_loss ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            learners/prey_0/total_loss ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/prey_0/vf_explained_var ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÅ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_0/vf_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñá‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/prey_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_1/entropy ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñà‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                          learners/prey_1/mean_kl_loss ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
ÊàêÂäüÂä†ËΩΩ predator_1 ÁöÑÊ®°Âûã
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÇ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/prey_1/policy_loss ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÜ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            learners/prey_1/total_loss ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/prey_1/vf_explained_var ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñá‚ñá‚ñÑ‚ñá‚ñà‚ñÖ‚ñà‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_1/vf_loss ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñÅ‚ñá‚ñá‚ñÉ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñá
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/prey_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 num_training_step_calls_per_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                 perf/cpu_util_percent ‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                 perf/ram_util_percent ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                    time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                      time_this_iter_s ‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                          time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      timers/env_runner_sampling_timer ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           timers/learner_update_timer ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            timers/restore_env_runners ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           timers/synch_env_connectors ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                  timers/synch_weights ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                             timers/training_iteration ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                  timers/training_step ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                             timestamp ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                    training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=56311)[0m wandb:
[36m(_WandbLoggingActor pid=56311)[0m wandb: Run summary:
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 161.11922
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 158.64502
ÊàêÂäüÂä†ËΩΩ prey_0 ÁöÑÊ®°Âûã
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 13.17584
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 -129.91373
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    env_runners/agent_steps/predator_0 500
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    env_runners/agent_steps/predator_1 500
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/agent_steps/prey_0 500
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/agent_steps/prey_1 500
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.00036
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           env_runners/env_reset_timer 0.0026
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            env_runners/env_step_timer 0.00042
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00011
[36m(_WandbLoggingActor pid=56311)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 2e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 1881.0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 1881.0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 env_runners/episode_duration_sec_mean 2.08479
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           env_runners/episode_len_max 2000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                          env_runners/episode_len_mean 2000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           env_runners/episode_len_min 2000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/episode_return_max 681.92843
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                       env_runners/episode_return_mean 203.02636
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        env_runners/episode_return_min -55.23299
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 161.11922
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 158.64502
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 13.17584
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 -129.91373
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00023
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 8e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0
ÊàêÂäüÂä†ËΩΩ prey_1 ÁöÑÊ®°Âûã
[36m(_WandbLoggingActor pid=56311)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05
ÊÄªÂÖ±Âä†ËΩΩ‰∫Ü 4 ‰∏™Êô∫ËÉΩ‰ΩìÊ®°Âûã
[36m(_WandbLoggingActor pid=56311)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0
ÂºÄÂßãÊé®ÁêÜ...
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 3e-05

=== Episode 1 ===
[36m(_WandbLoggingActor pid=56311)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 263000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 263526
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 263526
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 263526
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 1052000.0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 1178.1083
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                              env_runners/num_episodes 2
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     env_runners/num_episodes_lifetime 526
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 263000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 263526
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 263526
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 263526
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.0001
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                    env_runners/sample 2.10124
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     env_runners/time_between_sampling 2.70507
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 3e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 2e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 7e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            env_runners/weights_seq_no 262
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                              iterations_since_restore 263
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.07539
[36m(_WandbLoggingActor pid=56311)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03425
[36m(_WandbLoggingActor pid=56311)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 6e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.00235
[36m(_WandbLoggingActor pid=56311)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.00194
[36m(_WandbLoggingActor pid=56311)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.02808
[36m(_WandbLoggingActor pid=56311)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.00721
[36m(_WandbLoggingActor pid=56311)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.00129
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 940000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 247220000
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 389984.23694
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 120320
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 31644160
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 2145350.32472
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 2112995.53154
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 578580
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 1.46129
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_0/entropy -1.16495
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 15.22468
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.01543
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 7911040
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 12479.74697
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                       learners/predator_0/policy_loss -0.20765
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/predator_0/total_loss -0.14811
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  learners/predator_0/vf_explained_var -0.15395
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_0/vf_loss 7.39621
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 63.26608
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/predator_0/weights_seq_no 263
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 1.7319
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_1/entropy -0.99385
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 17.53783
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.0147
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 7911040
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 12479.64961
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/predator_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                       learners/predator_1/policy_loss -0.03524
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/predator_1/total_loss 0.0286
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                  learners/predator_1/vf_explained_var -0.02943
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/predator_1/vf_loss 7.67709
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 194.61313
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/predator_1/weights_seq_no 263
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 1.17036
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_0/entropy 3.16599
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 3.53886
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.00658
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 7911040
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 12479.52867
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/prey_0/policy_loss -0.01454
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            learners/prey_0/total_loss 0.02782
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/prey_0/vf_explained_var 0.48034
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_0/vf_loss 6.93179
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 228.98483
predator_0 ÊâßË°åÂä®‰Ωú: [-1.0865397 -0.6980525]
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/prey_0/weights_seq_no 263
[WARNING]: Received an action [-1.0865397 -0.6980525] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 1.21891
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_1/entropy 4.38299
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 12.86459
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.01034
predator_1 ÊâßË°åÂä®‰Ωú: [0.48765826 0.8203577 ]
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 7911040
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 12479.58196
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                              learners/prey_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           learners/prey_1/policy_loss -0.09498
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            learners/prey_1/total_loss -0.0378
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      learners/prey_1/vf_explained_var 0.75102
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                               learners/prey_1/vf_loss 8.91526
prey_0 ÊâßË°åÂä®‰Ωú: [0.65766114 0.14026976]
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 253.19974
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        learners/prey_1/weights_seq_no 263
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                        num_env_steps_sampled_lifetime 1052000.0
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                 num_training_step_calls_per_iteration 1
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                 perf/cpu_util_percent 8.67143
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                 perf/ram_util_percent 13.4
prey_1 ÊâßË°åÂä®‰Ωú: [-49.151207 -27.928514]
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                    time_since_restore 1216.62523
[WARNING]: Received an action [-49.151207 -27.928514] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                      time_this_iter_s 4.67777
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                          time_total_s 1216.62523
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                      timers/env_runner_sampling_timer 2.12709
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           timers/learner_update_timer 2.5104
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                            timers/restore_env_runners 1e-05
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                           timers/synch_env_connectors 0.00145
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                  timers/synch_weights 0.00304
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                             timers/training_iteration 4.64122
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                  timers/training_step 4.64092
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                             timestamp 1751621021
[36m(_WandbLoggingActor pid=56311)[0m wandb:                                                                                    training_iteration 263
[36m(_WandbLoggingActor pid=56311)[0m wandb:
[36m(_WandbLoggingActor pid=56311)[0m wandb: üöÄ View run PPO_env_b2888_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/b2888_00000
[36m(_WandbLoggingActor pid=56311)[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=56311)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 1868 artifact file(s) and 0 other file(s)
[36m(_WandbLoggingActor pid=56311)[0m wandb: Find logs at: ./wandb/run-20250704_180313-b2888_00000/logs
predator_0 ÊâßË°åÂä®‰Ωú: [-0.92854375  0.7777856 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.878853   1.5213217]
[WARNING]: Received an action [-0.878853   1.5213217] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.72388375 0.707762  ]
prey_1 ÊâßË°åÂä®‰Ωú: [-22.72742  33.60762]
[WARNING]: Received an action [-22.72742  33.60762] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.549574   1.1508583]
[WARNING]: Received an action [-1.549574   1.1508583] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.5641761 1.590854 ]
[WARNING]: Received an action [1.5641761 1.590854 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.07180823 0.34092563]
prey_1 ÊâßË°åÂä®‰Ωú: [-15.31698  -19.568884]
[WARNING]: Received an action [-15.31698  -19.568884] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-3.0326135  2.5642006]
[WARNING]: Received an action [-3.0326135  2.5642006] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.67509353 1.4774184 ]
[WARNING]: Received an action [0.67509353 1.4774184 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.10637197  0.25640294]
prey_1 ÊâßË°åÂä®‰Ωú: [-14.605014   1.199388]
[WARNING]: Received an action [-14.605014   1.199388] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5767825  1.3735907]
[WARNING]: Received an action [-1.5767825  1.3735907] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.20785502  1.5181218 ]
[WARNING]: Received an action [-0.20785502  1.5181218 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.37169006  0.15490302]
prey_1 ÊâßË°åÂä®‰Ωú: [  6.453667 -32.116734]
[WARNING]: Received an action [  6.453667 -32.116734] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.61213136  0.9518553 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.0509927  1.0556364]
[WARNING]: Received an action [-0.0509927  1.0556364] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.3312879  0.4598719]
prey_1 ÊâßË°åÂä®‰Ωú: [8.382197 9.020959]
[WARNING]: Received an action [8.382197 9.020959] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1075678  1.4208198]
[WARNING]: Received an action [-1.1075678  1.4208198] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.01082778 1.0265332 ]
[WARNING]: Received an action [0.01082778 1.0265332 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.39275146  0.23496208]
prey_1 ÊâßË°åÂä®‰Ωú: [ -2.415617 -13.731839]
[WARNING]: Received an action [ -2.415617 -13.731839] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6856741  0.5183329]
[WARNING]: Received an action [-1.6856741  0.5183329] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.8595377 1.4936384]
[WARNING]: Received an action [0.8595377 1.4936384] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.09734325 0.07213242]
prey_1 ÊâßË°åÂä®‰Ωú: [32.854374 28.061365]
[WARNING]: Received an action [32.854374 28.061365] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.537329   1.0557928]
[WARNING]: Received an action [-1.537329   1.0557928] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.9496765  1.8854392]
[WARNING]: Received an action [-1.9496765  1.8854392] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.0621155   0.22289604]
prey_1 ÊâßË°åÂä®‰Ωú: [ 50.24581 -79.51275]
[WARNING]: Received an action [ 50.24581 -79.51275] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3210263   0.76660657]
[WARNING]: Received an action [-1.3210263   0.76660657] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.31536567  0.606874  ]
prey_0 ÊâßË°åÂä®‰Ωú: [-0.07724732  0.3298239 ]
prey_1 ÊâßË°åÂä®‰Ωú: [56.489185  -3.2023706]
[WARNING]: Received an action [56.489185  -3.2023706] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5093887  2.657136 ]
[WARNING]: Received an action [-1.5093887  2.657136 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.95764554  1.054085  ]
[WARNING]: Received an action [-0.95764554  1.054085  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.05213724 0.34255242]
prey_1 ÊâßË°åÂä®‰Ωú: [-54.450794     0.76260334]
[WARNING]: Received an action [-54.450794     0.76260334] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6536533  2.0329237]
[WARNING]: Received an action [-1.6536533  2.0329237] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.59454906  0.5958698 ]
prey_0 ÊâßË°åÂä®‰Ωú: [0.01822809 0.42597097]
prey_1 ÊâßË°åÂä®‰Ωú: [-13.43154  -11.838745]
[WARNING]: Received an action [-13.43154  -11.838745] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3564744 -1.1831361]
[WARNING]: Received an action [-1.3564744 -1.1831361] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.66838586  0.5853399 ]
Episode 1 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 1 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -5.00
  predator_1: -2.87
  prey_0: -1.19
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 2 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-5.0015883  1.2642872]
[WARNING]: Received an action [-5.0015883  1.2642872] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.4850765  1.0961133]
[WARNING]: Received an action [-0.4850765  1.0961133] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [43.31906   2.994455]
[WARNING]: Received an action [43.31906   2.994455] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-43.80625    -2.4508252]
[WARNING]: Received an action [-43.80625    -2.4508252] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.5610104 -4.6427193]
[WARNING]: Received an action [-2.5610104 -4.6427193] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.17766485  0.86432344]
prey_0 ÊâßË°åÂä®‰Ωú: [13.6140785  2.0505457]
[WARNING]: Received an action [13.6140785  2.0505457] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 47.464554 -40.50342 ]
[WARNING]: Received an action [ 47.464554 -40.50342 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4953933  1.8308588]
[WARNING]: Received an action [-1.4953933  1.8308588] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.5242237  0.737859 ]
prey_0 ÊâßË°åÂä®‰Ωú: [20.001656    0.54741573]
[WARNING]: Received an action [20.001656    0.54741573] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 38.588604 -37.946068]
[WARNING]: Received an action [ 38.588604 -37.946068] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6353328  1.5266165]
[WARNING]: Received an action [-1.6353328  1.5266165] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.00678258 0.80197436]
prey_0 ÊâßË°åÂä®‰Ωú: [2.7728324 1.5953047]
[WARNING]: Received an action [2.7728324 1.5953047] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ -6.5768037 -38.70932  ]
[WARNING]: Received an action [ -6.5768037 -38.70932  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.4077205   0.38739347]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.10685999  0.79668957]
prey_0 ÊâßË°åÂä®‰Ωú: [1.7974337 9.787703 ]
[WARNING]: Received an action [1.7974337 9.787703 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-59.30847  -57.324352]
[WARNING]: Received an action [-59.30847  -57.324352] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5468093  -0.00954914]
[WARNING]: Received an action [-1.5468093  -0.00954914] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.21314704  0.75734997]
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.2692618 -1.4407505]
[WARNING]: Received an action [ 1.2692618 -1.4407505] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [  5.274265 -14.474683]
[WARNING]: Received an action [  5.274265 -14.474683] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.7921654  2.3705478]
[WARNING]: Received an action [-0.7921654  2.3705478] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.18761359  0.6705013 ]
prey_0 ÊâßË°åÂä®‰Ωú: [9.164357 8.244132]
[WARNING]: Received an action [9.164357 8.244132] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 55.0068   -18.509882]
[WARNING]: Received an action [ 55.0068   -18.509882] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.44688594 -0.51588154]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.44236478  0.61331815]
prey_0 ÊâßË°åÂä®‰Ωú: [14.004422   1.3321952]
[WARNING]: Received an action [14.004422   1.3321952] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [23.725916 22.27023 ]
[WARNING]: Received an action [23.725916 22.27023 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.8347824  3.485663 ]
[WARNING]: Received an action [-1.8347824  3.485663 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.22453475  0.2906875 ]
prey_0 ÊâßË°åÂä®‰Ωú: [-0.86956733  2.7856462 ]
[WARNING]: Received an action [-0.86956733  2.7856462 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [31.830338 20.387594]
[WARNING]: Received an action [31.830338 20.387594] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1866384  1.1051741]
[WARNING]: Received an action [-1.1866384  1.1051741] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.09707025  0.5777449 ]
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.427036 -1.34656 ]
[WARNING]: Received an action [ 2.427036 -1.34656 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 53.58842 -16.1878 ]
[WARNING]: Received an action [ 53.58842 -16.1878 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.1359513  -0.24616396]
[WARNING]: Received an action [-2.1359513  -0.24616396] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.11386224  0.17834029]
prey_0 ÊâßË°åÂä®‰Ωú: [-2.1086745  1.7939806]
[WARNING]: Received an action [-2.1086745  1.7939806] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [29.342644 12.109375]
[WARNING]: Received an action [29.342644 12.109375] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.8647958  2.5455668]
[WARNING]: Received an action [-1.8647958  2.5455668] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.19955125 -0.10408905]
prey_0 ÊâßË°åÂä®‰Ωú: [4.855715 2.105888]
[WARNING]: Received an action [4.855715 2.105888] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 52.8027 -19.6463]
[WARNING]: Received an action [ 52.8027 -19.6463] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.0025434 -1.4139504]
[WARNING]: Received an action [-2.0025434 -1.4139504] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.11379671  0.13911209]
Episode 2 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 2 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.81
  predator_1: -2.01
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 3 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-2.329737   0.9390194]
[WARNING]: Received an action [-2.329737   0.9390194] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.07648116 -0.09472784]
prey_0 ÊâßË°åÂä®‰Ωú: [ 8.757111   -0.48664927]
[WARNING]: Received an action [ 8.757111   -0.48664927] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-3.412827 22.509466]
[WARNING]: Received an action [-3.412827 22.509466] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4208125   0.58344936]
[WARNING]: Received an action [-1.4208125   0.58344936] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.13377953  0.08293983]
prey_0 ÊâßË°åÂä®‰Ωú: [0.39655536 0.47093925]
prey_1 ÊâßË°åÂä®‰Ωú: [ 9.346987  -7.0841093]
[WARNING]: Received an action [ 9.346987  -7.0841093] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.0586042  1.0230118]
[WARNING]: Received an action [-1.0586042  1.0230118] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.17495294 -0.04975682]
prey_0 ÊâßË°åÂä®‰Ωú: [0.37430024 6.460241  ]
[WARNING]: Received an action [0.37430024 6.460241  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-22.525143 -13.613807]
[WARNING]: Received an action [-22.525143 -13.613807] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.8118771  1.1678408]
[WARNING]: Received an action [-0.8118771  1.1678408] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.07370934  0.14970173]
prey_0 ÊâßË°åÂä®‰Ωú: [2.4597778 3.715934 ]
[WARNING]: Received an action [2.4597778 3.715934 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [54.35799  29.362045]
[WARNING]: Received an action [54.35799  29.362045] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.82901037  0.22764286]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.20947354  0.12123917]
prey_0 ÊâßË°åÂä®‰Ωú: [0.02845949 2.8179927 ]
[WARNING]: Received an action [0.02845949 2.8179927 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-69.05841  -48.803585]
[WARNING]: Received an action [-69.05841  -48.803585] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1442617  1.4851642]
[WARNING]: Received an action [-1.1442617  1.4851642] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.066011    0.21483697]
prey_0 ÊâßË°åÂä®‰Ωú: [-4.323172  -7.2360144]
[WARNING]: Received an action [-4.323172  -7.2360144] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-13.50855     1.3083316]
[WARNING]: Received an action [-13.50855     1.3083316] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2013056  0.7135003]
[WARNING]: Received an action [-1.2013056  0.7135003] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.1502697  -0.17592496]
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.03292793 -1.9030406 ]
[WARNING]: Received an action [ 0.03292793 -1.9030406 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-10.67804    -8.0286875]
[WARNING]: Received an action [-10.67804    -8.0286875] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1116395  2.8451467]
[WARNING]: Received an action [-1.1116395  2.8451467] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 0.09545827 -0.03570506]
prey_0 ÊâßË°åÂä®‰Ωú: [-0.8353898 -0.6645449]
prey_1 ÊâßË°åÂä®‰Ωú: [39.10008   -2.0420504]
[WARNING]: Received an action [39.10008   -2.0420504] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.9796329  -0.23794681]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.49071515  0.18275525]
prey_0 ÊâßË°åÂä®‰Ωú: [-2.3846097 -1.0106306]
[WARNING]: Received an action [-2.3846097 -1.0106306] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-44.86731 -87.02029]
[WARNING]: Received an action [-44.86731 -87.02029] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.65565413  0.7888693 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.7006893  -0.43377435]
prey_0 ÊâßË°åÂä®‰Ωú: [-5.6646895  1.9162993]
[WARNING]: Received an action [-5.6646895  1.9162993] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-25.444113   -1.9656849]
[WARNING]: Received an action [-25.444113   -1.9656849] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.47479454  0.28348643]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.12278561  0.85395956]
prey_0 ÊâßË°åÂä®‰Ωú: [-3.0440273  -0.33102685]
[WARNING]: Received an action [-3.0440273  -0.33102685] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [68.60172   -4.6767893]
[WARNING]: Received an action [68.60172   -4.6767893] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.6714016  0.4829908]
predator_1 ÊâßË°åÂä®‰Ωú: [0.40143025 1.2233624 ]
[WARNING]: Received an action [0.40143025 1.2233624 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.5396688 -1.7381053]
[WARNING]: Received an action [ 2.5396688 -1.7381053] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-47.13227  30.0079 ]
[WARNING]: Received an action [-47.13227  30.0079 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.35507387 0.5179802 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.2937824  -0.64108175]
Episode 3 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 3 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -2.81
  predator_1: -2.16
  prey_0: 17.37
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 4 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7066882   0.43036783]
[WARNING]: Received an action [-1.7066882   0.43036783] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.7049655  1.1205192]
[WARNING]: Received an action [-1.7049655  1.1205192] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.256312 -1.309575]
[WARNING]: Received an action [ 3.256312 -1.309575] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 0.9808538 14.544867 ]
[WARNING]: Received an action [ 0.9808538 14.544867 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7339828  0.5980235]
[WARNING]: Received an action [-1.7339828  0.5980235] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.37817854 1.0234177 ]
[WARNING]: Received an action [0.37817854 1.0234177 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.17174804 2.638929  ]
[WARNING]: Received an action [0.17174804 2.638929  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-19.375908   -4.9916553]
[WARNING]: Received an action [-19.375908   -4.9916553] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7995231 -2.707273 ]
[WARNING]: Received an action [-1.7995231 -2.707273 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.31682214 1.0009923 ]
[WARNING]: Received an action [0.31682214 1.0009923 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-6.748366   1.1870354]
[WARNING]: Received an action [-6.748366   1.1870354] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 23.443226 -30.917383]
[WARNING]: Received an action [ 23.443226 -30.917383] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.2320113  -0.26481175]
[WARNING]: Received an action [-2.2320113  -0.26481175] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.22449493  0.8765172 ]
prey_0 ÊâßË°åÂä®‰Ωú: [-11.990414   9.463657]
[WARNING]: Received an action [-11.990414   9.463657] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [30.795965 10.501872]
[WARNING]: Received an action [30.795965 10.501872] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3437015  -0.15318191]
[WARNING]: Received an action [-1.3437015  -0.15318191] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.02986336  0.6893457 ]
prey_0 ÊâßË°åÂä®‰Ωú: [-0.4916064 -6.4737115]
[WARNING]: Received an action [-0.4916064 -6.4737115] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 11.816238 -25.53076 ]
[WARNING]: Received an action [ 11.816238 -25.53076 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.98833877  1.0751742 ]
[WARNING]: Received an action [-0.98833877  1.0751742 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.44618535 1.4261811 ]
[WARNING]: Received an action [0.44618535 1.4261811 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.14211214 -0.51528704]
prey_1 ÊâßË°åÂä®‰Ωú: [42.198864 -5.281452]
[WARNING]: Received an action [42.198864 -5.281452] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.9726019  0.8925375]
predator_1 ÊâßË°åÂä®‰Ωú: [-1.6978549  0.6488484]
[WARNING]: Received an action [-1.6978549  0.6488484] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-6.669545  -3.4404697]
[WARNING]: Received an action [-6.669545  -3.4404697] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [11.511975  9.598426]
[WARNING]: Received an action [11.511975  9.598426] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3333896  1.0506899]
[WARNING]: Received an action [-1.3333896  1.0506899] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.5434166  1.5516133]
[WARNING]: Received an action [-0.5434166  1.5516133] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 8.472652  -1.8580651]
[WARNING]: Received an action [ 8.472652  -1.8580651] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [13.869364 17.216475]
[WARNING]: Received an action [13.869364 17.216475] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1627573  2.053656 ]
[WARNING]: Received an action [-1.1627573  2.053656 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.7285595  0.8347378]
prey_0 ÊâßË°åÂä®‰Ωú: [1.069787  1.0391154]
[WARNING]: Received an action [1.069787  1.0391154] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [  3.5370846 -18.884413 ]
[WARNING]: Received an action [  3.5370846 -18.884413 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6902994  1.6275059]
[WARNING]: Received an action [-1.6902994  1.6275059] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.22422366  0.59312224]
prey_0 ÊâßË°åÂä®‰Ωú: [-24.999035    1.3123257]
[WARNING]: Received an action [-24.999035    1.3123257] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-10.744624 -10.44477 ]
[WARNING]: Received an action [-10.744624 -10.44477 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.1896296  1.2598374]
[WARNING]: Received an action [-2.1896296  1.2598374] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.09400766  0.36172345]
prey_0 ÊâßË°åÂä®‰Ωú: [4.409435  3.2378695]
[WARNING]: Received an action [4.409435  3.2378695] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-0.72760224 13.234366  ]
[WARNING]: Received an action [-0.72760224 13.234366  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3943422  1.4218056]
[WARNING]: Received an action [-1.3943422  1.4218056] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.17591159  0.16428892]
prey_0 ÊâßË°åÂä®‰Ωú: [  2.4871304 -15.109877 ]
[WARNING]: Received an action [  2.4871304 -15.109877 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [24.848288  -4.7079024]
[WARNING]: Received an action [24.848288  -4.7079024] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3458842  2.590733 ]
[WARNING]: Received an action [-1.3458842  2.590733 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.3244168  -0.21596251]
Episode 4 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 4 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.00
  predator_1: -2.46
  prey_0: -2.63
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 5 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-0.07642519 -7.446443  ]
[WARNING]: Received an action [-0.07642519 -7.446443  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.34864652  1.3071914 ]
[WARNING]: Received an action [-0.34864652  1.3071914 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [4.037628 5.089463]
[WARNING]: Received an action [4.037628 5.089463] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-57.621872 -17.82097 ]
[WARNING]: Received an action [-57.621872 -17.82097 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.614936 -0.868937]
[WARNING]: Received an action [-1.614936 -0.868937] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.5645304  1.0062928]
[WARNING]: Received an action [-1.5645304  1.0062928] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.3039308 -2.241139 ]
[WARNING]: Received an action [ 2.3039308 -2.241139 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [10.721511  -5.9607663]
[WARNING]: Received an action [10.721511  -5.9607663] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4709187   0.06927222]
[WARNING]: Received an action [-1.4709187   0.06927222] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.09567371  0.9122548 ]
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.3478619 -3.5725646]
[WARNING]: Received an action [ 0.3478619 -3.5725646] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 13.806155 -21.614077]
[WARNING]: Received an action [ 13.806155 -21.614077] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.2852616  2.7692826]
[WARNING]: Received an action [-2.2852616  2.7692826] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.0975494  1.0297828]
[WARNING]: Received an action [-1.0975494  1.0297828] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.7112988 -1.9504375]
[WARNING]: Received an action [ 0.7112988 -1.9504375] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [14.729336   -0.60263604]
[WARNING]: Received an action [14.729336   -0.60263604] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3166318  1.8568666]
[WARNING]: Received an action [-1.3166318  1.8568666] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.7565948  0.9570979]
prey_0 ÊâßË°åÂä®‰Ωú: [1.3896999  0.25102657]
[WARNING]: Received an action [1.3896999  0.25102657] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-41.437958  81.68808 ]
[WARNING]: Received an action [-41.437958  81.68808 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7926077 -0.4863186]
[WARNING]: Received an action [-1.7926077 -0.4863186] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.4108707  0.46784312]
prey_0 ÊâßË°åÂä®‰Ωú: [0.22970212 1.358639  ]
[WARNING]: Received an action [0.22970212 1.358639  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 8.809072 82.20141 ]
[WARNING]: Received an action [ 8.809072 82.20141 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.00996256 -1.2184007 ]
[WARNING]: Received an action [-0.00996256 -1.2184007 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.27776653 0.9946826 ]
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.6492833  -0.00484955]
prey_1 ÊâßË°åÂä®‰Ωú: [-2.9473627  5.204981 ]
[WARNING]: Received an action [-2.9473627  5.204981 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-3.012547   2.1843364]
[WARNING]: Received an action [-3.012547   2.1843364] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.9527061  0.8627973]
[WARNING]: Received an action [-1.9527061  0.8627973] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.55259275 0.7821521 ]
prey_1 ÊâßË°åÂä®‰Ωú: [17.306679  6.621483]
[WARNING]: Received an action [17.306679  6.621483] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.17320812  2.04003   ]
[WARNING]: Received an action [-0.17320812  2.04003   ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.27471477  0.8835701 ]
prey_0 ÊâßË°åÂä®‰Ωú: [-0.10508901 -0.33613622]
prey_1 ÊâßË°åÂä®‰Ωú: [42.4156     5.4231834]
[WARNING]: Received an action [42.4156     5.4231834] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.0813932  3.4077685]
[WARNING]: Received an action [-1.0813932  3.4077685] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [3.1185389 1.40914  ]
[WARNING]: Received an action [3.1185389 1.40914  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.4198573 0.340357 ]
prey_1 ÊâßË°åÂä®‰Ωú: [-57.716072  10.082428]
[WARNING]: Received an action [-57.716072  10.082428] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.2332911  1.6443675]
[WARNING]: Received an action [-2.2332911  1.6443675] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.36765745  1.2504227 ]
[WARNING]: Received an action [-0.36765745  1.2504227 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.2468256  -0.09600043]
[WARNING]: Received an action [ 1.2468256  -0.09600043] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [12.518149  -7.4883204]
[WARNING]: Received an action [12.518149  -7.4883204] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.5478263  -0.21721423]
[WARNING]: Received an action [-2.5478263  -0.21721423] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.4474698 0.9165683]
[WARNING]: Received an action [1.4474698 0.9165683] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.6914119 1.4270948]
[WARNING]: Received an action [0.6914119 1.4270948] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 24.292418 -14.741315]
[WARNING]: Received an action [ 24.292418 -14.741315] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.8778691  1.8916653]
[WARNING]: Received an action [-0.8778691  1.8916653] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.19065    1.1729323]
[WARNING]: Received an action [-1.19065    1.1729323] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 5 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 5 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.00
  predator_1: -2.87
  prey_0: -2.37
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 6 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5371852   0.68951875]
[WARNING]: Received an action [-1.5371852   0.68951875] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.3639708  1.3210036]
[WARNING]: Received an action [-0.3639708  1.3210036] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.1115063 1.431984 ]
[WARNING]: Received an action [1.1115063 1.431984 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-8.965435 10.71008 ]
[WARNING]: Received an action [-8.965435 10.71008 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.832036 -0.823864]
predator_1 ÊâßË°åÂä®‰Ωú: [0.8534063 1.3860658]
[WARNING]: Received an action [0.8534063 1.3860658] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.8939668  0.38146105]
prey_1 ÊâßË°åÂä®‰Ωú: [52.243587  -6.9467883]
[WARNING]: Received an action [52.243587  -6.9467883] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2908568   0.70070994]
[WARNING]: Received an action [-1.2908568   0.70070994] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.34593287  1.0062172 ]
[WARNING]: Received an action [-0.34593287  1.0062172 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.2470572 0.7624639]
[WARNING]: Received an action [1.2470572 0.7624639] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [  7.9517803 -11.463384 ]
[WARNING]: Received an action [  7.9517803 -11.463384 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3610059   0.58867466]
[WARNING]: Received an action [-1.3610059   0.58867466] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [2.907977  1.3317322]
[WARNING]: Received an action [2.907977  1.3317322] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.1767883  0.80105853]
[WARNING]: Received an action [1.1767883  0.80105853] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [18.76531   -1.8606365]
[WARNING]: Received an action [18.76531   -1.8606365] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.02424    1.1297417]
[WARNING]: Received an action [-1.02424    1.1297417] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.362462  1.8418797]
[WARNING]: Received an action [1.362462  1.8418797] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.83813685 0.67062265]
prey_1 ÊâßË°åÂä®‰Ωú: [ 12.960359 -12.914977]
[WARNING]: Received an action [ 12.960359 -12.914977] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4809942  1.028896 ]
[WARNING]: Received an action [-1.4809942  1.028896 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.016027   1.1908906]
[WARNING]: Received an action [-1.016027   1.1908906] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.63648456 -0.3462407 ]
prey_1 ÊâßË°åÂä®‰Ωú: [-46.029316  12.501777]
[WARNING]: Received an action [-46.029316  12.501777] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3776776  0.7768701]
[WARNING]: Received an action [-1.3776776  0.7768701] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.2672817  1.6408468]
[WARNING]: Received an action [-0.2672817  1.6408468] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.4396849  0.27308872]
prey_1 ÊâßË°åÂä®‰Ωú: [-1.2065225 20.105658 ]
[WARNING]: Received an action [-1.2065225 20.105658 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4864902  1.5085787]
[WARNING]: Received an action [-1.4864902  1.5085787] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.496839   1.6747279]
[WARNING]: Received an action [-2.496839   1.6747279] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.4998405  0.97534776]
prey_1 ÊâßË°åÂä®‰Ωú: [-13.764478  13.158624]
[WARNING]: Received an action [-13.764478  13.158624] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.394672   1.4217076]
[WARNING]: Received an action [-1.394672   1.4217076] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.48936844 1.1736559 ]
[WARNING]: Received an action [0.48936844 1.1736559 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.7098696  -0.02705085]
prey_1 ÊâßË°åÂä®‰Ωú: [5.993237 9.058137]
[WARNING]: Received an action [5.993237 9.058137] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2987964   0.83620733]
[WARNING]: Received an action [-1.2987964   0.83620733] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.40415066  0.9483069 ]
prey_0 ÊâßË°åÂä®‰Ωú: [0.5853261  0.01867926]
prey_1 ÊâßË°åÂä®‰Ωú: [24.733168  4.415723]
[WARNING]: Received an action [24.733168  4.415723] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4479009  0.679536 ]
[WARNING]: Received an action [-1.4479009  0.679536 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.9480152  0.6885828]
prey_0 ÊâßË°åÂä®‰Ωú: [0.66805845 0.58744705]
prey_1 ÊâßË°åÂä®‰Ωú: [-0.5180181 12.05059  ]
[WARNING]: Received an action [-0.5180181 12.05059  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5193439  2.829746 ]
[WARNING]: Received an action [-1.5193439  2.829746 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.17649937  0.15848994]
prey_0 ÊâßË°åÂä®‰Ωú: [0.929031   0.13327697]
prey_1 ÊâßË°åÂä®‰Ωú: [-33.357723  11.007241]
[WARNING]: Received an action [-33.357723  11.007241] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.120225    0.75044376]
[WARNING]: Received an action [-1.120225    0.75044376] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.64070415  1.3169011 ]
[WARNING]: Received an action [-0.64070415  1.3169011 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 6 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 6 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.00
  predator_1: -2.81
  prey_0: -2.35
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 7 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-1.8326939 -1.2891145]
[WARNING]: Received an action [-1.8326939 -1.2891145] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.19850674 0.4247036 ]
prey_0 ÊâßË°åÂä®‰Ωú: [3.557939 3.964686]
[WARNING]: Received an action [3.557939 3.964686] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [25.053106 34.93214 ]
[WARNING]: Received an action [25.053106 34.93214 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.969185   1.9165138]
[WARNING]: Received an action [-1.969185   1.9165138] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.73116106  1.3885348 ]
[WARNING]: Received an action [-0.73116106  1.3885348 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.9217839 -1.9186695]
[WARNING]: Received an action [ 1.9217839 -1.9186695] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 51.7253   -14.000931]
[WARNING]: Received an action [ 51.7253   -14.000931] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.55922616 -0.25928032]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.50275654  0.90981627]
prey_0 ÊâßË°åÂä®‰Ωú: [0.4255815 3.238178 ]
[WARNING]: Received an action [0.4255815 3.238178 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [19.37838  -9.316981]
[WARNING]: Received an action [19.37838  -9.316981] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.125942   0.8939248]
[WARNING]: Received an action [-1.125942   0.8939248] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.6198298  0.3324609]
prey_0 ÊâßË°åÂä®‰Ωú: [5.8126197  0.04598922]
[WARNING]: Received an action [5.8126197  0.04598922] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [  5.43527  -21.675322]
[WARNING]: Received an action [  5.43527  -21.675322] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.9867967  1.7416801]
[WARNING]: Received an action [-0.9867967  1.7416801] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.6739832 1.0161872]
[WARNING]: Received an action [0.6739832 1.0161872] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [3.494441  1.6565723]
[WARNING]: Received an action [3.494441  1.6565723] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 2.062975  12.2436695]
[WARNING]: Received an action [ 2.062975  12.2436695] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.574389  2.021903]
[WARNING]: Received an action [-2.574389  2.021903] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.4091522   0.93265295]
[WARNING]: Received an action [-1.4091522   0.93265295] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [3.1400623 1.3891004]
[WARNING]: Received an action [3.1400623 1.3891004] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [84.66971   -0.7660205]
[WARNING]: Received an action [84.66971   -0.7660205] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-3.2447114  2.6447618]
[WARNING]: Received an action [-3.2447114  2.6447618] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.964414   1.4976265]
[WARNING]: Received an action [-1.964414   1.4976265] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.0315044  0.68196917]
[WARNING]: Received an action [1.0315044  0.68196917] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-63.10813  -60.468834]
[WARNING]: Received an action [-63.10813  -60.468834] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4366251   0.84179705]
[WARNING]: Received an action [-1.4366251   0.84179705] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.92997503  0.9340409 ]
prey_0 ÊâßË°åÂä®‰Ωú: [0.8737461  0.67105055]
prey_1 ÊâßË°åÂä®‰Ωú: [ 10.6521845 -26.094    ]
[WARNING]: Received an action [ 10.6521845 -26.094    ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4375252 -0.9061762]
[WARNING]: Received an action [-1.4375252 -0.9061762] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.7948172   0.58960426]
[WARNING]: Received an action [-1.7948172   0.58960426] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.6074567  0.6286117]
prey_1 ÊâßË°åÂä®‰Ωú: [ 7.043589 34.460205]
[WARNING]: Received an action [ 7.043589 34.460205] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.5596853  1.8139387]
[WARNING]: Received an action [-0.5596853  1.8139387] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.5143999  1.2542253]
[WARNING]: Received an action [-0.5143999  1.2542253] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.3692508 0.7029581]
[WARNING]: Received an action [1.3692508 0.7029581] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 0.38584703 28.861246  ]
[WARNING]: Received an action [ 0.38584703 28.861246  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7053704  2.0608642]
[WARNING]: Received an action [-1.7053704  2.0608642] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.0895667  0.6073658]
[WARNING]: Received an action [-2.0895667  0.6073658] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.1702815  0.25036025]
prey_1 ÊâßË°åÂä®‰Ωú: [-24.65281 -44.69072]
[WARNING]: Received an action [-24.65281 -44.69072] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.9733624   0.02357829]
predator_1 ÊâßË°åÂä®‰Ωú: [-1.4733553  1.4458822]
[WARNING]: Received an action [-1.4733553  1.4458822] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.33664864  0.02857618]
prey_1 ÊâßË°åÂä®‰Ωú: [-6.124318 36.930294]
[WARNING]: Received an action [-6.124318 36.930294] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3419671  1.4478581]
[WARNING]: Received an action [-1.3419671  1.4478581] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.3037253  1.1852096]
[WARNING]: Received an action [-0.3037253  1.1852096] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 7 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 7 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -2.90
  predator_1: -2.79
  prey_0: -2.54
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 8 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1670427   0.30200094]
[WARNING]: Received an action [-1.1670427   0.30200094] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.3353017 0.810251 ]
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.4037075 13.339106 ]
[WARNING]: Received an action [ 3.4037075 13.339106 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-3.8080747 -3.5025213]
[WARNING]: Received an action [-3.8080747 -3.5025213] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2267374  1.3719941]
[WARNING]: Received an action [-1.2267374  1.3719941] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.0617208   0.74951756]
[WARNING]: Received an action [-1.0617208   0.74951756] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-8.553689 12.784138]
[WARNING]: Received an action [-8.553689 12.784138] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 7.676391   -0.92296195]
[WARNING]: Received an action [ 7.676391   -0.92296195] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3842676  1.1752448]
[WARNING]: Received an action [-1.3842676  1.1752448] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.6474421 1.1376327]
[WARNING]: Received an action [0.6474421 1.1376327] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [  7.353283 -35.63966 ]
[WARNING]: Received an action [  7.353283 -35.63966 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 6.3868127 -1.5876582]
[WARNING]: Received an action [ 6.3868127 -1.5876582] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2388731 -0.2071796]
[WARNING]: Received an action [-1.2388731 -0.2071796] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.1420805 1.039784 ]
[WARNING]: Received an action [1.1420805 1.039784 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [11.697913   3.8561492]
[WARNING]: Received an action [11.697913   3.8561492] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-0.3232928 -1.7496672]
[WARNING]: Received an action [-0.3232928 -1.7496672] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.0838304  1.2265153]
[WARNING]: Received an action [-2.0838304  1.2265153] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-3.525978   1.2120719]
[WARNING]: Received an action [-3.525978   1.2120719] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.5898757 11.153176 ]
[WARNING]: Received an action [ 3.5898757 11.153176 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [6.6831126 2.9141507]
[WARNING]: Received an action [6.6831126 2.9141507] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.68650484  1.0744671 ]
[WARNING]: Received an action [-0.68650484  1.0744671 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.15782459  0.6506812 ]
prey_0 ÊâßË°åÂä®‰Ωú: [ -2.0520117 -13.844183 ]
[WARNING]: Received an action [ -2.0520117 -13.844183 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-17.93202     1.5488906]
[WARNING]: Received an action [-17.93202     1.5488906] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.095939  0.759424]
[WARNING]: Received an action [-2.095939  0.759424] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.6979432  0.43203902]
[WARNING]: Received an action [1.6979432  0.43203902] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 4.327533 24.200592]
[WARNING]: Received an action [ 4.327533 24.200592] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 3.4769773 -5.868769 ]
[WARNING]: Received an action [ 3.4769773 -5.868769 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.7029843  1.6382897]
[WARNING]: Received an action [-2.7029843  1.6382897] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.25902036  0.70404863]
prey_0 ÊâßË°åÂä®‰Ωú: [-17.08997  -11.703213]
[WARNING]: Received an action [-17.08997  -11.703213] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-0.5258284 -3.3324878]
[WARNING]: Received an action [-0.5258284 -3.3324878] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7334733  3.8920877]
[WARNING]: Received an action [-1.7334733  3.8920877] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.25247955 1.1606265 ]
[WARNING]: Received an action [0.25247955 1.1606265 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-18.274208   -6.8382163]
[WARNING]: Received an action [-18.274208   -6.8382163] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [3.4518962 6.5146313]
[WARNING]: Received an action [3.4518962 6.5146313] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.1105516  3.0237079]
[WARNING]: Received an action [-2.1105516  3.0237079] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.5427917  1.4001006]
[WARNING]: Received an action [-1.5427917  1.4001006] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-10.946079  18.896368]
[WARNING]: Received an action [-10.946079  18.896368] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 1.9081509 -1.2006782]
[WARNING]: Received an action [ 1.9081509 -1.2006782] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2920345  4.6795073]
[WARNING]: Received an action [-1.2920345  4.6795073] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.7663138  1.0799532]
[WARNING]: Received an action [-0.7663138  1.0799532] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-26.813606  15.808137]
[WARNING]: Received an action [-26.813606  15.808137] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [5.5080314 1.5369496]
[WARNING]: Received an action [5.5080314 1.5369496] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.4238214   0.41275203]
[WARNING]: Received an action [-2.4238214   0.41275203] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.25740856 1.6622624 ]
[WARNING]: Received an action [0.25740856 1.6622624 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [17.671438    0.39810884]
[WARNING]: Received an action [17.671438    0.39810884] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-1.0931196 -1.0588555]
[WARNING]: Received an action [-1.0931196 -1.0588555] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.7762024  1.5897763]
[WARNING]: Received an action [-0.7762024  1.5897763] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.7779733 0.8854474]
Episode 8 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 8 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.00
  predator_1: 17.21
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 9 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5960686  2.8532844]
[WARNING]: Received an action [-1.5960686  2.8532844] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.3759072 -0.3951075]
prey_0 ÊâßË°åÂä®‰Ωú: [-2.847536   5.7015123]
[WARNING]: Received an action [-2.847536   5.7015123] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 56.634583 -24.990782]
[WARNING]: Received an action [ 56.634583 -24.990782] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3524563   0.75640684]
[WARNING]: Received an action [-1.3524563   0.75640684] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.56405604  0.00716801]
prey_0 ÊâßË°åÂä®‰Ωú: [-3.93244   5.419425]
[WARNING]: Received an action [-3.93244   5.419425] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 1.601315 20.9845  ]
[WARNING]: Received an action [ 1.601315 20.9845  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.4135152  0.9145071]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.21137379  0.33411366]
prey_0 ÊâßË°åÂä®‰Ωú: [-15.924579  21.219229]
[WARNING]: Received an action [-15.924579  21.219229] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-19.599188  32.0912  ]
[WARNING]: Received an action [-19.599188  32.0912  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2840086  0.9845979]
[WARNING]: Received an action [-1.2840086  0.9845979] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.5070012  0.2160545]
prey_0 ÊâßË°åÂä®‰Ωú: [ -0.48116195 -12.482506  ]
[WARNING]: Received an action [ -0.48116195 -12.482506  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 20.686296 -31.418985]
[WARNING]: Received an action [ 20.686296 -31.418985] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.0599345  1.1498474]
[WARNING]: Received an action [-1.0599345  1.1498474] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.2722456   0.17623517]
prey_0 ÊâßË°åÂä®‰Ωú: [-8.456167   1.5345329]
[WARNING]: Received an action [-8.456167   1.5345329] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-157.26286     9.680492]
[WARNING]: Received an action [-157.26286     9.680492] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.3761369   0.73950934]
[WARNING]: Received an action [-1.3761369   0.73950934] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 0.09337683 -0.16188067]
prey_0 ÊâßË°åÂä®‰Ωú: [-31.392149 -14.854249]
[WARNING]: Received an action [-31.392149 -14.854249] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-118.725494    -2.3074186]
[WARNING]: Received an action [-118.725494    -2.3074186] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1238912  1.0710725]
[WARNING]: Received an action [-1.1238912  1.0710725] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.35067278 -0.46261832]
prey_0 ÊâßË°åÂä®‰Ωú: [-7.0531397  4.9764824]
[WARNING]: Received an action [-7.0531397  4.9764824] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [68.98222  57.942818]
[WARNING]: Received an action [68.98222  57.942818] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.83732986  0.7754916 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.39355648  0.29905093]
prey_0 ÊâßË°åÂä®‰Ωú: [4.6352615  0.43549842]
[WARNING]: Received an action [4.6352615  0.43549842] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-0.622088   1.3478813]
[WARNING]: Received an action [-0.622088   1.3478813] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1103294  0.8161186]
[WARNING]: Received an action [-1.1103294  0.8161186] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.05182813 0.54104435]
prey_0 ÊâßË°åÂä®‰Ωú: [-7.0111938 -4.239873 ]
[WARNING]: Received an action [-7.0111938 -4.239873 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 79.166245 -11.70445 ]
[WARNING]: Received an action [ 79.166245 -11.70445 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.7439816  1.1552217]
[WARNING]: Received an action [-0.7439816  1.1552217] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.06393398  0.11794458]
prey_0 ÊâßË°åÂä®‰Ωú: [ 4.6613607  -0.96761215]
[WARNING]: Received an action [ 4.6613607  -0.96761215] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 8.311224  -7.7064295]
[WARNING]: Received an action [ 8.311224  -7.7064295] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.59942615  0.78644025]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.19111541 -0.55250347]
prey_0 ÊâßË°åÂä®‰Ωú: [-4.3981514 -2.9169064]
[WARNING]: Received an action [-4.3981514 -2.9169064] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-19.55896   15.229955]
[WARNING]: Received an action [-19.55896   15.229955] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.51788664  0.4950717 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.20998625 -0.22814614]
prey_0 ÊâßË°åÂä®‰Ωú: [ 4.658043  -1.4659233]
[WARNING]: Received an action [ 4.658043  -1.4659233] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 7.1325707 18.488892 ]
[WARNING]: Received an action [ 7.1325707 18.488892 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.72041327  0.33834618]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.2999817   0.03270826]
Episode 9 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 9 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -2.93
  predator_1: -1.30
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 10 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-0.975772  2.98557 ]
[WARNING]: Received an action [-0.975772  2.98557 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.0419337 1.0824139]
[WARNING]: Received an action [1.0419337 1.0824139] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-10.305822  -11.5580635]
[WARNING]: Received an action [-10.305822  -11.5580635] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-24.137554 -10.430658]
[WARNING]: Received an action [-24.137554 -10.430658] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.6116211  1.2063123]
[WARNING]: Received an action [-2.6116211  1.2063123] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.2360902  1.7700219]
[WARNING]: Received an action [-1.2360902  1.7700219] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-6.7915583 -2.518356 ]
[WARNING]: Received an action [-6.7915583 -2.518356 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [47.865128 38.095608]
[WARNING]: Received an action [47.865128 38.095608] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.9131124  1.8588309]
[WARNING]: Received an action [-2.9131124  1.8588309] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.63408494 0.49440932]
prey_0 ÊâßË°åÂä®‰Ωú: [5.124043  6.4526834]
[WARNING]: Received an action [5.124043  6.4526834] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [27.14077  15.726249]
[WARNING]: Received an action [27.14077  15.726249] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.8743296  1.5321933]
[WARNING]: Received an action [-1.8743296  1.5321933] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.6353776  1.395802 ]
[WARNING]: Received an action [-1.6353776  1.395802 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.717338 27.219967]
[WARNING]: Received an action [ 1.717338 27.219967] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [40.36323  23.893425]
[WARNING]: Received an action [40.36323  23.893425] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.9255454  2.6816235]
[WARNING]: Received an action [-0.9255454  2.6816235] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.78227746  0.7104888 ]
prey_0 ÊâßË°åÂä®‰Ωú: [-0.17226368 26.016768  ]
[WARNING]: Received an action [-0.17226368 26.016768  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [  3.7645996 -58.16969  ]
[WARNING]: Received an action [  3.7645996 -58.16969  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1112511  2.1216106]
[WARNING]: Received an action [-1.1112511  2.1216106] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.20524517 0.8941971 ]
prey_0 ÊâßË°åÂä®‰Ωú: [1.1687307 2.1845303]
[WARNING]: Received an action [1.1687307 2.1845303] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-26.273355  -6.657909]
[WARNING]: Received an action [-26.273355  -6.657909] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2796596  2.1737251]
[WARNING]: Received an action [-1.2796596  2.1737251] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.29927635  1.0168442 ]
[WARNING]: Received an action [-0.29927635  1.0168442 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 9.264577 -3.373341]
[WARNING]: Received an action [ 9.264577 -3.373341] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ -7.7849846 -33.687935 ]
[WARNING]: Received an action [ -7.7849846 -33.687935 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5971007   0.92218304]
[WARNING]: Received an action [-1.5971007   0.92218304] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.2853908  1.3483198]
[WARNING]: Received an action [-0.2853908  1.3483198] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.15258396 2.2885113 ]
[WARNING]: Received an action [0.15258396 2.2885113 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-10.262113  20.856699]
[WARNING]: Received an action [-10.262113  20.856699] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4704791  1.2702903]
[WARNING]: Received an action [-1.4704791  1.2702903] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.41763315  1.2649609 ]
[WARNING]: Received an action [-0.41763315  1.2649609 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-4.1591086 -4.9928327]
[WARNING]: Received an action [-4.1591086 -4.9928327] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-46.923885  51.963364]
[WARNING]: Received an action [-46.923885  51.963364] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6669497  1.1699212]
[WARNING]: Received an action [-1.6669497  1.1699212] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.50085443  0.80305266]
prey_0 ÊâßË°åÂä®‰Ωú: [ 5.3721967 -1.4663215]
[WARNING]: Received an action [ 5.3721967 -1.4663215] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 22.615221 -19.041653]
[WARNING]: Received an action [ 22.615221 -19.041653] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.280351   1.0637859]
[WARNING]: Received an action [-1.280351   1.0637859] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.03950846  1.6906016 ]
[WARNING]: Received an action [-0.03950846  1.6906016 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-4.179842  2.259973]
[WARNING]: Received an action [-4.179842  2.259973] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 23.588093 -31.192366]
[WARNING]: Received an action [ 23.588093 -31.192366] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6843488  1.9665675]
[WARNING]: Received an action [-1.6843488  1.9665675] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.64362586 1.5634286 ]
[WARNING]: Received an action [0.64362586 1.5634286 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [  3.6883717 -16.249321 ]
[WARNING]: Received an action [  3.6883717 -16.249321 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-1.4483566 24.764303 ]
[WARNING]: Received an action [-1.4483566 24.764303 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.984908   1.9668212]
[WARNING]: Received an action [-2.984908   1.9668212] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.2173798  0.8019817]
[WARNING]: Received an action [-1.2173798  0.8019817] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 10 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 10 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -4.00
  predator_1: -2.92
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50
Êé®ÁêÜÂÆåÊàê!
[0m
