['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-01 18:21:19,627	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-01 18:21:20,239	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-01 18:21:20 (running for 00:00:00.13)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_bfbc9_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=2864454)[0m 2025-07-01 18:21:22,598	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html


[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865654)[0m 2025-07-01 18:21:25,011	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
== Status ==
Current time: 2025-07-01 18:21:25 (running for 00:00:05.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_bfbc9_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=2864454)[0m Install gputil for GPU system monitoring.
[36m(_WandbLoggingActor pid=2866614)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=2866614)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/wandb/run-20250701_182128-bfbc9_00000
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Syncing run PPO_env_bfbc9_00000
[36m(_WandbLoggingActor pid=2866614)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=2866614)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/bfbc9_00000


== Status ==
Current time: 2025-07-01 18:21:30 (running for 00:00:10.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+
| Trial name          | status   | loc                  |
|---------------------+----------+----------------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |
+---------------------+----------+----------------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-453.0292353747871,num_env_steps_sampled_lifetime=4000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000000)
[36m(MultiAgentEnvRunner pid=2865655)[0m 2025-07-01 18:21:25,037	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12132x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000000)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:21:35 (running for 00:00:15.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      1 |          5.80523 | 4000 |          -453.029 |            -91.5439 |            -79.6823 |        -217.343 |          -64.46 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-456.3140537617527,num_env_steps_sampled_lifetime=8000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000001)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12144x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000001)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:21:40 (running for 00:00:20.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      2 |          11.1632 | 8000 |          -456.314 |            -88.9911 |            -88.4163 |        -202.556 |         -76.351 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-449.9222623746607,num_env_steps_sampled_lifetime=12000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000002)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11968x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000002)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:21:45 (running for 00:00:25.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      3 |          17.0799 | 12000 |          -449.922 |            -83.9819 |            -74.3644 |         -208.34 |        -83.2359 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-445.18256266282987,num_env_steps_sampled_lifetime=16000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000003)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12045x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000003)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:21:50 (running for 00:00:30.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      4 |          22.5603 | 16000 |          -445.183 |             -81.649 |            -76.0916 |        -205.868 |        -81.5744 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:21:55 (running for 00:00:35.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      4 |          22.5603 | 16000 |          -445.183 |             -81.649 |            -76.0916 |        -205.868 |        -81.5744 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-433.16743712971174,num_env_steps_sampled_lifetime=20000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000004)
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000004)...
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11856x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:00 (running for 00:00:40.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      5 |          28.2289 | 20000 |          -433.167 |             -83.085 |             -74.053 |        -203.982 |        -72.0473 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-435.35343389231326,num_env_steps_sampled_lifetime=24000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000005)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12222x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000005)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:22:05 (running for 00:00:45.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      6 |          33.6406 | 24000 |          -435.353 |            -85.3105 |            -74.8688 |        -199.996 |        -75.1781 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-432.23827977520114,num_env_steps_sampled_lifetime=28000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000006)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11912x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:10 (running for 00:00:50.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      7 |          38.9806 | 28000 |          -432.238 |            -83.9922 |            -76.0305 |        -197.962 |        -74.2534 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-433.37683351577937,num_env_steps_sampled_lifetime=32000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000007)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11942x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000007)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:22:15 (running for 00:00:55.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      8 |          44.3788 | 32000 |          -433.377 |            -81.5397 |            -76.9231 |        -198.657 |        -76.2571 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-429.3548409792523,num_env_steps_sampled_lifetime=36000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000008)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12199x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000008)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:20 (running for 00:01:00.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |      9 |          49.6171 | 36000 |          -429.355 |            -79.6254 |            -78.5873 |        -197.996 |        -73.1466 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-427.91976054598706,num_env_steps_sampled_lifetime=40000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000009)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12036x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000009)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:25 (running for 00:01:05.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     10 |          55.0966 | 40000 |           -427.92 |            -78.4443 |            -77.1482 |        -197.962 |        -74.3656 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-429.6907370750121,num_env_steps_sampled_lifetime=44000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000010)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11868x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000010)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:30 (running for 00:01:10.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     11 |          60.8358 | 44000 |          -429.691 |            -76.9848 |            -78.3565 |        -198.672 |        -75.6772 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-427.8170486923854,num_env_steps_sampled_lifetime=48000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000011)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12095x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000011)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:35 (running for 00:01:15.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     12 |          66.4622 | 48000 |          -427.817 |            -73.9881 |            -79.6948 |        -198.971 |        -75.1633 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:22:40 (running for 00:01:20.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     12 |          66.4622 | 48000 |          -427.817 |            -73.9881 |            -79.6948 |        -198.971 |        -75.1633 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-426.43485812579587,num_env_steps_sampled_lifetime=52000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000012)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11951x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000012)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:45 (running for 00:01:25.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     13 |          73.2442 | 52000 |          -426.435 |            -72.9742 |            -80.7175 |        -196.951 |        -75.7923 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-425.17739307810024,num_env_steps_sampled_lifetime=56000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000013)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12158x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000013)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:22:50 (running for 00:01:30.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     14 |          79.0233 | 56000 |          -425.177 |            -72.6712 |            -80.7801 |        -195.886 |        -75.8401 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-424.82532883620144,num_env_steps_sampled_lifetime=60000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000014)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11868x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000014)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:22:56 (running for 00:01:35.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     15 |          84.9826 | 60000 |          -424.825 |            -71.4462 |            -81.6485 |        -195.614 |        -76.1166 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-421.3395879950403,num_env_steps_sampled_lifetime=64000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000015)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000015)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:23:01 (running for 00:01:40.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     16 |          90.5588 | 64000 |           -421.34 |            -69.4804 |             -81.276 |        -195.421 |        -75.1622 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-420.825661464534,num_env_steps_sampled_lifetime=68000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000016)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000016)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:23:06 (running for 00:01:45.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     17 |          96.3036 | 68000 |          -420.826 |            -69.6373 |            -80.4852 |        -196.246 |        -74.4575 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-419.05958636514197,num_env_steps_sampled_lifetime=72000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000017)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000017)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:23:11 (running for 00:01:50.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     18 |          102.095 | 72000 |           -419.06 |            -68.3254 |            -80.0605 |        -196.312 |        -74.3612 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:23:16 (running for 00:01:56.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     18 |          102.095 | 72000 |           -419.06 |            -68.3254 |            -80.0605 |        -196.312 |        -74.3612 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-419.2235188809757,num_env_steps_sampled_lifetime=76000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000018)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11942x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000018)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:23:21 (running for 00:02:01.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     19 |          108.016 | 76000 |          -419.224 |            -67.1895 |             -80.722 |        -196.414 |        -74.8977 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-417.2756124636173,num_env_steps_sampled_lifetime=80000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000019)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12089x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000019)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:23:26 (running for 00:02:06.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     20 |          113.778 | 80000 |          -417.276 |            -66.8391 |            -79.2706 |         -196.18 |        -74.9861 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-414.65335353649687,num_env_steps_sampled_lifetime=84000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000020)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12149x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000020)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:23:31 (running for 00:02:11.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     21 |          119.632 | 84000 |          -414.653 |            -64.1602 |            -79.3915 |        -196.044 |         -75.058 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-414.6789543815566,num_env_steps_sampled_lifetime=88000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000021)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000021)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:23:36 (running for 00:02:16.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     22 |          125.422 | 88000 |          -414.679 |            -63.8032 |            -79.1586 |        -196.262 |        -75.4555 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-415.1039099634697,num_env_steps_sampled_lifetime=92000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000022)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11988x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000022)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:23:41 (running for 00:02:21.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     23 |           130.99 | 92000 |          -415.104 |              -63.23 |            -79.8304 |        -196.587 |        -75.4561 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-414.13098278960814,num_env_steps_sampled_lifetime=96000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000023)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11983x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000023)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:23:46 (running for 00:02:26.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     24 |          136.319 | 96000 |          -414.131 |            -63.3487 |            -79.3153 |        -196.059 |        -75.4084 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-412.31670125181466,num_env_steps_sampled_lifetime=100000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000024)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12209x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000024)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:23:51 (running for 00:02:31.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     25 |          142.125 | 100000 |          -412.317 |            -61.9969 |            -79.7726 |        -195.311 |         -75.236 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:23:56 (running for 00:02:36.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     25 |          142.125 | 100000 |          -412.317 |            -61.9969 |            -79.7726 |        -195.311 |         -75.236 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-409.98423825535644,num_env_steps_sampled_lifetime=104000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000025)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11964x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000025)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:01 (running for 00:02:41.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     26 |          147.855 | 104000 |          -409.984 |            -59.6107 |            -79.4883 |        -194.906 |         -75.979 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-406.1583189549211,num_env_steps_sampled_lifetime=108000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000026)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000026)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m warning: velocites provided but types or ids not provided, returning only distan
[36m(MultiAgentEnvRunner pid=2865654)[0m ce and velocity values
== Status ==
Current time: 2025-07-01 18:24:06 (running for 00:02:46.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     27 |          154.664 | 108000 |          -406.158 |            -57.5048 |            -78.7201 |        -194.692 |        -75.2412 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-404.57751399998466,num_env_steps_sampled_lifetime=112000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000027)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11927x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000027)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:24:11 (running for 00:02:51.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     28 |          160.379 | 112000 |          -404.578 |            -55.3645 |            -79.6201 |        -194.246 |        -75.3472 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-403.48163970436485,num_env_steps_sampled_lifetime=116000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000028)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12204x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000028)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:16 (running for 00:02:56.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     29 |          166.215 | 116000 |          -403.482 |            -55.0162 |            -79.3508 |        -194.596 |        -74.5189 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-404.4522754034282,num_env_steps_sampled_lifetime=120000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000029)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11928x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000029)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:21 (running for 00:03:01.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     30 |          172.056 | 120000 |          -404.452 |            -53.5261 |            -80.7097 |        -194.504 |        -75.7129 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:24:26 (running for 00:03:06.69)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     30 |          172.056 | 120000 |          -404.452 |            -53.5261 |            -80.7097 |        -194.504 |        -75.7129 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-401.9904508635885,num_env_steps_sampled_lifetime=124000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000030)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000030)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:31 (running for 00:03:11.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     31 |          177.872 | 124000 |           -401.99 |            -50.9713 |            -81.0905 |        -194.465 |        -75.4632 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-398.98021509559067,num_env_steps_sampled_lifetime=128000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000031)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12072x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000031)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:37 (running for 00:03:16.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     32 |          184.212 | 128000 |           -398.98 |             -49.822 |            -81.5637 |        -194.714 |        -72.8802 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-396.04281896689184,num_env_steps_sampled_lifetime=132000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000032)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000032)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:42 (running for 00:03:21.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     33 |          189.661 | 132000 |          -396.043 |            -48.1069 |            -81.2788 |        -194.931 |        -71.7266 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-394.5360662893695,num_env_steps_sampled_lifetime=136000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000033)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11928x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000033)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:24:47 (running for 00:03:26.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     34 |          195.282 | 136000 |          -394.536 |            -46.6065 |            -80.6746 |        -194.155 |        -73.1001 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-391.3643659798808,num_env_steps_sampled_lifetime=140000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000034)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000034)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:52 (running for 00:03:31.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     35 |          201.254 | 140000 |          -391.364 |            -44.8835 |            -81.0664 |        -193.882 |        -71.5325 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-385.7982446248133,num_env_steps_sampled_lifetime=144000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000035)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12010x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000035)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:24:57 (running for 00:03:37.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     36 |          207.409 | 144000 |          -385.798 |            -42.4344 |            -80.8384 |        -192.214 |        -70.3111 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:25:02 (running for 00:03:42.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     36 |          207.409 | 144000 |          -385.798 |            -42.4344 |            -80.8384 |        -192.214 |        -70.3111 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-384.45535794285314,num_env_steps_sampled_lifetime=148000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000036)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12107x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000036)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:07 (running for 00:03:47.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     37 |          213.582 | 148000 |          -384.455 |            -42.2289 |            -80.1815 |        -191.377 |         -70.668 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-384.16695746486175,num_env_steps_sampled_lifetime=152000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000037)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12015x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000037)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:25:12 (running for 00:03:52.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     38 |          219.374 | 152000 |          -384.167 |            -41.6042 |            -79.1807 |         -193.05 |        -70.3319 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-381.7400488061258,num_env_steps_sampled_lifetime=156000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000038)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11952x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000038)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:17 (running for 00:03:57.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     39 |          225.572 | 156000 |           -381.74 |            -40.3693 |            -79.4797 |        -193.072 |        -68.8188 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-378.4408782203147,num_env_steps_sampled_lifetime=160000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000039)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11947x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000039)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:22 (running for 00:04:02.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     40 |          231.502 | 160000 |          -378.441 |            -37.9946 |            -79.2185 |        -193.712 |        -67.5156 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:25:27 (running for 00:04:07.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     40 |          231.502 | 160000 |          -378.441 |            -37.9946 |            -79.2185 |        -193.712 |        -67.5156 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-377.96332636112,num_env_steps_sampled_lifetime=164000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000040)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12233x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000040)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:32 (running for 00:04:12.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     41 |          237.621 | 164000 |          -377.963 |            -37.4414 |             -79.069 |        -193.785 |        -67.6677 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-376.21352422395574,num_env_steps_sampled_lifetime=168000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000041)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000041)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:25:37 (running for 00:04:17.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     42 |          243.532 | 168000 |          -376.214 |            -35.5273 |            -80.0698 |        -193.321 |        -67.2955 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-375.9891100389691,num_env_steps_sampled_lifetime=172000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000042)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11892x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000042)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:42 (running for 00:04:22.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     43 |          249.374 | 172000 |          -375.989 |            -34.6016 |            -81.2308 |         -193.58 |        -66.5768 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-373.45377796679634,num_env_steps_sampled_lifetime=176000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000043)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12096x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000043)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:47 (running for 00:04:27.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     44 |          255.536 | 176000 |          -373.454 |            -33.7664 |            -80.1602 |        -194.095 |        -65.4322 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-371.6826510763611,num_env_steps_sampled_lifetime=180000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000044)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000044)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:52 (running for 00:04:32.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     45 |          261.334 | 180000 |          -371.683 |            -30.9666 |            -81.3454 |        -193.792 |        -65.5789 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-373.94955900271833,num_env_steps_sampled_lifetime=184000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000045)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000045)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:25:57 (running for 00:04:37.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     46 |          267.246 | 184000 |           -373.95 |            -31.6996 |            -81.6789 |        -194.923 |        -65.6476 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:26:02 (running for 00:04:42.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     46 |          267.246 | 184000 |           -373.95 |            -31.6996 |            -81.6789 |        -194.923 |        -65.6476 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-370.4404595948338,num_env_steps_sampled_lifetime=188000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000046)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000046)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:26:07 (running for 00:04:47.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     47 |          272.993 | 188000 |           -370.44 |            -29.8634 |            -81.5987 |        -194.553 |        -64.4258 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-369.16014819450845,num_env_steps_sampled_lifetime=192000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000047)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12056x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000047)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:26:12 (running for 00:04:52.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     48 |          278.842 | 192000 |           -369.16 |            -29.0778 |            -81.1187 |        -195.304 |        -63.6601 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-369.82117734798936,num_env_steps_sampled_lifetime=196000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000048)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11944x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000048)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not pro
[36m(MultiAgentEnvRunner pid=2865655)[0m vided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:26:17 (running for 00:04:57.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     49 |          284.592 | 196000 |          -369.821 |            -27.7762 |            -81.8648 |        -196.091 |        -64.0895 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-370.78009147051563,num_env_steps_sampled_lifetime=200000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000049)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12081x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000049)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:26:22 (running for 00:05:02.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     50 |          290.457 | 200000 |           -370.78 |            -27.0585 |            -82.1898 |        -197.509 |        -64.0223 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-370.5351236339481,num_env_steps_sampled_lifetime=204000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000050)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12068x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000050)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:26:28 (running for 00:05:07.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     51 |          296.333 | 204000 |          -370.535 |            -25.8325 |             -83.495 |        -197.539 |        -63.6685 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-369.9832317639619,num_env_steps_sampled_lifetime=208000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000051)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11886x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000051)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:26:33 (running for 00:05:12.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     52 |          302.055 | 208000 |          -369.983 |            -25.0477 |            -82.7238 |        -199.624 |        -62.5872 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:26:38 (running for 00:05:17.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     52 |          302.055 | 208000 |          -369.983 |            -25.0477 |            -82.7238 |        -199.624 |        -62.5872 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-367.2656624604846,num_env_steps_sampled_lifetime=212000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000052)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000052)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:26:43 (running for 00:05:22.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     53 |          308.003 | 212000 |          -367.266 |            -23.5581 |            -83.8878 |        -199.964 |        -59.8562 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-364.097253117776,num_env_steps_sampled_lifetime=216000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000053)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000053)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:26:48 (running for 00:05:27.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     54 |           313.96 | 216000 |          -364.097 |            -21.0638 |            -84.9588 |        -199.601 |        -58.4731 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-363.795853367355,num_env_steps_sampled_lifetime=220000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000054)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11995x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000054)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:26:53 (running for 00:05:33.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     55 |          319.859 | 220000 |          -363.796 |            -18.5708 |            -85.1114 |        -201.169 |        -58.9446 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-364.68847542546877,num_env_steps_sampled_lifetime=224000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000055)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12065x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000055)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:26:58 (running for 00:05:38.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     56 |          325.736 | 224000 |          -364.688 |            -18.0668 |            -84.2373 |        -202.997 |        -59.3871 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-365.66334647206634,num_env_steps_sampled_lifetime=228000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000056)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12144x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000056)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:03 (running for 00:05:43.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     57 |          331.879 | 228000 |          -365.663 |            -16.6271 |            -83.6763 |        -204.503 |        -60.8568 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:27:08 (running for 00:05:48.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     57 |          331.879 | 228000 |          -365.663 |            -16.6271 |            -83.6763 |        -204.503 |        -60.8568 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-365.3415248311351,num_env_steps_sampled_lifetime=232000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000057)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11904x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000057)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance
[36m(MultiAgentEnvRunner pid=2865655)[0m  and velocity values
== Status ==
Current time: 2025-07-01 18:27:13 (running for 00:05:53.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     58 |          337.615 | 232000 |          -365.342 |            -16.5151 |            -83.6923 |         -204.86 |        -60.2741 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-364.1952080706601,num_env_steps_sampled_lifetime=236000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000058)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12059x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000058)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:18 (running for 00:05:58.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     59 |          343.753 | 236000 |          -364.195 |             -14.628 |            -82.9168 |        -207.267 |        -59.3838 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-366.6009379325744,num_env_steps_sampled_lifetime=240000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000059)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000059)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:23 (running for 00:06:03.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     60 |          349.475 | 240000 |          -366.601 |            -14.7789 |            -83.2223 |        -208.264 |        -60.3359 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-366.14650512713996,num_env_steps_sampled_lifetime=244000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000060)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000060)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:28 (running for 00:06:08.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     61 |          355.183 | 244000 |          -366.147 |            -15.4614 |            -80.7846 |         -209.38 |        -60.5202 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-366.30170303351684,num_env_steps_sampled_lifetime=248000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000061)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12108x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000061)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:33 (running for 00:06:13.33)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     62 |          360.621 | 248000 |          -366.302 |            -15.0121 |            -81.1068 |        -209.852 |         -60.331 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-363.5596191495244,num_env_steps_sampled_lifetime=252000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000062)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000062)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:38 (running for 00:06:18.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     63 |          366.261 | 252000 |           -363.56 |            -12.7172 |            -82.7242 |        -209.043 |        -59.0757 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-363.6313517396638,num_env_steps_sampled_lifetime=256000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000063)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000063)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:43 (running for 00:06:23.41)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     64 |          371.808 | 256000 |          -363.631 |            -11.1346 |            -82.7987 |        -209.554 |        -60.1436 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-362.80995455124497,num_env_steps_sampled_lifetime=260000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000064)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000064)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:27:48 (running for 00:06:28.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     65 |          377.219 | 260000 |           -362.81 |             -10.913 |            -81.5776 |        -209.803 |        -60.5167 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:27:53 (running for 00:06:33.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     65 |          377.219 | 260000 |           -362.81 |             -10.913 |            -81.5776 |        -209.803 |        -60.5167 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-363.13933560798984,num_env_steps_sampled_lifetime=264000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000065)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12053x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000065)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:27:58 (running for 00:06:38.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     66 |          382.608 | 264000 |          -363.139 |            -10.0327 |            -81.8443 |        -210.548 |        -60.7144 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-361.2905577856423,num_env_steps_sampled_lifetime=268000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000066)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12007x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000066)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:28:03 (running for 00:06:43.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     67 |          387.798 | 268000 |          -361.291 |            -10.2252 |            -79.6893 |        -210.458 |        -60.9184 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-358.86038915564114,num_env_steps_sampled_lifetime=272000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000067)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12072x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000067)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:09 (running for 00:06:48.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     68 |           393.68 | 272000 |           -358.86 |            -8.02854 |            -79.7376 |        -210.283 |         -60.811 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-359.3299647932683,num_env_steps_sampled_lifetime=276000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000068)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12091x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000068)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:14 (running for 00:06:53.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     69 |          399.326 | 276000 |           -359.33 |             -8.1075 |            -80.4458 |        -210.886 |        -59.8903 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-358.6532054254497,num_env_steps_sampled_lifetime=280000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000069)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11885x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000069)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:28:19 (running for 00:06:58.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     70 |          404.971 | 280000 |          -358.653 |            -9.23738 |            -81.1352 |        -208.934 |        -59.3462 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-356.0362652459659,num_env_steps_sampled_lifetime=284000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000070)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12144x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000070)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:24 (running for 00:07:03.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     71 |          410.531 | 284000 |          -356.036 |            -8.34688 |            -81.2811 |        -208.325 |        -58.0828 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-359.54761931740205,num_env_steps_sampled_lifetime=288000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000071)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000071)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:29 (running for 00:07:09.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     72 |           415.99 | 288000 |          -359.548 |             -9.4214 |            -82.5774 |        -209.301 |        -58.2476 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-357.0434096961215,num_env_steps_sampled_lifetime=292000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000072)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11934x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000072)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:34 (running for 00:07:14.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     73 |          421.484 | 292000 |          -357.043 |            -8.53027 |            -82.1423 |        -208.836 |        -57.5346 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-353.9965937238981,num_env_steps_sampled_lifetime=296000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000073)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12054x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000073)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:28:39 (running for 00:07:19.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     74 |          426.661 | 296000 |          -353.997 |            -7.16816 |            -82.1559 |        -208.293 |        -56.3792 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-352.10148757777716,num_env_steps_sampled_lifetime=300000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000074)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000074)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:44 (running for 00:07:24.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     75 |           432.15 | 300000 |          -352.101 |            -7.98735 |            -80.4319 |        -208.566 |         -55.116 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-349.62177438668596,num_env_steps_sampled_lifetime=304000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
== Status ==
Current time: 2025-07-01 18:28:49 (running for 00:07:29.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     76 |          437.588 | 304000 |          -349.622 |            -7.36781 |            -79.4962 |        -208.759 |        -53.9991 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000075)


[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000075)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:54 (running for 00:07:34.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     76 |          437.588 | 304000 |          -349.622 |            -7.36781 |            -79.4962 |        -208.759 |        -53.9991 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-345.7359861763609,num_env_steps_sampled_lifetime=308000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000076)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11964x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000076)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:28:59 (running for 00:07:39.41)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     77 |          442.993 | 308000 |          -345.736 |            -6.82823 |             -79.027 |        -206.147 |        -53.7338 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-346.15789007930215,num_env_steps_sampled_lifetime=312000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000077)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000077)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:04 (running for 00:07:44.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     78 |          448.349 | 312000 |          -346.158 |            -8.36038 |            -78.7448 |        -204.965 |        -54.0878 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-345.17713639469906,num_env_steps_sampled_lifetime=316000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000078)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000078)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:09 (running for 00:07:49.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     79 |          453.704 | 316000 |          -345.177 |            -9.08044 |            -76.7691 |        -203.625 |        -55.7024 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-343.8244052579441,num_env_steps_sampled_lifetime=320000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000079)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000079)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:14 (running for 00:07:54.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     80 |          459.214 | 320000 |          -343.824 |            -10.5746 |            -75.9086 |        -202.412 |        -54.9291 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-340.2685598632464,num_env_steps_sampled_lifetime=324000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000080)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000080)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:19 (running for 00:07:59.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     81 |          464.727 | 324000 |          -340.269 |            -9.81365 |            -75.9848 |        -202.112 |        -52.3581 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-341.7391992162382,num_env_steps_sampled_lifetime=328000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000081)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12115x across cluster][0m
[36m(MultiAgentEnvRunner pid=2865654)[0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000081)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:24 (running for 00:08:04.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     82 |          470.256 | 328000 |          -341.739 |            -10.5169 |            -75.6193 |         -202.76 |        -52.8427 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-340.21379173227285,num_env_steps_sampled_lifetime=332000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000082)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11957x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000082)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:29:29 (running for 00:08:09.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     83 |          475.875 | 332000 |          -340.214 |            -10.9267 |            -75.2312 |        -202.015 |         -52.041 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-339.6536253460098,num_env_steps_sampled_lifetime=336000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000083)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12036x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000083)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:34 (running for 00:08:14.67)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     84 |           481.34 | 336000 |          -339.654 |            -11.7665 |            -75.7157 |        -199.495 |        -52.6769 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-339.4421406441217,num_env_steps_sampled_lifetime=340000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000084)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000084)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:40 (running for 00:08:19.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     85 |          486.736 | 340000 |          -339.442 |            -12.1429 |             -74.645 |        -199.654 |        -52.9998 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-339.9789268836968,num_env_steps_sampled_lifetime=344000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000085)
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000085)...
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11995x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:29:45 (running for 00:08:24.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     86 |          491.924 | 344000 |          -339.979 |            -11.8698 |            -75.3983 |        -198.923 |         -53.788 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:29:50 (running for 00:08:29.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     86 |          491.924 | 344000 |          -339.979 |            -11.8698 |            -75.3983 |        -198.923 |         -53.788 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-338.265631098218,num_env_steps_sampled_lifetime=348000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000086)
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000086)...
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12021x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:29:55 (running for 00:08:34.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     87 |          497.619 | 348000 |          -338.266 |            -10.8006 |             -74.134 |         -199.57 |        -53.7616 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-338.31794851573636,num_env_steps_sampled_lifetime=352000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000087)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12188x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000087)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:30:00 (running for 00:08:39.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     88 |          502.846 | 352000 |          -338.318 |            -11.3012 |            -73.2015 |        -199.075 |        -54.7402 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-338.30615615158126,num_env_steps_sampled_lifetime=356000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000088)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000088)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:30:05 (running for 00:08:44.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     89 |          508.481 | 356000 |          -338.306 |            -12.5005 |            -71.6544 |        -199.628 |        -54.5237 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-336.5742440995072,num_env_steps_sampled_lifetime=360000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000089)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000089)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:30:10 (running for 00:08:50.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     90 |           513.87 | 360000 |          -336.574 |             -13.533 |            -72.2344 |        -197.995 |        -52.8119 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-334.8412502026225,num_env_steps_sampled_lifetime=364000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000090)
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000090)...
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11989x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:30:15 (running for 00:08:55.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     91 |          519.483 | 364000 |          -334.841 |             -14.015 |            -72.5696 |        -196.124 |        -52.1329 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-334.8942989037299,num_env_steps_sampled_lifetime=368000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000091)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12191x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000091)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m warning: velocites provided but types or ids not provided, return
[36m(MultiAgentEnvRunner pid=2865654)[0m ing only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:30:20 (running for 00:09:00.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     92 |          524.993 | 368000 |          -334.894 |            -14.1142 |            -73.5315 |        -195.087 |        -52.1616 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-337.26550703402455,num_env_steps_sampled_lifetime=372000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000092)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11951x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000092)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:30:25 (running for 00:09:05.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     93 |          530.612 | 372000 |          -337.266 |            -16.0708 |             -72.271 |        -195.764 |        -53.1595 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-334.7188523971516,num_env_steps_sampled_lifetime=376000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000093)
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000093)...
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12168x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:30:30 (running for 00:09:10.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     94 |          536.274 | 376000 |          -334.719 |            -15.4919 |            -71.6632 |        -193.366 |        -54.1974 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-337.0393452455286,num_env_steps_sampled_lifetime=380000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000094)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11952x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000094)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:30:35 (running for 00:09:15.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     95 |          541.673 | 380000 |          -337.039 |            -16.1317 |            -71.1592 |        -196.123 |        -53.6258 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-337.6652001659714,num_env_steps_sampled_lifetime=384000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000095)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11938x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000095)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:30:40 (running for 00:09:20.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     96 |          547.084 | 384000 |          -337.665 |            -15.7138 |            -70.9326 |         -197.03 |        -53.9891 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-336.1893027827321,num_env_steps_sampled_lifetime=388000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
== Status ==
Current time: 2025-07-01 18:30:45 (running for 00:09:25.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     97 |          552.421 | 388000 |          -336.189 |            -15.5295 |            -69.7583 |         -195.37 |        -55.5313 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000096)


[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12170x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000096)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:30:50 (running for 00:09:30.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     97 |          552.421 | 388000 |          -336.189 |            -15.5295 |            -69.7583 |         -195.37 |        -55.5313 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-337.5983038985546,num_env_steps_sampled_lifetime=392000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000097)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11928x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000097)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:30:55 (running for 00:09:35.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     98 |          557.956 | 392000 |          -337.598 |            -16.2333 |            -69.2085 |        -196.587 |        -55.5698 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-335.4609542563901,num_env_steps_sampled_lifetime=396000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000098)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12057x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000098)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:31:00 (running for 00:09:40.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |     99 |          563.737 | 396000 |          -335.461 |            -16.4773 |            -69.0757 |        -194.994 |        -54.9142 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-331.41394361308494,num_env_steps_sampled_lifetime=400000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000099)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12015x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000099)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:31:05 (running for 00:09:45.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    100 |          569.519 | 400000 |          -331.414 |            -15.4296 |            -69.5681 |        -191.819 |        -54.5975 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-330.9060114498474,num_env_steps_sampled_lifetime=404000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000100)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11892x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000100)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:31:10 (running for 00:09:50.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    101 |          575.791 | 404000 |          -330.906 |            -16.7119 |            -67.8529 |        -193.007 |        -53.3338 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-333.79562637706545,num_env_steps_sampled_lifetime=408000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000101)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12036x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000101)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:31:15 (running for 00:09:55.67)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    102 |          582.086 | 408000 |          -333.796 |            -16.4422 |            -68.7857 |        -194.909 |        -53.6584 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:31:20 (running for 00:10:00.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    102 |          582.086 | 408000 |          -333.796 |            -16.4422 |            -68.7857 |        -194.909 |        -53.6584 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-329.89592938482826,num_env_steps_sampled_lifetime=412000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000102)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12012x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000102)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:31:25 (running for 00:10:05.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    103 |          588.115 | 412000 |          -329.896 |             -15.431 |            -67.2624 |        -193.435 |        -53.7675 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-331.5039035843715,num_env_steps_sampled_lifetime=416000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000103)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12180x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000103)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:31:30 (running for 00:10:10.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    104 |          594.245 | 416000 |          -331.504 |            -14.8577 |             -66.636 |         -195.58 |        -54.4306 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-327.95741781856697,num_env_steps_sampled_lifetime=420000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000104)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11928x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000104)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:31:36 (running for 00:10:15.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    105 |          600.928 | 420000 |          -327.957 |            -14.3899 |            -65.5187 |        -193.719 |        -54.3299 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-328.37423052056727,num_env_steps_sampled_lifetime=424000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000105)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12086x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000105)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:31:41 (running for 00:10:20.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    106 |          606.607 | 424000 |          -328.374 |            -15.7648 |            -65.1579 |        -192.861 |        -54.5909 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-324.7900737981365,num_env_steps_sampled_lifetime=428000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000106)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12088x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000106)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:31:46 (running for 00:10:25.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    107 |          612.049 | 428000 |           -324.79 |            -15.0239 |            -63.4296 |        -190.922 |        -55.4143 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:31:51 (running for 00:10:30.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    107 |          612.049 | 428000 |           -324.79 |            -15.0239 |            -63.4296 |        -190.922 |        -55.4143 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-324.53416783524534,num_env_steps_sampled_lifetime=432000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000107)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11994x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000107)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:31:56 (running for 00:10:36.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    108 |          617.635 | 432000 |          -324.534 |            -15.1619 |            -62.4788 |        -190.269 |        -56.6244 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-322.7602912839853,num_env_steps_sampled_lifetime=436000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000108)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12028x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000108)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:01 (running for 00:10:41.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    109 |          623.415 | 436000 |           -322.76 |            -15.8939 |            -62.2867 |        -188.624 |        -55.9561 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-318.53981900250596,num_env_steps_sampled_lifetime=440000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000109)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12034x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000109)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:06 (running for 00:10:46.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    110 |          628.819 | 440000 |           -318.54 |            -13.5078 |            -62.7647 |         -187.52 |        -54.7473 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-317.2646024137673,num_env_steps_sampled_lifetime=444000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000110)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11962x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000110)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:32:11 (running for 00:10:51.13)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    111 |          634.743 | 444000 |          -317.265 |            -12.3596 |            -63.9845 |        -188.585 |        -52.3357 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.102749139747,num_env_steps_sampled_lifetime=448000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000111)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11938x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000111)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:16 (running for 00:10:56.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    112 |          640.439 | 448000 |          -316.103 |            -12.3775 |            -64.7688 |        -188.334 |        -50.6227 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.84786333794915,num_env_steps_sampled_lifetime=452000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000112)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12081x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000112)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:21 (running for 00:11:01.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    113 |          645.896 | 452000 |          -316.848 |            -13.1925 |            -63.5433 |        -190.029 |        -50.0829 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.58746333725253,num_env_steps_sampled_lifetime=456000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000113)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12113x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000113)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:26 (running for 00:11:06.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    114 |           651.56 | 456000 |          -316.587 |            -12.3433 |            -64.9882 |        -189.469 |        -49.7868 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-317.7071750913982,num_env_steps_sampled_lifetime=460000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000114)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11892x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000114)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:31 (running for 00:11:11.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    115 |          656.898 | 460000 |          -317.707 |            -12.1943 |            -64.4719 |        -190.787 |        -50.2539 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:32:36 (running for 00:11:16.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    115 |          656.898 | 460000 |          -317.707 |            -12.1943 |            -64.4719 |        -190.787 |        -50.2539 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.2448527140466,num_env_steps_sampled_lifetime=464000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000115)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12154x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000115)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:41 (running for 00:11:21.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    116 |          662.551 | 464000 |          -316.245 |            -11.0466 |            -63.0252 |        -191.374 |        -50.7991 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-317.05580423405104,num_env_steps_sampled_lifetime=468000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000116)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12038x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000116)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:46 (running for 00:11:26.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    117 |           667.93 | 468000 |          -317.056 |            -10.1573 |            -63.7086 |        -192.841 |        -50.3487 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-313.9320906086299,num_env_steps_sampled_lifetime=472000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000117)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11894x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000117)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:32:51 (running for 00:11:31.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    118 |          673.465 | 472000 |          -313.932 |            -9.07631 |            -64.3264 |        -190.612 |        -49.9172 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.67526317361035,num_env_steps_sampled_lifetime=476000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000118)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12106x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000118)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:32:56 (running for 00:11:36.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    119 |          679.233 | 476000 |          -316.675 |            -9.15235 |            -63.9232 |        -193.303 |         -50.297 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.1445625607689,num_env_steps_sampled_lifetime=480000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000119)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12048x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000119)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:33:01 (running for 00:11:41.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    120 |          684.805 | 480000 |          -316.145 |            -8.41507 |            -62.5257 |        -193.903 |        -51.3006 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-315.161002243677,num_env_steps_sampled_lifetime=484000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000120)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12036x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000120)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:33:06 (running for 00:11:46.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    121 |          690.427 | 484000 |          -315.161 |             -9.3041 |             -62.482 |        -192.943 |        -50.4316 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-311.61633046711705,num_env_steps_sampled_lifetime=488000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000121)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11964x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000121)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:33:11 (running for 00:11:51.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    122 |          695.861 | 488000 |          -311.616 |            -7.98848 |            -62.0397 |        -193.318 |        -48.2702 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865654)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-311.9897125561049,num_env_steps_sampled_lifetime=492000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000122)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11988x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000122)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:33:16 (running for 00:11:56.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    123 |          701.558 | 492000 |           -311.99 |            -7.57054 |            -62.6247 |        -191.773 |        -50.0213 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865654)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-311.1204438127589,num_env_steps_sampled_lifetime=496000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000123)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000123)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:33:22 (running for 00:12:01.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    124 |          707.086 | 496000 |           -311.12 |            -7.10941 |            -60.9176 |        -191.666 |        -51.4276 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:33:27 (running for 00:12:06.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    124 |          707.086 | 496000 |           -311.12 |            -7.10941 |            -60.9176 |        -191.666 |        -51.4276 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-315.23678549516023,num_env_steps_sampled_lifetime=500000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000124)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000124)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:33:32 (running for 00:12:11.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    125 |          712.621 | 500000 |          -315.237 |             -7.1854 |            -60.2693 |        -195.483 |        -52.2994 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.2139140939079,num_env_steps_sampled_lifetime=504000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000125)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12042x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000125)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:33:37 (running for 00:12:16.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    126 |          718.301 | 504000 |          -316.214 |             -6.7421 |            -59.8673 |        -195.026 |        -54.5783 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-315.9674000743808,num_env_steps_sampled_lifetime=508000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000126)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12054x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000126)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:33:42 (running for 00:12:21.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    127 |          723.879 | 508000 |          -315.967 |            -6.96302 |            -58.9851 |        -195.692 |        -54.3278 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.40808523063845,num_env_steps_sampled_lifetime=512000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000127)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11892x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000127)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:33:47 (running for 00:12:26.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    128 |          729.318 | 512000 |          -316.408 |            -6.55929 |            -59.0315 |        -196.463 |        -54.3543 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-313.2928262977017,num_env_steps_sampled_lifetime=516000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000128)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12128x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000128)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:33:52 (running for 00:12:32.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    129 |          734.843 | 516000 |          -313.293 |            -6.07847 |            -59.6244 |        -195.222 |        -52.3684 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-314.91873760595155,num_env_steps_sampled_lifetime=520000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000129)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11924x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000129)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:33:57 (running for 00:12:37.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    130 |          740.576 | 520000 |          -314.919 |            -6.29662 |            -58.7488 |        -197.703 |        -52.1706 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-314.23783135588775,num_env_steps_sampled_lifetime=524000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000130)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12176x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000130)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:02 (running for 00:12:42.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    131 |          746.216 | 524000 |          -314.238 |            -5.92855 |              -58.16 |         -197.73 |        -52.4197 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-314.8623147861683,num_env_steps_sampled_lifetime=528000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000131)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11904x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000131)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:07 (running for 00:12:47.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    132 |          751.973 | 528000 |          -314.862 |            -6.29222 |            -58.8314 |        -197.446 |         -52.293 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:34:12 (running for 00:12:52.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    132 |          751.973 | 528000 |          -314.862 |            -6.29222 |            -58.8314 |        -197.446 |         -52.293 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-313.2030082669647,num_env_steps_sampled_lifetime=532000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000132)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000132)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:34:17 (running for 00:12:57.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    133 |          757.851 | 532000 |          -313.203 |            -5.61255 |            -59.4761 |        -195.373 |         -52.741 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-313.6670175411608,num_env_steps_sampled_lifetime=536000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000133)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000133)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:22 (running for 00:13:02.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    134 |          763.922 | 536000 |          -313.667 |            -4.74439 |            -59.3094 |        -196.995 |         -52.618 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-314.221953314631,num_env_steps_sampled_lifetime=540000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000134)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12033x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000134)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:27 (running for 00:13:07.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    135 |          769.507 | 540000 |          -314.222 |            -5.96637 |            -57.8239 |        -197.646 |        -52.7857 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-313.78581188102834,num_env_steps_sampled_lifetime=544000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000135)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11859x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000135)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:32 (running for 00:13:12.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    136 |          774.948 | 544000 |          -313.786 |            -6.56406 |            -55.9514 |        -198.142 |        -53.1285 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-311.1915369676444,num_env_steps_sampled_lifetime=548000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000136)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000136)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:37 (running for 00:13:17.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    137 |          780.386 | 548000 |          -311.192 |            -6.30551 |            -55.1598 |        -197.234 |         -52.492 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-309.4077511643917,num_env_steps_sampled_lifetime=552000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000137)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000137)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:42 (running for 00:13:22.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    138 |          785.824 | 552000 |          -309.408 |            -6.38613 |            -54.1704 |        -197.045 |         -51.806 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-306.9468149091441,num_env_steps_sampled_lifetime=556000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000138)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11850x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000138)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:34:47 (running for 00:13:27.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    139 |          791.265 | 556000 |          -306.947 |            -5.70756 |            -52.4136 |        -196.736 |        -52.0897 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-305.0296365905141,num_env_steps_sampled_lifetime=560000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000139)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12174x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000139)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:52 (running for 00:13:32.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    140 |          796.686 | 560000 |           -305.03 |            -5.81591 |            -51.5123 |        -195.555 |        -52.1462 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-304.8863887707884,num_env_steps_sampled_lifetime=564000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000140)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000140)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:34:57 (running for 00:13:37.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    141 |          802.062 | 564000 |          -304.886 |            -6.97685 |            -51.1578 |        -195.469 |        -51.2827 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:35:02 (running for 00:13:42.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    141 |          802.062 | 564000 |          -304.886 |            -6.97685 |            -51.1578 |        -195.469 |        -51.2827 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-302.46302470118195,num_env_steps_sampled_lifetime=568000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000141)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000141)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:35:03,242 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.8046 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:35:08 (running for 00:13:47.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    142 |           807.54 | 568000 |          -302.463 |            -6.91034 |             -50.036 |        -194.079 |        -51.4376 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-302.9412615326801,num_env_steps_sampled_lifetime=572000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000142)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000142)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:35:13 (running for 00:13:52.79)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    143 |          812.865 | 572000 |          -302.941 |            -6.79832 |             -48.241 |        -196.063 |        -51.8385 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:35:13,248 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.7879 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-300.65890794906954,num_env_steps_sampled_lifetime=576000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000143)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000143)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:35:18 (running for 00:13:57.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    144 |          818.528 | 576000 |          -300.659 |            -5.98948 |            -47.5447 |        -196.448 |        -50.6763 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-299.83491537769254,num_env_steps_sampled_lifetime=580000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000144)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11953x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000144)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:35:23 (running for 00:14:02.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    145 |          824.048 | 580000 |          -299.835 |            -6.35877 |            -48.1897 |        -196.518 |        -48.7681 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:35:23,253 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.7529 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-299.15588751680656,num_env_steps_sampled_lifetime=584000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000145)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11999x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000145)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:35:28 (running for 00:14:07.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    146 |          829.334 | 584000 |          -299.156 |             -6.6926 |            -47.3829 |        -195.903 |        -49.1778 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-296.72208724424576,num_env_steps_sampled_lifetime=588000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000146)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12096x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000146)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:35:33 (running for 00:14:13.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    147 |          834.986 | 588000 |          -296.722 |            -6.59956 |            -46.4125 |        -194.706 |        -49.0043 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:35:33,258 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.7246 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-297.91849767216286,num_env_steps_sampled_lifetime=592000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000147)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000147)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:35:38 (running for 00:14:18.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    148 |          840.598 | 592000 |          -297.918 |            -6.74241 |            -45.7941 |        -196.377 |        -49.0045 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-299.9775034282149,num_env_steps_sampled_lifetime=596000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000148)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000148)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:35:43,264 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.7024 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:35:43 (running for 00:14:23.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    149 |          846.088 | 596000 |          -299.978 |            -8.07395 |            -46.4075 |        -197.234 |        -48.2624 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-296.60158201331217,num_env_steps_sampled_lifetime=600000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000149)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000149)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:35:48 (running for 00:14:28.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    150 |          851.525 | 600000 |          -296.602 |             -8.0847 |             -46.539 |        -194.875 |        -47.1029 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-290.88266721190587,num_env_steps_sampled_lifetime=604000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000150)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11916x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000150)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:35:53,269 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.6741 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:35:53 (running for 00:14:33.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    151 |          856.758 | 604000 |          -290.883 |            -7.78325 |            -46.8051 |         -190.53 |         -45.764 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-291.49714937550425,num_env_steps_sampled_lifetime=608000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000151)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11964x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000151)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:35:58 (running for 00:14:38.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    152 |          862.273 | 608000 |          -291.497 |            -7.79337 |            -46.7246 |        -189.626 |        -47.3532 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
[33m(raylet)[0m [2025-07-01 18:36:03,275 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.6581 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:36:03 (running for 00:14:43.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    152 |          862.273 | 608000 |          -291.497 |            -7.79337 |            -46.7246 |        -189.626 |        -47.3532 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-293.03639003533294,num_env_steps_sampled_lifetime=612000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000152)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12049x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000152)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:36:08 (running for 00:14:48.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    153 |           867.75 | 612000 |          -293.036 |            -9.01769 |            -45.6803 |         -191.46 |        -46.8787 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-294.3480146451637,num_env_steps_sampled_lifetime=616000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000153)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12167x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000153)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: veloc
[36m(MultiAgentEnvRunner pid=2865655)[0m ites provided but types or ids not provided, returning only distance and velocity values
[33m(raylet)[0m [2025-07-01 18:36:13,282 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.6196 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:36:13 (running for 00:14:53.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    154 |          873.288 | 616000 |          -294.348 |            -8.33833 |            -44.9965 |        -192.889 |        -48.1247 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-294.80217939943054,num_env_steps_sampled_lifetime=620000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000154)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11915x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000154)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:36:18 (running for 00:14:58.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    155 |          878.732 | 620000 |          -294.802 |            -8.19767 |            -45.9443 |        -191.571 |        -49.0894 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-293.35235343468884,num_env_steps_sampled_lifetime=624000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000155)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000155)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:36:23,288 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.5967 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:36:23 (running for 00:15:03.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    156 |          884.258 | 624000 |          -293.352 |            -6.25142 |            -45.8193 |        -191.016 |        -50.2651 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-292.08865851767683,num_env_steps_sampled_lifetime=628000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000156)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000156)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:36:28 (running for 00:15:08.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    157 |           889.81 | 628000 |          -292.089 |            -5.66344 |            -45.4394 |        -191.601 |        -49.3845 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-294.65512958606575,num_env_steps_sampled_lifetime=632000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000157)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11961x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000157)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:36:33,293 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.5627 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:36:34 (running for 00:15:13.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    158 |           895.21 | 632000 |          -294.655 |            -5.69802 |            -43.4597 |        -194.824 |        -50.6735 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-294.5945090307271,num_env_steps_sampled_lifetime=636000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000158)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12167x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000158)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:36:39 (running for 00:15:18.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    159 |          900.932 | 636000 |          -294.595 |            -6.09843 |            -42.5612 |        -195.826 |        -50.1093 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-294.0909924372432,num_env_steps_sampled_lifetime=640000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000159)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11860x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000159)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:36:43,299 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.5404 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:36:44 (running for 00:15:23.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    160 |           906.27 | 640000 |          -294.091 |            -6.38348 |            -41.1411 |        -196.342 |        -50.2242 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865654)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-296.54696828840474,num_env_steps_sampled_lifetime=644000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000160)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000160)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:36:49 (running for 00:15:28.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    161 |          911.739 | 644000 |          -296.547 |            -7.19279 |             -41.719 |        -197.208 |        -50.4271 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:36:53,305 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.5247 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-300.84340136856787,num_env_steps_sampled_lifetime=648000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000161)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000161)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:36:54 (running for 00:15:34.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    162 |          917.341 | 648000 |          -300.843 |            -7.03602 |            -41.1521 |        -199.656 |        -52.9997 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:36:59 (running for 00:15:39.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    162 |          917.341 | 648000 |          -300.843 |            -7.03602 |            -41.1521 |        -199.656 |        -52.9997 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-300.60870291809636,num_env_steps_sampled_lifetime=652000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000162)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12228x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000162)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:37:03,310 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.4901 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:37:04 (running for 00:15:44.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    163 |          922.714 | 652000 |          -300.609 |            -6.82563 |             -41.086 |        -200.021 |        -52.6759 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-301.03704429457457,num_env_steps_sampled_lifetime=656000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000163)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11976x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000163)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:37:09 (running for 00:15:49.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    164 |          928.327 | 656000 |          -301.037 |            -6.62601 |            -40.3831 |         -200.97 |        -53.0575 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-302.922983836719,num_env_steps_sampled_lifetime=660000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000164)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11904x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000164)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:37:13,315 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.461 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:37:14 (running for 00:15:54.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    165 |          933.461 | 660000 |          -302.923 |            -5.90631 |            -40.3044 |        -203.204 |        -53.5086 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-304.2094418741241,num_env_steps_sampled_lifetime=664000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000165)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12156x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000165)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:37:19 (running for 00:15:59.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    166 |          939.095 | 664000 |          -304.209 |            -6.02822 |            -39.8658 |        -205.353 |        -52.9623 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-305.6960907312138,num_env_steps_sampled_lifetime=668000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000166)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000166)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:37:23,321 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.4291 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:37:24 (running for 00:16:04.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    167 |          944.672 | 668000 |          -305.696 |            -5.96805 |            -39.0067 |        -207.848 |        -52.8737 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-303.28645446253046,num_env_steps_sampled_lifetime=672000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000167)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11868x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000167)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:37:29 (running for 00:16:09.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    168 |          950.294 | 672000 |          -303.286 |            -5.56844 |            -38.6277 |        -207.826 |        -51.2641 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-301.95337756414665,num_env_steps_sampled_lifetime=676000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000168)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12096x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000168)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:37:33,326 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.4072 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:37:34 (running for 00:16:14.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    169 |          955.846 | 676000 |          -301.953 |            -6.82427 |            -38.7125 |          -205.7 |        -50.7167 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-298.81118026202455,num_env_steps_sampled_lifetime=680000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000169)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12036x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000169)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity va
[36m(MultiAgentEnvRunner pid=2865654)[0m lues
== Status ==
Current time: 2025-07-01 18:37:39 (running for 00:16:19.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    170 |          961.231 | 680000 |          -298.811 |            -5.23902 |            -37.0213 |        -206.023 |        -50.5279 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:37:43,332 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.3915 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-298.79691533202663,num_env_steps_sampled_lifetime=684000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000170)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12035x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000170)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:37:44 (running for 00:16:24.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    171 |          966.818 | 684000 |          -298.797 |            -3.21231 |             -35.475 |        -207.873 |        -52.2361 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-301.95272861183963,num_env_steps_sampled_lifetime=688000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000171)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12024x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000171)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:37:50 (running for 00:16:29.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    172 |          972.292 | 688000 |          -301.953 |            -3.45347 |            -35.2967 |        -210.554 |        -52.6481 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865654)[0m
[33m(raylet)[0m [2025-07-01 18:37:53,337 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.3626 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:37:55 (running for 00:16:34.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    172 |          972.292 | 688000 |          -301.953 |            -3.45347 |            -35.2967 |        -210.554 |        -52.6481 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-297.4581929632618,num_env_steps_sampled_lifetime=692000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000172)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12076x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000172)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m warning: velocites pr
[36m(MultiAgentEnvRunner pid=2865654)[0m ovided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:38:00 (running for 00:16:39.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    173 |          978.053 | 692000 |          -297.458 |             -2.8624 |            -33.7496 |        -209.619 |        -51.2269 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-297.6172390686612,num_env_steps_sampled_lifetime=696000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000173)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11947x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000173)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:38:03,342 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.3281 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:38:05 (running for 00:16:45.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    174 |          983.559 | 696000 |          -297.617 |            -2.34585 |            -32.9016 |         -211.74 |        -50.6296 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-302.0700957155102,num_env_steps_sampled_lifetime=700000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000174)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12084x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000174)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
[36m(MultiAgentEnvRunner pid=2865654)[0m
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:38:10 (running for 00:16:50.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    175 |           989.13 | 700000 |           -302.07 |             -3.1813 |            -32.3107 |        -213.833 |        -52.7448 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-306.28084309578867,num_env_steps_sampled_lifetime=704000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000175)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11880x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000175)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:38:13,348 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.3054 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:38:15 (running for 00:16:55.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    176 |          994.696 | 704000 |          -306.281 |             -4.0992 |             -31.844 |         -217.54 |        -52.7981 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-303.91421817188524,num_env_steps_sampled_lifetime=708000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000176)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12120x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000176)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:38:20 (running for 00:17:00.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    177 |          1000.15 | 708000 |          -303.914 |            -3.59264 |            -31.3898 |        -218.045 |        -50.8872 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-305.9035522265878,num_env_steps_sampled_lifetime=712000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000177)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12048x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000177)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:38:23,354 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.2772 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:38:25 (running for 00:17:05.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    178 |          1005.71 | 712000 |          -305.904 |            -3.92106 |            -32.2642 |        -218.546 |         -51.172 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-307.97545444681435,num_env_steps_sampled_lifetime=716000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000178)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11892x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000178)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:38:30 (running for 00:17:10.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    179 |          1011.24 | 716000 |          -307.975 |            -5.43546 |            -32.1333 |        -219.526 |        -50.8802 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865654)[0m
[33m(raylet)[0m [2025-07-01 18:38:33,359 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.258 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-308.0757128326038,num_env_steps_sampled_lifetime=720000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000179)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000179)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:38:35 (running for 00:17:15.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    180 |          1016.91 | 720000 |          -308.076 |            -4.21193 |            -31.7128 |         -221.51 |        -50.6408 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-310.17172190395905,num_env_steps_sampled_lifetime=724000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000180)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12144x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000180)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:38:40 (running for 00:17:20.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    181 |          1022.44 | 724000 |          -310.172 |            -5.27643 |            -31.9882 |        -223.925 |        -48.9823 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:38:43,364 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.2233 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-310.8048875512014,num_env_steps_sampled_lifetime=728000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000181)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12000x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000181)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
== Status ==
Current time: 2025-07-01 18:38:45 (running for 00:17:25.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    182 |          1027.85 | 728000 |          -310.805 |            -5.63032 |             -32.507 |        -223.781 |        -48.8866 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


== Status ==
Current time: 2025-07-01 18:38:50 (running for 00:17:30.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    182 |          1027.85 | 728000 |          -310.805 |            -5.63032 |             -32.507 |        -223.781 |        -48.8866 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-310.8387522857045,num_env_steps_sampled_lifetime=732000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000182)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12010x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000182)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m
[36m(MultiAgentEnvRunner pid=2865654)[0m
[33m(raylet)[0m [2025-07-01 18:38:53,370 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.1947 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:38:55 (running for 00:17:35.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    183 |          1033.35 | 732000 |          -310.839 |            -5.95268 |            -33.7237 |         -224.39 |        -46.7722 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-309.9705015830532,num_env_steps_sampled_lifetime=736000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000183)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11954x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000183)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:39:00 (running for 00:17:40.69)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    184 |          1038.86 | 736000 |          -309.971 |            -5.52016 |            -33.4445 |          -225.1 |        -45.9063 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-310.6627793365502,num_env_steps_sampled_lifetime=740000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000184)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12033x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000184)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:39:03,375 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.1727 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:39:05 (running for 00:17:45.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    185 |          1044.43 | 740000 |          -310.663 |            -5.42413 |             -35.114 |        -224.719 |        -45.4054 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-309.4150065449365,num_env_steps_sampled_lifetime=744000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000185)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11955x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000185)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:39:11 (running for 00:17:50.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    186 |          1049.98 | 744000 |          -309.415 |            -4.48852 |            -35.8181 |        -223.076 |        -46.0326 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:39:13,381 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.1566 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-310.50298241438657,num_env_steps_sampled_lifetime=748000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000186)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12144x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000186)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only dist
[36m(MultiAgentEnvRunner pid=2865655)[0m ance and velocity values
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:39:16 (running for 00:17:55.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    187 |          1055.61 | 748000 |          -310.503 |             -5.5579 |            -35.9796 |        -222.999 |        -45.9668 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-311.0558318083215,num_env_steps_sampled_lifetime=752000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000187)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11939x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000187)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:39:21 (running for 00:18:00.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    188 |          1061.21 | 752000 |          -311.056 |            -4.98332 |             -36.054 |         -223.18 |        -46.8389 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:39:23,386 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.1275 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-312.3234161495052,num_env_steps_sampled_lifetime=756000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000188)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12060x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000188)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:39:26 (running for 00:18:06.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    189 |          1066.88 | 756000 |          -312.323 |            -6.21646 |            -36.3825 |         -224.02 |        -45.7049 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-313.04633259604134,num_env_steps_sampled_lifetime=760000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000189)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12003x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000189)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:39:31 (running for 00:18:11.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    190 |          1072.39 | 760000 |          -313.046 |            -6.58646 |             -36.147 |         -223.98 |        -46.3331 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:39:33,392 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.0928 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-311.5495222314234,num_env_steps_sampled_lifetime=764000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000190)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11973x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000190)...
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
== Status ==
Current time: 2025-07-01 18:39:36 (running for 00:18:16.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    191 |          1077.97 | 764000 |           -311.55 |            -5.60439 |            -36.5151 |        -223.217 |        -46.2132 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:39:41 (running for 00:18:21.33)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    191 |          1077.97 | 764000 |           -311.55 |            -5.60439 |            -36.5151 |        -223.217 |        -46.2132 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-309.4654460793929,num_env_steps_sampled_lifetime=768000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000191)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12216x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000191)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:39:43,398 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.0615 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:39:46 (running for 00:18:26.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    192 |          1083.47 | 768000 |          -309.465 |            -4.81623 |            -37.2048 |        -222.504 |        -44.9409 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-311.1728484587459,num_env_steps_sampled_lifetime=772000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000192)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11856x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000192)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:39:51 (running for 00:18:31.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    193 |          1089.03 | 772000 |          -311.173 |            -6.29015 |            -37.4066 |        -222.885 |        -44.5911 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-313.76113295448187,num_env_steps_sampled_lifetime=776000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000193)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12132x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000193)... Done. 0.0s
[33m(raylet)[0m [2025-07-01 18:39:53,404 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.0393 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-01 18:39:56 (running for 00:18:36.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    194 |           1094.7 | 776000 |          -313.761 |            -6.25211 |            -37.1373 |        -223.928 |        -46.4434 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.8379140268025,num_env_steps_sampled_lifetime=780000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000194)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11940x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000194)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:40:01 (running for 00:18:41.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    195 |          1100.22 | 780000 |          -316.838 |            -7.33475 |            -38.1795 |        -224.453 |        -46.8711 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:40:03,409 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 22.0234 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.22677390634254,num_env_steps_sampled_lifetime=784000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000195)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12168x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000195)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:40:06 (running for 00:18:46.61)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    196 |          1105.88 | 784000 |          -316.227 |            -9.32232 |             -38.314 |        -223.138 |        -45.4528 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-317.61396834395333,num_env_steps_sampled_lifetime=788000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000196)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11843x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000196)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:40:11 (running for 00:18:51.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    197 |          1111.55 | 788000 |          -317.614 |            -10.2378 |             -37.674 |         -223.28 |        -46.4217 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
[33m(raylet)[0m [2025-07-01 18:40:13,415 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 21.9883 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-318.2009420694428,num_env_steps_sampled_lifetime=792000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000197)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 12085x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000197)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2865654)[0m
== Status ==
Current time: 2025-07-01 18:40:16 (running for 00:18:56.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    198 |          1117.21 | 792000 |          -318.201 |            -10.2651 |            -38.6547 |        -223.375 |        -45.9064 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+


[36m(MultiAgentEnvRunner pid=2865655)[0m
Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-318.9237591038923,num_env_steps_sampled_lifetime=796000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000198)
[36m(MultiAgentEnvRunner pid=2865655)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 11964x across cluster][0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000198)... Done. 0.0s
== Status ==
Current time: 2025-07-01 18:40:22 (running for 00:19:01.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | RUNNING  | 192.168.0.25:2864454 |    199 |          1122.64 | 796000 |          -318.924 |            -10.6364 |            -38.1298 |        -222.642 |        -47.5153 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[33m(raylet)[0m [2025-07-01 18:40:23,421 E 2862794 2862823] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070 is over 95% full, available space: 21.9596 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_bfbc9_00000 reported env_runners/episode_return_mean=-316.7430684534366,num_env_steps_sampled_lifetime=800000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2864454)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000199)
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-01_18-21-20/PPO_env_bfbc9_00000_0_2025-07-01_18-21-20/checkpoint_000199)...
2025-07-01 18:40:27,010	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-07-01_18-21-20' in 0.0998s.
== Status ==
Current time: 2025-07-01 18:40:27 (running for 00:19:06.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-01_18-21-18_931530_2862070/artifacts/2025-07-01_18-21-20/PPO_2025-07-01_18-21-20/driver_artifacts
Number of trials: 1/1 (1 TERMINATED)
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
| Trial name          | status     | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_1 |   return prey_0 |
|---------------------+------------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|
| PPO_env_bfbc9_00000 | TERMINATED | 192.168.0.25:2864454 |    200 |          1128.15 | 800000 |          -316.743 |            -10.5093 |            -38.4148 |        -222.287 |        -45.5319 |
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+
[36m(_WandbLoggingActor pid=2866614)[0m Done. 0.0s
[36m(_WandbLoggingActor pid=2866614)[0m wandb: uploading artifact checkpoint_PPO_env_bfbc9_00000
[36m(_WandbLoggingActor pid=2866614)[0m wandb: uploading artifact checkpoint_PPO_env_bfbc9_00000; uploading history steps 196-199, summary, console lines 197-199
2025-07-01 18:40:31,134	INFO tune.py:1041 -- Total run time: 1150.91 seconds (1146.67 seconds for the tuning loop).
[36m(_WandbLoggingActor pid=2866614)[0m wandb:
[36m(_WandbLoggingActor pid=2866614)[0m wandb:
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Run history:
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    env_runners/agent_steps/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    env_runners/agent_steps/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/agent_steps/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/agent_steps/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  env_runners/connector_pipeline_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           env_runners/env_reset_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            env_runners/env_step_timer ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ


ËÆ≠ÁªÉÂÆåÊàê
[36m(_WandbLoggingActor pid=2866614)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 env_runners/episode_duration_sec_mean ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           env_runners/episode_len_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                          env_runners/episode_len_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           env_runners/episode_len_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/episode_return_max ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                       env_runners/episode_return_mean ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/episode_return_min ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñà‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ‚ñá‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñà‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ‚ñá‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     env_runners/num_env_steps_sampled ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput ‚ñá‚ñÜ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                              env_runners/num_episodes ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     env_runners/num_episodes_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[0m
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  env_runners/rlmodule_inference_timer ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                    env_runners/sample ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     env_runners/time_between_sampling ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            env_runners/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                   fault_tolerance/num_healthy_workers ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                              iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_0/entropy ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñà‚ñà‚ñÉ‚ñá‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÜ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/predator_0/mean_kl_loss ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                       learners/predator_0/policy_loss ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÇ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/predator_0/total_loss ‚ñÜ‚ñÜ‚ñÉ‚ñá‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñá‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  learners/predator_0/vf_explained_var ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñà‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_0/vf_loss ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ‚ñá‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/predator_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_1/entropy ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñà‚ñÉ‚ñÑ‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/predator_1/mean_kl_loss ‚ñÉ‚ñÉ‚ñá‚ñÇ‚ñÖ‚ñà‚ñÜ‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                       learners/predator_1/policy_loss ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/predator_1/total_loss ‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  learners/predator_1/vf_explained_var ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÜ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_1/vf_loss ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/predator_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñá‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_0/entropy ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÜ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                          learners/prey_0/mean_kl_loss ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñà‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/prey_0/policy_loss ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            learners/prey_0/total_loss ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/prey_0/vf_explained_var ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÖ‚ñà‚ñÉ‚ñá‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_0/vf_loss ‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/prey_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_1/entropy ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñà‚ñÉ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                          learners/prey_1/mean_kl_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/prey_1/policy_loss ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            learners/prey_1/total_loss ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/prey_1/vf_explained_var ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñà‚ñÉ‚ñà‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÜ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_1/vf_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñÅ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñá‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/prey_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 num_training_step_calls_per_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                 perf/cpu_util_percent ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                 perf/ram_util_percent ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                    time_since_restore ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                      time_this_iter_s ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                          time_total_s ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      timers/env_runner_sampling_timer ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           timers/learner_update_timer ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            timers/restore_env_runners ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           timers/synch_env_connectors ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                  timers/synch_weights ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                             timers/training_iteration ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                  timers/training_step ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                             timestamp ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                    training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2866614)[0m wandb:
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Run summary:
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 -10.50929
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 -38.41483
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 -45.53187
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 -222.28708
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    env_runners/agent_steps/predator_0 500
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    env_runners/agent_steps/predator_1 500
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/agent_steps/prey_0 500
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/agent_steps/prey_1 500
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.0004
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           env_runners/env_reset_timer 0.00332
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            env_runners/env_step_timer 0.00047
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00014
[36m(_WandbLoggingActor pid=2866614)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 2e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 3e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 1881.0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 1881.0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 env_runners/episode_duration_sec_mean 2.51358
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           env_runners/episode_len_max 2000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                          env_runners/episode_len_mean 2000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           env_runners/episode_len_min 2000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/episode_return_max -222.22375
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                       env_runners/episode_return_mean -316.74307
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        env_runners/episode_return_min -429.86467
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 -10.50929
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 -38.41483
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 -45.53187
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 -222.28708
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00027
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 0.00011
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 4e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 200000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 200400
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 200400
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 200400
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 800000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 994.96247
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                              env_runners/num_episodes 2
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     env_runners/num_episodes_lifetime 400
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 200000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 200400
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 200400
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 200400
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.00015
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                    env_runners/sample 2.55952
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     env_runners/time_between_sampling 3.35422
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 4e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 3e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 3e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 8e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            env_runners/weights_seq_no 199
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                              iterations_since_restore 200
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.08428
[36m(_WandbLoggingActor pid=2866614)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03612
[36m(_WandbLoggingActor pid=2866614)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 8e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.00257
[36m(_WandbLoggingActor pid=2866614)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 3e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.00203
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.02991
[36m(_WandbLoggingActor pid=2866614)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.01187
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.0014
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 940000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 188000000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 336765.08124
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 120320
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 24064000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 2049213.58284
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 2015060.77874
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 517140
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 0.92473
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_0/entropy -1.84644
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 10.26241
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.01333
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 10776.1439
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_0/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                       learners/predator_0/policy_loss -0.18002
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/predator_0/total_loss -0.15986
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  learners/predator_0/vf_explained_var 0.13805
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_0/vf_loss 1.56544
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 1.66998
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/predator_0/weights_seq_no 200
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 0.4871
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_1/entropy -0.68101
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 12.86021
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.0139
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 10776.26202
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/predator_1/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                       learners/predator_1/policy_loss 0.02836
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/predator_1/total_loss 0.05034
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                  learners/predator_1/vf_explained_var 0.34087
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/predator_1/vf_loss 3.04067
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 5.25266
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/predator_1/weights_seq_no 200
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 0.69354
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_0/entropy -0.99202
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 23.83545
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.0192
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 10776.28592
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_0/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/prey_0/policy_loss -0.03009
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            learners/prey_0/total_loss 0.01
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/prey_0/vf_explained_var 0.52242
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_0/vf_loss 5.35435
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 36.3091
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/prey_0/weights_seq_no 200
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 1.18632
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_1/entropy 3.62281
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 153.70728
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.01295
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 10776.37159
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                              learners/prey_1/num_trainable_parameters 129285
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           learners/prey_1/policy_loss 9e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            learners/prey_1/total_loss 0.06393
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      learners/prey_1/vf_explained_var -0.09631
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                               learners/prey_1/vf_loss 9.69614
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 1035.41272
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        learners/prey_1/weights_seq_no 200
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                        num_env_steps_sampled_lifetime 800000
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                 num_training_step_calls_per_iteration 1
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                 perf/cpu_util_percent 15.8875
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                 perf/ram_util_percent 67.2
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                    time_since_restore 1128.14555
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                      time_this_iter_s 5.51048
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                          time_total_s 1128.14555
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                      timers/env_runner_sampling_timer 2.59414
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           timers/learner_update_timer 3.0197
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                            timers/restore_env_runners 2e-05
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                           timers/synch_env_connectors 0.00161
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                  timers/synch_weights 0.00348
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                             timers/training_iteration 5.61816
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                  timers/training_step 5.61777
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                             timestamp 1751362826
[36m(_WandbLoggingActor pid=2866614)[0m wandb:                                                                                    training_iteration 200
[36m(_WandbLoggingActor pid=2866614)[0m wandb:
[36m(_WandbLoggingActor pid=2866614)[0m wandb: üöÄ View run PPO_env_bfbc9_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/bfbc9_00000
[36m(_WandbLoggingActor pid=2866614)[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 1427 artifact file(s) and 0 other file(s)
[36m(_WandbLoggingActor pid=2866614)[0m wandb: Find logs at: ./wandb/run-20250701_182128-bfbc9_00000/logs
