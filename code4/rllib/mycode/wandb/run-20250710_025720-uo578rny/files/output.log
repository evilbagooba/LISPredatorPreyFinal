['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-10 02:57:28,352	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-10 02:57:28,927	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-10 02:57:29 (running for 00:00:00.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_2dc34_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=1140425)[0m 2025-07-10 02:57:30,963	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(PPO pid=1140425)[0m 2025-07-10 02:57:33,240	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
[36m(PPO pid=1140425)[0m Install gputil for GPU system monitoring.
== Status ==
Current time: 2025-07-10 02:57:34 (running for 00:00:05.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+
| Trial name          | status   | loc                  |
|---------------------+----------+----------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |
+---------------------+----------+----------------------+
[36m(_WandbLoggingActor pid=1140689)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=1140689)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/wandb/run-20250710_025736-2dc34_00000
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Syncing run PPO_env_2dc34_00000
[36m(_WandbLoggingActor pid=1140689)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=1140689)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/2dc34_00000


== Status ==
Current time: 2025-07-10 02:57:40 (running for 00:00:11.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      1 |          4.90662 | 4000 |           -415.55 |        -187.818 |        -85.3356 |            -70.8227 |            -71.5744 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000000)
[36m(MultiAgentEnvRunner pid=1140515)[0m 2025-07-10 02:57:33,170	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 5x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 5x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 5x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000000)...
[36m(_WandbLoggingActor pid=1140689)[0m Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000001)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000001)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:57:45 (running for 00:00:16.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      2 |          9.47436 | 8000 |           -439.49 |        -190.522 |        -92.3473 |            -70.4893 |            -86.1317 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000002)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000002)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:57:50 (running for 00:00:21.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      3 |          14.1402 | 12000 |          -434.695 |        -195.041 |        -84.6587 |            -78.1977 |            -76.7975 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000003)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000003)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:57:55 (running for 00:00:26.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      4 |          18.8318 | 16000 |          -443.666 |        -197.773 |        -83.7901 |            -83.7289 |            -78.3732 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000004)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000004)...
[36m(_WandbLoggingActor pid=1140689)[0m Done. 0.0s
== Status ==
Current time: 2025-07-10 02:58:00 (running for 00:00:31.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      5 |          23.6097 | 20000 |          -444.472 |        -197.095 |        -84.0635 |            -87.2505 |            -76.0631 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000005)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000005)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:58:05 (running for 00:00:36.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      6 |          28.3595 | 24000 |          -435.947 |        -196.696 |         -85.145 |            -88.9507 |            -65.1548 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000006)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:58:10 (running for 00:00:41.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      7 |          33.0729 | 28000 |          -426.422 |        -196.428 |        -84.1339 |            -88.7034 |            -57.1573 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000007)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000007)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:58:15 (running for 00:00:46.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      8 |          37.7862 | 32000 |          -410.873 |        -191.155 |        -87.7011 |            -78.7392 |            -53.2773 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000008)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000008)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:58:20 (running for 00:00:51.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |      9 |          42.3111 | 36000 |          -387.783 |        -191.879 |        -90.8196 |            -50.2915 |            -54.7937 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000009)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000009)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:58:25 (running for 00:00:56.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     10 |          46.7711 | 40000 |          -361.028 |        -192.604 |        -91.1567 |             -23.139 |            -54.1284 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000010)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000010)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:58:30 (running for 00:01:01.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     11 |          51.3518 | 44000 |          -345.232 |         -192.71 |        -91.8619 |            -7.95638 |            -52.7037 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000011)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000011)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:58:35 (running for 00:01:06.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     12 |          55.9325 | 48000 |          -314.369 |        -189.864 |        -90.9371 |              21.821 |             -55.389 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000012)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000012)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:58:40 (running for 00:01:12.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     13 |          60.4794 | 52000 |          -244.259 |         -184.93 |        -86.9646 |             66.5626 |            -38.9271 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000013)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000013)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:58:45 (running for 00:01:17.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     15 |          69.8399 | 60000 |          -193.334 |        -187.238 |        -86.0378 |              101.23 |            -21.2884 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000014)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000014)...
[36m(_WandbLoggingActor pid=1140689)[0m Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000015)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000015)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:58:51 (running for 00:01:22.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     16 |          74.3292 | 64000 |          -135.497 |        -186.168 |        -86.5691 |             133.483 |             3.75688 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000016)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000016)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:58:56 (running for 00:01:27.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     17 |          78.8706 | 68000 |          -60.0621 |        -181.953 |        -82.6627 |             165.273 |             39.2805 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000017)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000017)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:59:01 (running for 00:01:32.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     18 |           83.544 | 72000 |           -16.764 |        -181.004 |        -82.3207 |             187.725 |             58.8363 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000018)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000018)... Done. 0.0s
== Status ==
Current time: 2025-07-10 02:59:06 (running for 00:01:37.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     19 |          88.0777 | 76000 |           14.6179 |        -180.519 |        -83.5783 |             202.524 |             76.1917 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000019)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000019)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:59:11 (running for 00:01:42.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     20 |          92.5365 | 80000 |           51.9336 |        -178.745 |        -81.3362 |             219.217 |             92.7978 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000020)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000020)...
[36m(_WandbLoggingActor pid=1140689)[0m Done. 0.0s
== Status ==
Current time: 2025-07-10 02:59:16 (running for 00:01:47.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     21 |          97.0892 | 84000 |           64.9075 |        -179.426 |        -81.0894 |             225.073 |             100.351 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000021)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000021)...
[36m(_WandbLoggingActor pid=1140689)[0m Done. 0.0s


== Status ==
Current time: 2025-07-10 02:59:21 (running for 00:01:52.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     22 |          101.577 | 88000 |           110.589 |        -177.058 |        -78.5606 |             241.468 |             124.739 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000022)


[36m(MultiAgentEnvRunner pid=1140514)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=1140514)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000022)...
[36m(_WandbLoggingActor pid=1140689)[0m Done. 0.0s
== Status ==
Current time: 2025-07-10 02:59:26 (running for 00:01:57.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     23 |          106.053 | 92000 |           170.765 |        -174.209 |        -75.8136 |             266.084 |             154.703 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000023)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000023)... Done. 0.0s


== Status ==
Current time: 2025-07-10 02:59:31 (running for 00:02:02.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | RUNNING  | 192.168.0.25:1140425 |     24 |          110.516 | 96000 |           194.562 |        -172.271 |        -74.1822 |             281.509 |             159.506 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
2025-07-10 02:59:31,625	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-07-10_02-57-28' in 0.0235s.


== Status ==
Current time: 2025-07-10 02:59:31 (running for 00:02:02.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_02-57-27_798246_1138519/artifacts/2025-07-10_02-57-28/PPO_2025-07-10_02-57-28/driver_artifacts
Number of trials: 1/1 (1 TERMINATED)
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status     | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return prey_0 |   return predator_1 |   return predator_0 |
|---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_2dc34_00000 | TERMINATED | 192.168.0.25:1140425 |     25 |          114.989 | 100000 |           213.108 |        -171.795 |         -73.831 |             288.738 |             169.997 |
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=1140425)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000024)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_02-57-28/PPO_env_2dc34_00000_0_2025-07-10_02-57-28/checkpoint_000024)... Done. 0.0s
[36m(_WandbLoggingActor pid=1140689)[0m wandb: uploading artifact checkpoint_PPO_env_2dc34_00000
2025-07-10 02:59:35,537	INFO tune.py:1041 -- Total run time: 126.72 seconds (122.68 seconds for the tuning loop).
[36m(_WandbLoggingActor pid=1140689)[0m wandb:
[36m(_WandbLoggingActor pid=1140689)[0m wandb:


ËÆ≠ÁªÉÂÆåÊàê
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Run history:
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    env_runners/agent_steps/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    env_runners/agent_steps/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/agent_steps/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/agent_steps/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  env_runners/connector_pipeline_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           env_runners/env_reset_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            env_runners/env_step_timer ‚ñá‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñà‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñà‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñà‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÉ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÜ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 env_runners/episode_duration_sec_mean ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           env_runners/episode_len_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                          env_runners/episode_len_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           env_runners/episode_len_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/episode_return_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                       env_runners/episode_return_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/episode_return_min ‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñà‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñà‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÇ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñà‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     env_runners/num_env_steps_sampled ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput ‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                              env_runners/num_episodes ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     env_runners/num_episodes_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  env_runners/rlmodule_inference_timer ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                    env_runners/sample ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     env_runners/time_between_sampling ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            env_runners/weights_seq_no ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                   fault_tolerance/num_healthy_workers ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                              iterations_since_restore ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=1140689)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_0/entropy ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/predator_0/mean_kl_loss ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                       learners/predator_0/policy_loss ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/predator_0/total_loss ‚ñÉ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  learners/predator_0/vf_explained_var ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_0/vf_loss ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÅ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/predator_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_1/entropy ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/predator_1/mean_kl_loss ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                       learners/predator_1/policy_loss ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/predator_1/total_loss ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  learners/predator_1/vf_explained_var ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñá
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_1/vf_loss ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/predator_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_0/entropy ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                          learners/prey_0/mean_kl_loss ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñá‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/prey_0/policy_loss ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            learners/prey_0/total_loss ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/prey_0/vf_explained_var ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñà‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_0/vf_loss ‚ñá‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÅ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/prey_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_1/entropy ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                          learners/prey_1/mean_kl_loss ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/prey_1/policy_loss ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            learners/prey_1/total_loss ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/prey_1/vf_explained_var ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÖ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_1/vf_loss ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñà‚ñá‚ñÑ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñá‚ñá‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/prey_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 num_training_step_calls_per_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                 perf/cpu_util_percent ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                 perf/ram_util_percent ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                    time_since_restore ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                      time_this_iter_s ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                          time_total_s ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      timers/env_runner_sampling_timer ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           timers/learner_update_timer ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            timers/restore_env_runners ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           timers/synch_env_connectors ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                  timers/synch_weights ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                             timers/training_iteration ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                  timers/training_step ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                             timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                    training_iteration ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=1140689)[0m wandb:
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Run summary:
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 169.99707
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 288.73751
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 -73.83099
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 -171.79533
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    env_runners/agent_steps/predator_0 500
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    env_runners/agent_steps/predator_1 500
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/agent_steps/prey_0 500
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/agent_steps/prey_1 500
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.00035
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           env_runners/env_reset_timer 0.00268
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            env_runners/env_step_timer 0.00043
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00012
[36m(_WandbLoggingActor pid=1140689)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 2e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 1881.0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 1881.0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 env_runners/episode_duration_sec_mean 2.08644
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           env_runners/episode_len_max 2000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                          env_runners/episode_len_mean 2000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           env_runners/episode_len_min 2000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/episode_return_max 1605.36399
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                       env_runners/episode_return_mean 213.10826
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        env_runners/episode_return_min -509.56865
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 169.99707
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 288.73751
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 -73.83099
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 -171.79533
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00023
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 8e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 3e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 25000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 25050
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 25050
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 25050
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 100000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 1189.29994
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                              env_runners/num_episodes 2
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     env_runners/num_episodes_lifetime 50
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 25000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 25050
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 25050
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 25050
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.0001
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                    env_runners/sample 2.12245
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     env_runners/time_between_sampling 3.97858
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 3e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 3e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 7e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            env_runners/weights_seq_no 24
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                              iterations_since_restore 25
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.1086
[36m(_WandbLoggingActor pid=1140689)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03418
[36m(_WandbLoggingActor pid=1140689)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 7e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.00306
[36m(_WandbLoggingActor pid=1140689)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 3e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.00189
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.02336
[36m(_WandbLoggingActor pid=1140689)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.04422
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.00147
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 940000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 23500000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 396805.54877
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 120320
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 3008000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 2171784.56404
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 2143319.94186
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 578580
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 1.51875
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_0/entropy 1.33153
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 3.07784
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.01258
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 752000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 12697.71409
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                       learners/predator_0/policy_loss -0.12035
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/predator_0/total_loss -0.05131
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  learners/predator_0/vf_explained_var 0.0141
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_0/vf_loss 9.98745
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 9815.06738
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/predator_0/weights_seq_no 25
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 1.13906
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_1/entropy 2.17816
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 2.83581
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.01214
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 752000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 12697.76785
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/predator_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                       learners/predator_1/policy_loss -0.15002
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/predator_1/total_loss -0.0862
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                  learners/predator_1/vf_explained_var 0.00862
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/predator_1/vf_loss 10
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 10543.76465
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/predator_1/weights_seq_no 25
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 0.8543
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_0/entropy 2.80863
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 2.43225
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.01381
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 752000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 12697.79222
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/prey_0/policy_loss -0.06777
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            learners/prey_0/total_loss -0.01615
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/prey_0/vf_explained_var 0.20258
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_0/vf_loss 7.96442
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 107.64236
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/prey_0/weights_seq_no 25
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 1.0125
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_1/entropy 2.22904
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 4.34818
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.01258
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 752000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 12697.71697
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                              learners/prey_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           learners/prey_1/policy_loss -0.13454
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            learners/prey_1/total_loss -0.08063
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      learners/prey_1/vf_explained_var -0.09888
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                               learners/prey_1/vf_loss 8.23615
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 568.50861
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        learners/prey_1/weights_seq_no 25
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                        num_env_steps_sampled_lifetime 100000
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                 num_training_step_calls_per_iteration 1
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                 perf/cpu_util_percent 9.0
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                 perf/ram_util_percent 20.7
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                    time_since_restore 114.98917
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                      time_this_iter_s 4.47277
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                          time_total_s 114.98917
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                      timers/env_runner_sampling_timer 2.14043
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           timers/learner_update_timer 2.68817
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                            timers/restore_env_runners 2e-05
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                           timers/synch_env_connectors 0.00141
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                  timers/synch_weights 0.00383
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                             timers/training_iteration 4.83307
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                  timers/training_step 4.83283
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                             timestamp 1752083971
[36m(_WandbLoggingActor pid=1140689)[0m wandb:                                                                                    training_iteration 25
[36m(_WandbLoggingActor pid=1140689)[0m wandb:
[36m(_WandbLoggingActor pid=1140689)[0m wandb: üöÄ View run PPO_env_2dc34_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/2dc34_00000
[36m(_WandbLoggingActor pid=1140689)[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 202 artifact file(s) and 0 other file(s)
[36m(_WandbLoggingActor pid=1140689)[0m wandb: Find logs at: ./wandb/run-20250710_025736-2dc34_00000/logs
ÂèÇÊï∞Ëß£ÊûêÂÆåÊàê: n_predators=2, n_preys=2, total_agents=4, algo=PPO
[34m[1mwandb[0m: [32m[41mERROR[0m The nbformat package was not found. It is required to save notebook history.
