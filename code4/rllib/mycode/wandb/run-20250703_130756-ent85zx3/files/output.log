['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-03 13:07:58,793	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-03 13:07:59,247	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-03 13:07:59 (running for 00:00:00.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_4e4c4_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=14979)[0m 2025-07-03 13:08:01,198	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(PPO pid=14979)[0m 2025-07-03 13:08:03,381	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
== Status ==
Current time: 2025-07-03 13:08:04 (running for 00:00:05.13)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+
| Trial name          | status   | loc                |
|---------------------+----------+--------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |
+---------------------+----------+--------------------+
[36m(PPO pid=14979)[0m Install gputil for GPU system monitoring.
[36m(_WandbLoggingActor pid=15344)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(_WandbLoggingActor pid=15344)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=15344)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=15344)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=15344)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/wandb/run-20250703_130806-4e4c4_00000
[36m(_WandbLoggingActor pid=15344)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=15344)[0m wandb: Syncing run PPO_env_4e4c4_00000
[36m(_WandbLoggingActor pid=15344)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=15344)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/4e4c4_00000


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-396.8680596226132,num_env_steps_sampled_lifetime=4000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
== Status ==
Current time: 2025-07-03 13:08:10 (running for 00:00:11.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |   ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      1 |          4.98731 | 4000 |          -396.868 |        -209.773 |            -86.8778 |        -92.2344 |            -7.98317 |
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000000)
[36m(MultiAgentEnvRunner pid=15110)[0m 2025-07-03 13:08:03,315	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8087x across cluster][0m
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000000)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000001)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000001)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:08:15 (running for 00:00:16.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |   ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      2 |          9.45725 | 8000 |          -417.254 |        -206.953 |            -83.4397 |        -92.3866 |            -34.4747 |
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9961x across cluster][0m
Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-395.4260789029734,num_env_steps_sampled_lifetime=12000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000002)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000002)...
[36m(_WandbLoggingActor pid=15344)[0m Done. 0.0s
== Status ==
Current time: 2025-07-03 13:08:20 (running for 00:00:21.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      3 |          14.0663 | 12000 |          -395.426 |        -209.664 |            -89.2844 |        -86.5664 |            -9.91134 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9456x across cluster][0m
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000003)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000003)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15109)[0m
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9712x across cluster][0m
== Status ==
Current time: 2025-07-03 13:08:26 (running for 00:00:26.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      4 |          18.5816 | 16000 |          -357.926 |        -201.251 |            -89.5406 |        -85.3873 |             18.2527 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-328.6318818466733,num_env_steps_sampled_lifetime=20000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000004)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000004)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9736x across cluster][0m
== Status ==
Current time: 2025-07-03 13:08:31 (running for 00:00:31.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      5 |           23.112 | 20000 |          -328.632 |        -203.073 |            -74.7636 |        -84.0108 |             33.2151 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000005)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000005)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15109)[0m
== Status ==
Current time: 2025-07-03 13:08:36 (running for 00:00:36.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      6 |           27.649 | 24000 |          -302.656 |        -204.204 |             -50.888 |        -83.4236 |             35.8594 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-285.2097814617649,num_env_steps_sampled_lifetime=28000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000006)
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9216x across cluster][0m
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:08:41 (running for 00:00:41.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      7 |          32.1867 | 28000 |           -285.21 |        -199.612 |            -26.1969 |        -78.7826 |             19.3814 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000007)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000007)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9840x across cluster][0m
== Status ==
Current time: 2025-07-03 13:08:46 (running for 00:00:47.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      8 |          36.6556 | 32000 |          -280.869 |        -197.896 |            -17.1634 |        -77.8417 |             12.0316 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-249.4028887269827,num_env_steps_sampled_lifetime=36000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000008)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000008)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9863x across cluster][0m
== Status ==
Current time: 2025-07-03 13:08:51 (running for 00:00:52.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |      9 |          41.1472 | 36000 |          -249.403 |        -197.458 |             6.80142 |        -78.8672 |              20.121 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000009)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000009)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9569x across cluster][0m
[36m(MultiAgentEnvRunner pid=15110)[0m
== Status ==
Current time: 2025-07-03 13:08:56 (running for 00:00:57.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     10 |            45.72 | 40000 |          -225.494 |        -196.796 |             15.2507 |        -74.7836 |             30.8353 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-202.53395482698224,num_env_steps_sampled_lifetime=44000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000010)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000010)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15109)[0m
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9792x across cluster][0m
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000011)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000011)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:09:01 (running for 00:01:02.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     12 |          54.7689 | 48000 |          -197.078 |        -195.246 |             28.7687 |        -78.0323 |             47.4315 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-188.38103769736043,num_env_steps_sampled_lifetime=52000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000012)
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9136x across cluster][0m
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000012)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:09:06 (running for 00:01:07.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     13 |          59.3009 | 52000 |          -188.381 |        -193.865 |             27.6116 |        -79.2809 |             57.1538 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=15110)[0m
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000013)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000013)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9844x across cluster][0m
== Status ==
Current time: 2025-07-03 13:09:11 (running for 00:01:12.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     14 |          63.7882 | 56000 |          -185.973 |        -192.435 |              29.883 |        -80.3035 |             56.8822 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-174.70764963158442,num_env_steps_sampled_lifetime=60000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000014)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000014)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9564x across cluster][0m
[36m(MultiAgentEnvRunner pid=15110)[0m
== Status ==
Current time: 2025-07-03 13:09:16 (running for 00:01:17.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     15 |          68.3596 | 60000 |          -174.708 |        -191.967 |             30.1127 |        -80.1971 |             67.3434 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000015)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000015)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9768x across cluster][0m
== Status ==
Current time: 2025-07-03 13:09:21 (running for 00:01:22.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     16 |          72.8928 | 64000 |          -159.399 |        -190.381 |             36.4845 |        -80.6779 |             75.1757 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-156.53021328939175,num_env_steps_sampled_lifetime=68000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000016)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000016)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9678x across cluster][0m
== Status ==
Current time: 2025-07-03 13:09:26 (running for 00:01:27.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     17 |           77.416 | 68000 |           -156.53 |        -189.891 |             32.3266 |        -81.0238 |             82.0576 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000017)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000017)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m
== Status ==
Current time: 2025-07-03 13:09:31 (running for 00:01:32.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     18 |          81.9689 | 72000 |          -144.139 |        -188.191 |             40.3948 |        -80.9189 |             84.5762 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-127.0641215057399,num_env_steps_sampled_lifetime=76000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000018)
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9178x across cluster][0m
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000018)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:09:36 (running for 00:01:37.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     19 |          86.5788 | 76000 |          -127.064 |         -187.94 |              48.431 |        -80.8613 |             93.3058 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000019)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000019)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9576x across cluster][0m
== Status ==
Current time: 2025-07-03 13:09:41 (running for 00:01:42.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     20 |          91.1325 | 80000 |          -128.692 |        -188.467 |             43.7698 |        -81.4101 |             97.4162 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-124.09716405145488,num_env_steps_sampled_lifetime=84000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000020)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000020)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9744x across cluster][0m
== Status ==
Current time: 2025-07-03 13:09:46 (running for 00:01:47.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     21 |          95.6694 | 84000 |          -124.097 |         -188.81 |             39.4215 |        -81.8759 |             107.167 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000021)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000021)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9776x across cluster][0m
Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-110.05974822280555,num_env_steps_sampled_lifetime=92000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000022)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000022)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:09:51 (running for 00:01:52.69)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     23 |          104.762 | 92000 |           -110.06 |        -189.324 |             39.7777 |        -81.5822 |             121.069 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9760x across cluster][0m
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000023)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000023)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m
== Status ==
Current time: 2025-07-03 13:09:56 (running for 00:01:57.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     24 |          109.288 | 96000 |          -97.0098 |        -188.067 |             41.3328 |        -80.7921 |             130.517 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-89.98875336449888,num_env_steps_sampled_lifetime=100000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000024)
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9296x across cluster][0m
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000024)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:10:01 (running for 00:02:02.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     25 |          113.859 | 100000 |          -89.9888 |        -188.828 |             40.2148 |        -80.5926 |             139.217 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000025)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000025)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9814x across cluster][0m
[36m(MultiAgentEnvRunner pid=15110)[0m
== Status ==
Current time: 2025-07-03 13:10:07 (running for 00:02:07.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     26 |          118.381 | 104000 |          -63.8279 |        -188.258 |              51.651 |         -80.571 |              153.35 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-37.08139180425478,num_env_steps_sampled_lifetime=108000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000026)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000026)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9346x across cluster][0m
== Status ==
Current time: 2025-07-03 13:10:12 (running for 00:02:12.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     27 |          122.999 | 108000 |          -37.0814 |        -186.031 |             59.8174 |         -80.126 |             169.258 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000027)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000027)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9696x across cluster][0m
== Status ==
Current time: 2025-07-03 13:10:17 (running for 00:02:17.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     28 |          127.537 | 112000 |          -16.9471 |        -184.146 |             68.3764 |        -80.4984 |             179.321 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=6.266643472871781,num_env_steps_sampled_lifetime=116000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000028)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000028)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15109)[0m
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9632x across cluster][0m
== Status ==
Current time: 2025-07-03 13:10:22 (running for 00:02:22.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     29 |          132.081 | 116000 |           6.26664 |        -183.604 |             79.2626 |        -80.2425 |             190.851 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000029)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000029)... Done. 0.0s


== Status ==
Current time: 2025-07-03 13:10:27 (running for 00:02:27.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     30 |          136.582 | 120000 |           24.1434 |        -180.946 |             86.3257 |        -79.7965 |              198.56 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=51.789489124364145,num_env_steps_sampled_lifetime=124000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000030)
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9520x across cluster][0m
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000030)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:10:32 (running for 00:02:33.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     31 |          141.062 | 124000 |           51.7895 |         -179.08 |             94.0678 |        -79.0916 |             215.893 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000031)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000031)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9664x across cluster][0m
== Status ==
Current time: 2025-07-03 13:10:37 (running for 00:02:38.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     32 |          145.557 | 128000 |           65.1013 |        -178.566 |             92.3647 |        -79.9733 |             231.276 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=87.76780760456312,num_env_steps_sampled_lifetime=132000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000032)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000032)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9816x across cluster][0m
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000033)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000033)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:10:42 (running for 00:02:43.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     34 |          154.561 | 136000 |           95.6778 |        -178.307 |             95.6816 |         -78.951 |             257.255 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 10168x across cluster][0m
Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=101.28491064593831,num_env_steps_sampled_lifetime=140000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000034)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000034)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:10:47 (running for 00:02:48.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     35 |          159.049 | 140000 |           101.285 |        -176.646 |             93.7758 |        -80.1356 |              264.29 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=15109)[0m
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 10004x across cluster][0m
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000035)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000035)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m
== Status ==
Current time: 2025-07-03 13:10:52 (running for 00:02:53.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     36 |          163.585 | 144000 |           96.2393 |        -176.981 |              89.722 |         -79.403 |             262.901 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=15109)[0m
Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=109.19824110098573,num_env_steps_sampled_lifetime=148000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000036)
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8431x across cluster][0m
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000036)... Done. 0.0s
== Status ==
Current time: 2025-07-03 13:10:57 (running for 00:02:58.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     37 |          168.121 | 148000 |           109.198 |        -176.062 |              92.193 |        -78.3653 |             271.433 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000037)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000037)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9613x across cluster][0m
== Status ==
Current time: 2025-07-03 13:11:02 (running for 00:03:03.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     38 |          172.665 | 152000 |           114.643 |        -175.105 |              94.463 |        -77.3779 |             272.663 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=136.23606655187797,num_env_steps_sampled_lifetime=156000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000038)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000038)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9296x across cluster][0m
== Status ==
Current time: 2025-07-03 13:11:07 (running for 00:03:08.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     39 |          177.293 | 156000 |           136.236 |        -174.004 |             95.4111 |        -75.7751 |             290.604 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000039)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000039)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9864x across cluster][0m
[36m(MultiAgentEnvRunner pid=15110)[0m
== Status ==
Current time: 2025-07-03 13:11:12 (running for 00:03:13.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     40 |          181.801 | 160000 |           135.425 |        -172.669 |             101.096 |        -75.6859 |             282.684 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_4e4c4_00000 reported env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=150.59500176474867,num_env_steps_sampled_lifetime=164000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000040)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000040)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9544x across cluster][0m
== Status ==
Current time: 2025-07-03 13:11:17 (running for 00:03:18.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     41 |          186.376 | 164000 |           150.595 |        -172.855 |             102.152 |         -74.644 |             295.942 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=14979)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000041)
[36m(_WandbLoggingActor pid=15344)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-03_13-07-59/PPO_env_4e4c4_00000_0_2025-07-03_13-07-59/checkpoint_000041)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=15110)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 9656x across cluster][0m
== Status ==
Current time: 2025-07-03 13:11:22 (running for 00:03:23.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-03_13-07-57_100210_13210/artifacts/2025-07-03_13-07-59/PPO_2025-07-03_13-07-59/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_1 |   return prey_0 |   return predator_0 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_4e4c4_00000 | RUNNING  | 192.168.0.25:14979 |     42 |          190.903 | 168000 |            157.23 |        -172.712 |             111.543 |         -74.368 |             292.767 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
