['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-10 13:17:01,005	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-10 13:17:01,549	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-10 13:17:01 (running for 00:00:00.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_ba5f0_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=2016592)[0m 2025-07-10 13:17:03,579	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html


[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(PPO pid=2016592)[0m 2025-07-10 13:17:05,828	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
[36m(PPO pid=2016592)[0m Install gputil for GPU system monitoring.
== Status ==
Current time: 2025-07-10 13:17:06 (running for 00:00:05.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+
| Trial name          | status   | loc                  |
|---------------------+----------+----------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |
+---------------------+----------+----------------------+


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(_WandbLoggingActor pid=2016857)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=2016857)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/wandb/run-20250710_131708-ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Syncing run PPO_env_ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=2016857)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/ba5f0_00000
== Status ==
Current time: 2025-07-10 13:17:11 (running for 00:00:10.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+
| Trial name          | status   | loc                  |
|---------------------+----------+----------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |
+---------------------+----------+----------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000000)
[36m(MultiAgentEnvRunner pid=2016686)[0m 2025-07-10 13:17:05,769	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 6x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 6x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 6x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000000)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:17:16 (running for 00:00:15.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      1 |          6.35642 | 4000 |           -289.11 |            -33.7119 |        -71.3009 |        -79.0019 |            -105.095 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000001)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000001)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:17:21 (running for 00:00:20.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      2 |          11.3197 | 8000 |           -353.21 |            -57.0357 |        -54.1866 |        -138.069 |             -103.92 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000002)


[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 4x across cluster][0m
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000002)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 5x across cluster][0m
== Status ==
Current time: 2025-07-10 13:17:26 (running for 00:00:25.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      3 |          16.7629 | 12000 |          -377.026 |            -62.2435 |        -85.2588 |        -127.924 |              -101.6 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000003)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000003)... Done. 0.0s


== Status ==
Current time: 2025-07-10 13:17:31 (running for 00:00:30.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      4 |          23.0378 | 16000 |          -341.601 |            -65.9485 |        -88.2856 |        -109.532 |            -77.8349 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000004)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000004)... Done. 0.0s
== Status ==
Current time: 2025-07-10 13:17:36 (running for 00:00:35.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      5 |          28.2527 | 20000 |          -346.947 |            -69.6582 |        -89.7969 |        -116.361 |            -71.1306 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000005)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000005)... Done. 0.0s
== Status ==
Current time: 2025-07-10 13:17:42 (running for 00:00:40.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      6 |          33.6863 | 24000 |          -350.314 |            -75.7221 |         -80.056 |         -120.18 |            -74.3555 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000006)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-10 13:17:47 (running for 00:00:45.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      7 |          38.6449 | 28000 |          -349.975 |            -74.2184 |        -74.4005 |        -124.179 |            -77.1762 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:17:52 (running for 00:00:50.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      7 |          38.6449 | 28000 |          -349.975 |            -74.2184 |        -74.4005 |        -124.179 |            -77.1762 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000007)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000007)...
[36m(_WandbLoggingActor pid=2016857)[0m Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
== Status ==
Current time: 2025-07-10 13:17:57 (running for 00:00:55.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      8 |          44.0813 | 32000 |          -347.879 |            -68.5081 |        -71.2008 |        -128.817 |            -79.3536 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000008)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000008)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:18:02 (running for 00:01:00.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |      9 |          49.4944 | 36000 |          -343.592 |            -62.1632 |        -67.9586 |        -135.703 |            -77.7674 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000009)


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000009)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
== Status ==
Current time: 2025-07-10 13:18:07 (running for 00:01:05.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     10 |           54.819 | 40000 |          -342.454 |            -62.3897 |        -73.5892 |        -132.369 |            -74.1067 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000010)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000010)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:18:12 (running for 00:01:10.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     11 |          59.9981 | 44000 |           -343.52 |            -60.2372 |        -76.1437 |        -131.087 |            -76.0529 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000011)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000011)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:18:17 (running for 00:01:15.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     12 |          65.0643 | 48000 |          -332.014 |            -49.4146 |        -75.5725 |        -133.064 |            -73.9629 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000012)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000012)...
[36m(_WandbLoggingActor pid=2016857)[0m Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:18:22 (running for 00:01:20.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     13 |          70.8849 | 52000 |          -323.912 |            -48.4502 |        -72.5929 |        -133.345 |            -69.5238 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000013)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000013)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:18:27 (running for 00:01:25.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     14 |          75.7646 | 56000 |          -325.972 |            -47.6857 |        -73.1476 |        -135.161 |            -69.9778 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000014)


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000014)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:18:32 (running for 00:01:31.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     15 |          80.9018 | 60000 |           -318.08 |            -43.3756 |        -71.1109 |        -135.268 |            -68.3257 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000015)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000015)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:18:37 (running for 00:01:36.05)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     16 |           86.226 | 64000 |          -296.228 |            -26.9957 |        -69.3445 |        -131.225 |            -68.6634 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000016)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000016)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:18:42 (running for 00:01:41.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     17 |          91.3944 | 68000 |          -273.718 |            -11.3025 |        -69.7197 |        -127.344 |            -65.3519 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000017)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000017)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:18:47 (running for 00:01:46.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     18 |          96.8191 | 72000 |          -262.891 |            -5.15564 |        -69.9876 |        -124.113 |            -63.6351 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000018)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000018)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:18:52 (running for 00:01:51.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     19 |          101.843 | 76000 |          -265.049 |            -6.19021 |        -72.1258 |        -123.419 |            -63.3145 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000019)
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000019)... Done. 0.0s
== Status ==
Current time: 2025-07-10 13:18:57 (running for 00:01:56.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     20 |          107.524 | 80000 |          -266.247 |            -7.49316 |        -73.5965 |        -121.093 |            -64.0646 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 7x across cluster][0m
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000020)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000020)... Done. 0.0s
== Status ==
Current time: 2025-07-10 13:19:02 (running for 00:02:01.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     21 |          113.586 | 84000 |          -257.759 |            -3.00019 |        -74.8092 |        -119.097 |            -60.8525 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:19:07 (running for 00:02:06.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     21 |          113.586 | 84000 |          -257.759 |            -3.00019 |        -74.8092 |        -119.097 |            -60.8525 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000021)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000021)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:19:12 (running for 00:02:11.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     22 |          119.181 | 88000 |          -229.912 |             10.8699 |        -70.4348 |        -117.522 |            -52.8254 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000022)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000022)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
== Status ==
Current time: 2025-07-10 13:19:17 (running for 00:02:16.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     23 |          123.999 | 92000 |          -210.586 |             17.6517 |        -69.0065 |        -119.421 |              -39.81 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000023)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000023)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:19:22 (running for 00:02:21.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     24 |          129.961 | 96000 |          -203.464 |             25.6111 |        -64.3919 |        -121.479 |            -43.2038 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000024)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000024)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:19:27 (running for 00:02:26.37)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     25 |          134.885 | 100000 |          -198.122 |             26.5081 |        -65.2806 |        -121.229 |            -38.1207 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000025)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000025)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
== Status ==
Current time: 2025-07-10 13:19:32 (running for 00:02:31.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     26 |          140.041 | 104000 |           -154.68 |             41.0982 |        -64.0132 |        -113.287 |            -18.4779 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000026)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000026)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:19:37 (running for 00:02:36.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     27 |          145.344 | 108000 |          -144.877 |             44.1125 |        -65.8475 |        -113.042 |            -10.1005 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000027)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000027)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:19:42 (running for 00:02:41.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     28 |           150.21 | 112000 |          -119.691 |             52.7938 |        -65.9824 |        -109.944 |             3.44177 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000028)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000028)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:19:48 (running for 00:02:46.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     29 |          155.525 | 116000 |          -110.192 |             54.9357 |        -68.3936 |         -108.38 |             11.6458 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000029)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000029)...
[36m(_WandbLoggingActor pid=2016857)[0m Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
== Status ==
Current time: 2025-07-10 13:19:53 (running for 00:02:51.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     30 |          160.842 | 120000 |          -104.971 |             57.8091 |        -70.0648 |        -103.983 |             11.2675 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000030)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000030)...
[36m(_WandbLoggingActor pid=2016857)[0m Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m 2025-07-10 13:19:57,238	ERROR actor_manager.py:187 -- Worker exception caught during `apply()`: integer division or modulo by zero
[36m(MultiAgentEnvRunner pid=2016686)[0m Traceback (most recent call last):
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 183, in apply
[36m(MultiAgentEnvRunner pid=2016686)[0m     return func(self, *args, **kwargs)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py", line 110, in <lambda>
[36m(MultiAgentEnvRunner pid=2016686)[0m     else (lambda w: (w.sample(**random_action_kwargs), w.get_metrics()))
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py", line 463, in _resume_span
[36m(MultiAgentEnvRunner pid=2016686)[0m     return method(self, *_args, **_kwargs)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env_runner.py", line 222, in sample
[36m(MultiAgentEnvRunner pid=2016686)[0m     samples = self._sample(
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py", line 463, in _resume_span
[36m(MultiAgentEnvRunner pid=2016686)[0m     return method(self, *_args, **_kwargs)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env_runner.py", line 358, in _sample
[36m(MultiAgentEnvRunner pid=2016686)[0m     results = self._try_env_step(actions_for_env)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py", line 463, in _resume_span
[36m(MultiAgentEnvRunner pid=2016686)[0m     return method(self, *_args, **_kwargs)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/env_runner.py", line 208, in _try_env_step
[36m(MultiAgentEnvRunner pid=2016686)[0m     raise e
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/env_runner.py", line 193, in _try_env_step
[36m(MultiAgentEnvRunner pid=2016686)[0m     results = self.env.step(actions)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/vector/sync_vector_multi_agent_env.py", line 135, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     ) = self.envs[i].step(action)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     return super().step(action)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/core.py", line 322, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     return self.env.step(action)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py", line 152, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     self.env.step(action[self.env.agent_selection])
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/order_enforcing.py", line 70, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     super().step(action)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py", line 47, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     self.env.step(action)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/clip_out_of_bounds.py", line 52, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     super().step(action)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py", line 47, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     self.env.step(action)
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld.py", line 264, in step
[36m(MultiAgentEnvRunner pid=2016686)[0m     self.agent_selection = self._agent_selector.next()
[36m(MultiAgentEnvRunner pid=2016686)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/agent_selector.py", line 44, in next
[36m(MultiAgentEnvRunner pid=2016686)[0m     self._current_agent = (self._current_agent + 1) % len(self.agent_order)
[36m(MultiAgentEnvRunner pid=2016686)[0m ZeroDivisionError: integer division or modulo by zero
== Status ==
Current time: 2025-07-10 13:19:58 (running for 00:02:56.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:03 (running for 00:03:01.67)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:08 (running for 00:03:06.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:13 (running for 00:03:11.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:18 (running for 00:03:16.79)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:23 (running for 00:03:21.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:28 (running for 00:03:26.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:33 (running for 00:03:31.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:38 (running for 00:03:36.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:43 (running for 00:03:41.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:48 (running for 00:03:47.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:20:53 (running for 00:03:52.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016686)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffeeba804d5aa450af82ec70a801000000 Worker ID: 3e416c7ea3d1646b18c88de80e8d456c5535ad5564a9d777faca8baf Node ID: 98b040497795e5873915a046f812b464b30f12bcb3d80ca3e90eb3f7 Worker IP address: 192.168.0.25 Worker port: 43189 Worker PID: 2016686 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.
== Status ==
Current time: 2025-07-10 13:20:58 (running for 00:03:57.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     31 |          166.338 | 124000 |          -88.9783 |             58.8348 |        -63.6534 |        -101.813 |             17.6533 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m 2025-07-10 13:20:59,008	ERROR actor_manager.py:873 -- Ray error (The actor eeba804d5aa450af82ec70a801000000 is unavailable: The actor is temporarily unavailable: IOError: Fail all inflight tasks due to actor state change.. The task may or maynot have been executed on the actor.), taking actor 2 out of service.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m 2025-07-10 13:20:59,008	ERROR actor_manager.py:674 -- The actor eeba804d5aa450af82ec70a801000000 is unavailable: The actor is temporarily unavailable: IOError: Fail all inflight tasks due to actor state change.. The task may or maynot have been executed on the actor.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m NoneType: None
[36m(MultiAgentEnvRunner pid=2018408)[0m 2025-07-10 13:20:59,414	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000031)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m 2025-07-10 13:21:01,901	WARNING actor_manager.py:886 -- Bringing previously unhealthy, now-healthy actor 2 back into service.
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000031)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:21:03 (running for 00:04:02.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     32 |          232.367 | 128000 |           -33.254 |             81.2393 |        -46.5064 |          -96.55 |              28.563 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000032)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000032)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:21:08 (running for 00:04:07.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     33 |          238.134 | 70000 |          -135.795 |              38.041 |        -56.6785 |        -112.304 |            -4.85278 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000033)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000033)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2016685)[0m 2025-07-10 13:21:13,780	ERROR actor_manager.py:187 -- Worker exception caught during `apply()`: integer division or modulo by zero
[36m(MultiAgentEnvRunner pid=2016685)[0m Traceback (most recent call last):
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 183, in apply
[36m(MultiAgentEnvRunner pid=2016685)[0m     return func(self, *args, **kwargs)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/execution/rollout_ops.py", line 110, in <lambda>
[36m(MultiAgentEnvRunner pid=2016685)[0m     else (lambda w: (w.sample(**random_action_kwargs), w.get_metrics()))
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py", line 463, in _resume_span
[36m(MultiAgentEnvRunner pid=2016685)[0m     return method(self, *_args, **_kwargs)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env_runner.py", line 222, in sample
[36m(MultiAgentEnvRunner pid=2016685)[0m     samples = self._sample(
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py", line 463, in _resume_span
[36m(MultiAgentEnvRunner pid=2016685)[0m     return method(self, *_args, **_kwargs)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/multi_agent_env_runner.py", line 358, in _sample
[36m(MultiAgentEnvRunner pid=2016685)[0m     results = self._try_env_step(actions_for_env)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py", line 463, in _resume_span
[36m(MultiAgentEnvRunner pid=2016685)[0m     return method(self, *_args, **_kwargs)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/env_runner.py", line 208, in _try_env_step
[36m(MultiAgentEnvRunner pid=2016685)[0m     raise e
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/env_runner.py", line 193, in _try_env_step
[36m(MultiAgentEnvRunner pid=2016685)[0m     results = self.env.step(actions)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/vector/sync_vector_multi_agent_env.py", line 135, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     ) = self.envs[i].step(action)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/wrappers/common.py", line 393, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     return super().step(action)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/core.py", line 322, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     return self.env.step(action)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/ray/rllib/env/wrappers/pettingzoo_env.py", line 152, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     self.env.step(action[self.env.agent_selection])
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/order_enforcing.py", line 70, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     super().step(action)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py", line 47, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     self.env.step(action)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/clip_out_of_bounds.py", line 52, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     super().step(action)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py", line 47, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     self.env.step(action)
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld.py", line 264, in step
[36m(MultiAgentEnvRunner pid=2016685)[0m     self.agent_selection = self._agent_selector.next()
[36m(MultiAgentEnvRunner pid=2016685)[0m   File "/home/qrbao/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/agent_selector.py", line 44, in next
[36m(MultiAgentEnvRunner pid=2016685)[0m     self._current_agent = (self._current_agent + 1) % len(self.agent_order)
[36m(MultiAgentEnvRunner pid=2016685)[0m ZeroDivisionError: integer division or modulo by zero
[36m(MultiAgentEnvRunner pid=2016685)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:21:13 (running for 00:04:12.33)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:18 (running for 00:04:17.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:23 (running for 00:04:22.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:28 (running for 00:04:27.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:34 (running for 00:04:32.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:39 (running for 00:04:37.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:44 (running for 00:04:42.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:49 (running for 00:04:47.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:54 (running for 00:04:52.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:21:59 (running for 00:04:57.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:22:04 (running for 00:05:02.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


== Status ==
Current time: 2025-07-10 13:22:09 (running for 00:05:07.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd7e1f358c112e63ef06825c001000000 Worker ID: ade8baa61d921bc273c59e27709e5a1bb63fe9b4d0ee82a4cc4f7219 Node ID: 98b040497795e5873915a046f812b464b30f12bcb3d80ca3e90eb3f7 Worker IP address: 192.168.0.25 Worker port: 35321 Worker PID: 2016685 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code 1.
== Status ==
Current time: 2025-07-10 13:22:14 (running for 00:05:12.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     34 |          243.129 | 74000 |          -127.775 |             49.9692 |        -58.1614 |        -114.064 |            -5.51899 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m 2025-07-10 13:22:15,101	ERROR actor_manager.py:873 -- Ray error (The actor d7e1f358c112e63ef06825c001000000 is unavailable: The actor is temporarily unavailable: IOError: Fail all inflight tasks due to actor state change.. The task may or maynot have been executed on the actor.), taking actor 1 out of service.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m 2025-07-10 13:22:15,102	ERROR actor_manager.py:674 -- The actor d7e1f358c112e63ef06825c001000000 is unavailable: The actor is temporarily unavailable: IOError: Fail all inflight tasks due to actor state change.. The task may or maynot have been executed on the actor.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m NoneType: None
[36m(MultiAgentEnvRunner pid=2018649)[0m 2025-07-10 13:22:15,984	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000034)
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m 2025-07-10 13:22:18,255	WARNING actor_manager.py:886 -- Bringing previously unhealthy, now-healthy actor 1 back into service.
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000034)...
[36m(_WandbLoggingActor pid=2016857)[0m Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018649)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:22:19 (running for 00:05:17.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     35 |          308.599 | 78000 |          -0.85047 |             98.9662 |        -56.8088 |        -131.119 |             88.1113 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000035)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000035)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018649)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:22:24 (running for 00:05:22.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     36 |          314.332 | 12000 |          -33.7878 |             52.6559 |        -62.6282 |        -107.872 |             84.0569 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000036)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000036)... Done. 0.0s
== Status ==
Current time: 2025-07-10 13:22:29 (running for 00:05:27.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     37 |          319.484 | 16000 |          -34.3272 |             73.7143 |        -75.5932 |        -102.795 |             70.3465 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+


[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
== Status ==
Current time: 2025-07-10 13:22:34 (running for 00:05:33.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     37 |          319.484 | 16000 |          -34.3272 |             73.7143 |        -75.5932 |        -102.795 |             70.3465 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000037)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000037)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:22:39 (running for 00:05:38.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     38 |          324.858 | 20000 |           39.6867 |             80.6487 |          -65.53 |        -98.9423 |              123.51 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000038)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000038)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018649)[0m Reset complete:[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:22:44 (running for 00:05:43.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     39 |           330.24 | 24000 |           61.5666 |             87.7762 |         -60.341 |        -99.1245 |             133.256 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000039)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000039)...
[36m(_WandbLoggingActor pid=2016857)[0m Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:22:49 (running for 00:05:48.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     40 |          335.515 | 28000 |           134.401 |             136.832 |        -61.2515 |        -90.8094 |              149.63 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000040)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000040)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 3x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 4x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 7x across cluster][0m
== Status ==
Current time: 2025-07-10 13:22:54 (running for 00:05:53.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     41 |          340.218 | 32000 |           144.313 |             145.021 |        -60.3217 |         -93.183 |             152.798 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000041)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000041)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:22:59 (running for 00:05:58.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     42 |          346.082 | 36000 |           107.119 |             127.854 |        -72.8457 |        -87.8851 |             139.995 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000042)


[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018408)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 1 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:23:04 (running for 00:06:03.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     43 |           351.23 | 40000 |           146.486 |             164.395 |        -68.7397 |        -89.9387 |             140.769 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000043)


[36m(MultiAgentEnvRunner pid=2018649)[0m Reset complete:[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   Agents: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m   _cumulative_rewards keys: ['predator_0', 'predator_1', 'prey_0', 'prey_1'][32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018408)[0m Agent 0 (predator) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%[32m [repeated 2x across cluster][0m
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 3 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
[36m(MultiAgentEnvRunner pid=2018649)[0m Agent 2 (prey) ‰∏çÂπ∏Èòµ‰∫°! Ê≠ª‰∫°Ê¶ÇÁéá: 0.1%
== Status ==
Current time: 2025-07-10 13:23:09 (running for 00:06:08.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | RUNNING  | 192.168.0.25:2016592 |     44 |          356.927 | 44000 |           187.458 |             195.337 |        -65.2809 |        -91.0826 |             148.485 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000042)... Done. 0.0s
2025-07-10 13:23:12,310	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-07-10_13-17-01' in 0.0283s.


== Status ==
Current time: 2025-07-10 13:23:12 (running for 00:06:10.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-10_13-17-00_458093_2014828/artifacts/2025-07-10_13-17-01/PPO_2025-07-10_13-17-01/driver_artifacts
Number of trials: 1/1 (1 TERMINATED)
+---------------------+------------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
| Trial name          | status     | loc                  |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return prey_0 |   return prey_1 |   return predator_1 |
|---------------------+------------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------|
| PPO_env_ba5f0_00000 | TERMINATED | 192.168.0.25:2016592 |     45 |          362.176 | 48000 |           208.638 |             196.142 |        -62.9223 |        -91.4801 |             166.898 |
+---------------------+------------+----------------------+--------+------------------+-------+-------------------+---------------------+-----------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=2016592)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000044)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000043)... Done. 0.0s
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-10_13-17-01/PPO_env_ba5f0_00000_0_2025-07-10_13-17-01/checkpoint_000044)...
[36m(_WandbLoggingActor pid=2016857)[0m Done. 0.0s
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; updating run metadata; uploading artifact checkpoint_PPO_env_ba5f0_00000 (+ 1 more)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; updating run metadata; uploading artifact checkpoint_PPO_env_ba5f0_00000 (+ 2 more)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000 (+ 3 more)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000 (+ 4 more)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000 (+ 1 more)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading data
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading data
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000; uploading artifact checkpoint_PPO_env_ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading artifact checkpoint_PPO_env_ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: uploading data
2025-07-10 13:25:15,071	INFO tune.py:1041 -- Total run time: 493.63 seconds (370.73 seconds for the tuning loop).


ËÆ≠ÁªÉÂÆåÊàê
[36m(_WandbLoggingActor pid=2016857)[0m wandb:
[36m(_WandbLoggingActor pid=2016857)[0m wandb:
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Run history:
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    env_runners/agent_steps/predator_0 ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    env_runners/agent_steps/predator_1 ‚ñà‚ñà‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/agent_steps/prey_0 ‚ñÅ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/agent_steps/prey_1 ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  env_runners/connector_pipeline_timer ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           env_runners/env_reset_timer ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            env_runners/env_step_timer ‚ñÉ‚ñÇ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 env_runners/episode_duration_sec_mean ‚ñÅ‚ñá‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           env_runners/episode_len_max ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                          env_runners/episode_len_mean ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           env_runners/episode_len_min ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/episode_return_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                       env_runners/episode_return_mean ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/episode_return_min ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ‚ñÑ‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÇ
Ëé∑ÂèñÊúÄ‰Ω≥checkpoint...
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñà‚ñá‚ñÑ‚ñÜ‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     env_runners/num_env_steps_sampled ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                              env_runners/num_episodes ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     env_runners/num_episodes_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ‚ñà‚ñÜ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  env_runners/rlmodule_inference_timer ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                    env_runners/sample ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     env_runners/time_between_sampling ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            env_runners/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                   fault_tolerance/num_healthy_workers ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                              iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ‚ñá‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ‚ñá‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_0/entropy ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/predator_0/mean_kl_loss ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_0/num_module_steps_trained ‚ñá‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                       learners/predator_0/policy_loss ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/predator_0/total_loss ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  learners/predator_0/vf_explained_var ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_0/vf_loss ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñá‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/predator_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_1/entropy ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/predator_1/mean_kl_loss ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_1/num_module_steps_trained ‚ñá‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                       learners/predator_1/policy_loss ‚ñÑ‚ñÉ‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/predator_1/total_loss ‚ñÉ‚ñÉ‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  learners/predator_1/vf_explained_var ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_1/vf_loss ‚ñà‚ñÖ‚ñá‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/predator_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_0/entropy ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÜ‚ñÅ‚ñà‚ñá‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                          learners/prey_0/mean_kl_loss ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñà‚ñÅ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÅ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_0/num_module_steps_trained ‚ñá‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/prey_0/policy_loss ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            learners/prey_0/total_loss ‚ñÜ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/prey_0/vf_explained_var ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_0/vf_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÉ‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÉ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/prey_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_1/entropy ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                          learners/prey_1/mean_kl_loss ‚ñÖ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÇ‚ñá‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_1/num_module_steps_trained ‚ñá‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/prey_1/policy_loss ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÅ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñà‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            learners/prey_1/total_loss ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñá‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñà‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/prey_1/vf_explained_var ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñà‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_1/vf_loss ‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÖ‚ñà‚ñÖ‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñÇ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñá‚ñÑ‚ñá‚ñÉ‚ñÅ‚ñá‚ñÉ‚ñÜ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/prey_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 num_training_step_calls_per_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                 perf/cpu_util_percent ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñÑ‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÅ‚ñá‚ñá‚ñÅ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                 perf/ram_util_percent ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                    time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                      time_this_iter_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                          time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      timers/env_runner_sampling_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           timers/learner_update_timer ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            timers/restore_env_runners ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           timers/synch_env_connectors ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                  timers/synch_weights ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                             timers/training_iteration ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                  timers/training_step ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                             timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                    training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=2016857)[0m wandb:
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Run summary:
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 196.14192
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 166.89849
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 -62.92227
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 -91.48007
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    env_runners/agent_steps/predator_0 383.24138
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    env_runners/agent_steps/predator_1 417.96552
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/agent_steps/prey_0 407.58621
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/agent_steps/prey_1 399
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.00034
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           env_runners/env_reset_timer 0.0026
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            env_runners/env_step_timer 0.00047
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00012
[36m(_WandbLoggingActor pid=2016857)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 2e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 589.54371
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 589.54371
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 env_runners/episode_duration_sec_mean 1.8633
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           env_runners/episode_len_max 2000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                          env_runners/episode_len_mean 1607.7931
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           env_runners/episode_len_min 956
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/episode_return_max 1677.7113
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                       env_runners/episode_return_mean 208.63808
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        env_runners/episode_return_min -240.48152
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 196.14192
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 166.89849
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 -62.92227
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 -91.48007
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00023
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 9e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 3e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 730
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1178
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1003
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1096
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 11469
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 12507
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 12157
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 11955
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 48000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 1122.8557
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                              env_runners/num_episodes 2
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     env_runners/num_episodes_lifetime 29
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 730
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1178
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1003
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1096
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 11469
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 12507
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 12157
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 11955
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.00011
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                    env_runners/sample 2.41598
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     env_runners/time_between_sampling 3.5773
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 3e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 3e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 5e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            env_runners/weights_seq_no 44
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 2
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                              iterations_since_restore 45
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.10327
[36m(_WandbLoggingActor pid=2016857)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03488
[36m(_WandbLoggingActor pid=2016857)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 0.00011
[36m(_WandbLoggingActor pid=2016857)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.00315
[36m(_WandbLoggingActor pid=2016857)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.00188
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.02435
[36m(_WandbLoggingActor pid=2016857)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.03692
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.00166
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 1108000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 51044000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 402825.64903
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 141824
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 6533632
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 2150630.73664
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 2117389.2519
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 578580
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 1.28145
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_0/entropy 1.35011
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 6.90953
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.01571
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_0/num_module_steps_trained 35456
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 1633408
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 12890.22191
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                       learners/predator_0/policy_loss -0.03966
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/predator_0/total_loss 0.02479
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  learners/predator_0/vf_explained_var 0.02776
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_0/vf_loss 8.86188
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 5051.07129
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/predator_0/weights_seq_no 45
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 1.70859
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1.00781
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_1/entropy 1.44157
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 18.70981
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.01322
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_1/num_module_steps_trained 35456
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 1633408
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 12890.15575
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/predator_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                       learners/predator_1/policy_loss -0.20675
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/predator_1/total_loss -0.13917
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                  learners/predator_1/vf_explained_var 0.05302
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/predator_1/vf_loss 8.99848
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 10593.6875
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/predator_1/weights_seq_no 45
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 1.28145
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_0/entropy 1.40657
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 9.98771
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.016
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_0/num_module_steps_trained 35456
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 1633408
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 12890.13876
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/prey_0/policy_loss -0.07486
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            learners/prey_0/total_loss -0.01329
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/prey_0/vf_explained_var 0.38741
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_0/vf_loss 8.2123
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 48.56131
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/prey_0/weights_seq_no 45
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 1.51875
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_1/entropy 0.45774
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 18.26187
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.01299
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_1/num_module_steps_trained 35456
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 1633408
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 12890.14086
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                              learners/prey_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           learners/prey_1/policy_loss -0.12686
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            learners/prey_1/total_loss -0.06765
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      learners/prey_1/vf_explained_var -0.00671
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                               learners/prey_1/vf_loss 7.89763
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 269.76801
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        learners/prey_1/weights_seq_no 45
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                        num_env_steps_sampled_lifetime 48000
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                 num_training_step_calls_per_iteration 1
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                 perf/cpu_util_percent 10.87143
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                 perf/ram_util_percent 23.3
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                    time_since_restore 362.17647
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                      time_this_iter_s 5.2499
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                          time_total_s 362.17647
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                      timers/env_runner_sampling_timer 3.66198
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           timers/learner_update_timer 3.39899
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                            timers/restore_env_runners 0.00015
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                           timers/synch_env_connectors 0.00141
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                  timers/synch_weights 0.00392
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                             timers/training_iteration 7.06566
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                  timers/training_step 7.06527
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                             timestamp 1752121392
[36m(_WandbLoggingActor pid=2016857)[0m wandb:                                                                                    training_iteration 45
[36m(_WandbLoggingActor pid=2016857)[0m wandb:
[36m(_WandbLoggingActor pid=2016857)[0m wandb: üöÄ View run PPO_env_ba5f0_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/ba5f0_00000
[36m(_WandbLoggingActor pid=2016857)[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 342 artifact file(s) and 0 other file(s)
[36m(_WandbLoggingActor pid=2016857)[0m wandb: Find logs at: ./wandb/run-20250710_131708-ba5f0_00000/logs
*** SIGTERM received at time=1752124004 on cpu 14 ***
PC: @     0x7ac3d492a042  (unknown)  epoll_wait
    @     0x7ac3d4845330  180667136  (unknown)
    @     0x7ac3d4a7d813  (unknown)  select_epoll_poll
[2025-07-10 14:06:44,950 E 2014828 2014828] logging.cc:496: *** SIGTERM received at time=1752124004 on cpu 14 ***
[2025-07-10 14:06:44,950 E 2014828 2014828] logging.cc:496: PC: @     0x7ac3d492a042  (unknown)  epoll_wait
[2025-07-10 14:06:44,950 E 2014828 2014828] logging.cc:496:     @     0x7ac3d4845330  180667136  (unknown)
[2025-07-10 14:06:44,950 E 2014828 2014828] logging.cc:496:     @     0x7ac3d4a7d813  (unknown)  select_epoll_poll
