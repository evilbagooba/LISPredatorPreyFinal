['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-04 17:39:41,871	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-04 17:39:42,296	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-04 17:39:42 (running for 00:00:00.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_6e160_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=39248)[0m 2025-07-04 17:39:44,299	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
[36m(PPO pid=39248)[0m 2025-07-04 17:39:46,527	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
[36m(PPO pid=39248)[0m Install gputil for GPU system monitoring.


== Status ==
Current time: 2025-07-04 17:39:47 (running for 00:00:05.19)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+
| Trial name          | status   | loc                |
|---------------------+----------+--------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |
+---------------------+----------+--------------------+
[36m(_WandbLoggingActor pid=39612)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(_WandbLoggingActor pid=39612)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=39612)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=39612)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=39612)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts/PPO_env_6e160_00000_0_2025-07-04_17-39-42/wandb/run-20250704_173949-6e160_00000
[36m(_WandbLoggingActor pid=39612)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=39612)[0m wandb: Syncing run PPO_env_6e160_00000
[36m(_WandbLoggingActor pid=39612)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=39612)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/6e160_00000


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=4000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-452.3029210419144 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
== Status ==
Current time: 2025-07-04 17:39:53 (running for 00:00:11.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |   ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      1 |          4.76459 | 4000 |          -452.303 |        -209.332 |             -58.382 |        -91.4089 |            -93.1804 |
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000000)
[36m(MultiAgentEnvRunner pid=39341)[0m 2025-07-04 17:39:46,457	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000000)... Done. 0.0s


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000001)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000001)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:39:58 (running for 00:00:16.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |   ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      2 |          9.25549 | 8000 |          -461.186 |        -210.062 |            -75.4185 |        -96.2375 |            -79.4677 |
+---------------------+----------+--------------------+--------+------------------+------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=12000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-455.9430304184136 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000002)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000002)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:03 (running for 00:00:21.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      3 |          13.8536 | 12000 |          -455.943 |        -206.674 |            -67.1964 |         -97.715 |            -84.3577 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000003)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000003)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:08 (running for 00:00:26.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      4 |          18.2832 | 16000 |          -457.258 |        -204.437 |            -68.9406 |        -98.5326 |            -85.3478 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=20000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-451.0720983430201 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000004)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000004)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:13 (running for 00:00:31.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      5 |          22.7907 | 20000 |          -451.072 |        -207.592 |            -67.8462 |        -92.3496 |             -83.284 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000005)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000005)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:18 (running for 00:00:36.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      6 |          27.2564 | 24000 |          -416.639 |          -206.6 |            -52.8704 |        -93.2947 |            -63.8741 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=28000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-415.2180959037656 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000006)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:23 (running for 00:00:41.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      7 |          31.7268 | 28000 |          -415.218 |        -205.165 |            -53.5438 |        -95.4355 |            -61.0734 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000007)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000007)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:28 (running for 00:00:46.67)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      8 |          36.1787 | 32000 |          -396.028 |        -204.947 |             -49.253 |        -92.8823 |            -48.9463 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=36000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-373.73992323922516 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000008)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000008)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:34 (running for 00:00:51.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |      9 |          40.6043 | 36000 |           -373.74 |        -206.029 |            -45.0701 |        -92.4236 |            -30.2175 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000009)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000009)... Done. 0.0s
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=44000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-326.2573399725472 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000010)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000010)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:39 (running for 00:00:56.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     11 |          49.5953 | 44000 |          -326.257 |        -206.854 |            -28.8307 |        -92.3222 |             1.74962 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000011)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000011)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:44 (running for 00:01:01.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     12 |          54.0497 | 48000 |          -303.098 |         -206.39 |            -20.8139 |        -92.6569 |              16.763 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=52000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-293.8945257697162 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000012)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000012)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:49 (running for 00:01:06.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     13 |            58.55 | 52000 |          -293.895 |        -207.853 |            -23.2176 |        -92.1578 |             29.3334 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000013)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000013)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:54 (running for 00:01:11.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     14 |          63.0685 | 56000 |          -285.326 |        -207.195 |            -22.2293 |        -92.4005 |             36.4988 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=60000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-269.71778473536483 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000014)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000014)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:40:59 (running for 00:01:17.01)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     15 |          67.6777 | 60000 |          -269.718 |         -208.13 |            -15.0012 |        -90.5001 |             43.9134 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000015)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000015)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:04 (running for 00:01:22.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     16 |          72.1699 | 64000 |          -277.037 |        -208.223 |            -13.9548 |        -91.4227 |             36.5638 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=68000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-285.83434722027806 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000016)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000016)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:09 (running for 00:01:27.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     17 |          76.6312 | 68000 |          -285.834 |        -208.385 |            -16.1385 |        -91.8573 |             30.5465 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000017)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000017)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:14 (running for 00:01:32.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     18 |          81.1263 | 72000 |          -268.767 |        -209.183 |            -8.36425 |        -92.0182 |             40.7984 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=76000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-269.4073552777923 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000018)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000018)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:19 (running for 00:01:37.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     19 |           85.688 | 76000 |          -269.407 |        -209.639 |            -7.98316 |        -91.3754 |             39.5899 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000019)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000019)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=84000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-240.25731392489226 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000020)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000020)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:24 (running for 00:01:42.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     21 |          94.6328 | 84000 |          -240.257 |        -210.667 |             4.72364 |        -90.7146 |             56.4007 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000021)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000021)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:29 (running for 00:01:47.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     22 |           99.122 | 88000 |          -238.067 |        -210.701 |             8.41884 |        -90.5618 |             54.7766 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=92000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-236.4724014578342 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000022)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000022)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:34 (running for 00:01:52.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     23 |          103.597 | 92000 |          -236.472 |         -210.81 |             11.5629 |        -90.9889 |             53.7639 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000023)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000023)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:39 (running for 00:01:57.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |    ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     24 |          108.043 | 96000 |           -223.89 |        -211.589 |             18.8904 |         -91.047 |             59.8557 |
+---------------------+----------+--------------------+--------+------------------+-------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=100000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-211.78334198959266 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000024)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000024)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:44 (running for 00:02:02.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     25 |          112.497 | 100000 |          -211.783 |        -211.513 |             23.9672 |        -91.3095 |             67.0718 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000025)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000025)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:49 (running for 00:02:07.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     26 |          116.954 | 104000 |           -191.86 |        -211.931 |             37.2824 |        -91.5257 |             74.3144 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=108000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-168.88478420089393 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000026)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000026)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:54 (running for 00:02:12.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     27 |          121.518 | 108000 |          -168.885 |        -212.647 |             50.6174 |        -91.1824 |             84.3275 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000027)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000027)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:41:59 (running for 00:02:17.71)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     28 |          126.039 | 112000 |          -143.481 |        -214.075 |             61.4195 |        -90.7468 |             99.9212 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=116000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-127.58143992221386 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000028)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000028)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:05 (running for 00:02:22.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     29 |          130.506 | 116000 |          -127.581 |        -215.392 |             68.5633 |        -90.7376 |             109.985 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000029)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000029)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=124000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-103.63582144754584 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000030)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000030)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:10 (running for 00:02:27.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     31 |          139.451 | 124000 |          -103.636 |        -217.403 |              77.038 |         -90.839 |             127.568 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000031)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000031)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:15 (running for 00:02:32.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     32 |            143.9 | 128000 |          -78.0604 |        -217.926 |             87.3086 |        -87.8971 |             140.454 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=132000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-68.48055798575832 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000032)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000032)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:20 (running for 00:02:37.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     33 |          148.415 | 132000 |          -68.4806 |        -219.027 |             93.6683 |        -88.4281 |             145.307 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000033)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000033)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:25 (running for 00:02:42.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     34 |          152.917 | 136000 |          -61.9021 |        -219.461 |             98.4433 |        -88.4333 |             147.549 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=140000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-55.491710446471025 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000034)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000034)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:30 (running for 00:02:47.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     35 |          157.407 | 140000 |          -55.4917 |         -220.45 |             97.6266 |        -86.6948 |             154.026 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000035)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000035)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:35 (running for 00:02:52.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     36 |          161.863 | 144000 |            -56.86 |        -220.115 |             98.7791 |        -87.1808 |             151.657 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=148000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-61.36219792877984 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len':
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000036)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000036)... Done. 0.0s

== Status ==
Current time: 2025-07-04 17:42:40 (running for 00:02:57.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     37 |          166.362 | 148000 |          -61.3622 |        -221.884 |             98.9883 |        -86.7839 |             148.317 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000037)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000037)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:45 (running for 00:03:03.04)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     38 |          170.861 | 152000 |          -54.5813 |         -221.59 |              104.55 |        -87.1673 |             149.626 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=156000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-55.73185974817056 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000038)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000038)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:50 (running for 00:03:08.04)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     39 |          175.447 | 156000 |          -55.7319 |        -223.117 |             106.883 |         -85.561 |             146.063 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000039)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000039)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=164000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-45.433441002451566 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000040)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000040)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:42:55 (running for 00:03:13.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     41 |          184.368 | 164000 |          -45.4334 |        -223.992 |             111.523 |        -84.9211 |             151.958 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000041)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000041)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:00 (running for 00:03:18.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     42 |           188.86 | 168000 |          -29.4023 |         -225.05 |             116.162 |        -84.9489 |             164.434 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=172000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-36.64142994415488 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000042)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000042)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:05 (running for 00:03:23.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     43 |          193.336 | 172000 |          -36.6414 |        -225.967 |             111.499 |        -84.5992 |             162.426 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000043)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000043)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:10 (running for 00:03:28.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     44 |          197.907 | 176000 |          -18.3552 |        -226.978 |             121.123 |        -84.0052 |             171.505 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=180000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-11.939620089646494 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000044)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000044)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:15 (running for 00:03:33.33)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     45 |          202.403 | 180000 |          -11.9396 |        -227.843 |             125.226 |        -83.8822 |              174.56 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000045)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000045)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:20 (running for 00:03:38.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     46 |          206.909 | 184000 |          -10.5289 |        -228.656 |             126.986 |        -83.4529 |             174.594 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=188000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-2.1799372006398894 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000046)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000046)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:25 (running for 00:03:43.41)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     47 |           211.37 | 188000 |          -2.17994 |        -229.612 |             128.631 |        -83.1752 |             181.977 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000047)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000047)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:30 (running for 00:03:48.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     48 |          215.824 | 192000 |             2.016 |        -230.202 |             126.178 |        -82.4838 |             188.524 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=196000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-2.9129817821919826 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000048)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000048)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:35 (running for 00:03:53.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     49 |          220.321 | 196000 |          -2.91298 |        -230.089 |             120.358 |        -81.9898 |             188.807 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000049)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000049)... Done. 0.0s
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=204000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-20.117990894660217 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000050)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000050)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:40 (running for 00:03:58.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     51 |          229.328 | 204000 |           -20.118 |        -230.696 |             106.897 |        -82.0966 |             185.777 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000051)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000051)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:45 (running for 00:04:03.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     52 |          233.788 | 208000 |          -21.1344 |         -231.05 |             105.256 |        -82.4394 |             187.099 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=212000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-30.680573843673493 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000052)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000052)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:51 (running for 00:04:08.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     53 |          238.264 | 212000 |          -30.6806 |        -231.626 |             99.0482 |        -81.3372 |             183.235 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000053)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000053)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:43:56 (running for 00:04:13.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     54 |          242.746 | 216000 |          -27.4866 |        -232.406 |              100.55 |        -81.4193 |             185.789 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=220000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-19.21682632849562 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000054)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000054)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:01 (running for 00:04:18.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     55 |          247.182 | 220000 |          -19.2168 |        -232.922 |             107.237 |        -80.6866 |             187.155 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000055)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000055)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:06 (running for 00:04:23.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     56 |          251.632 | 224000 |          -15.9124 |        -233.027 |             109.348 |        -80.6453 |             188.412 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=228000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-16.330868300038095 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000056)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000056)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:11 (running for 00:04:28.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     57 |          256.169 | 228000 |          -16.3309 |        -234.624 |             111.491 |        -81.6968 |             188.499 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000057)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000057)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:16 (running for 00:04:34.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     58 |          260.676 | 232000 |          -24.3093 |        -235.026 |             103.448 |        -81.6906 |             188.959 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=236000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=-15.60004923030317 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000058)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000058)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000059)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000059)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:21 (running for 00:04:39.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     60 |          269.642 | 240000 |          -18.2999 |        -236.512 |             109.691 |        -81.7382 |             190.259 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=244000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=0.20338605082672756 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000060)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000060)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:26 (running for 00:04:44.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     61 |          274.121 | 244000 |          0.203386 |        -237.924 |             120.098 |        -81.7292 |             199.759 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000061)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000061)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:31 (running for 00:04:49.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     62 |          278.623 | 248000 |           12.8607 |        -238.096 |             127.372 |        -81.5099 |             205.094 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=252000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=19.421081652074495 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000062)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000062)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:36 (running for 00:04:54.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     63 |          283.221 | 252000 |           19.4211 |        -238.655 |             133.848 |        -81.7779 |             206.006 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000063)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000063)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:41 (running for 00:04:59.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     64 |          287.713 | 256000 |           21.7673 |        -239.176 |             128.311 |         -83.722 |             216.354 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=260000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=23.324089309824235 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000064)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000064)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:46 (running for 00:05:04.37)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     65 |           292.22 | 260000 |           23.3241 |        -239.783 |             122.768 |        -84.0834 |             224.423 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000065)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000065)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:51 (running for 00:05:09.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     66 |          296.736 | 264000 |           17.7028 |        -240.666 |             117.367 |        -84.7815 |             225.783 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=268000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=24.32526352859682 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000066)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000066)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:44:56 (running for 00:05:14.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     67 |          301.219 | 268000 |           24.3253 |        -241.093 |              124.61 |        -84.7836 |             225.592 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000067)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000067)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:01 (running for 00:05:19.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     68 |          305.739 | 272000 |           28.1679 |        -240.878 |             126.403 |        -85.1221 |             227.765 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=276000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=25.935076082897666 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000068)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000068)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:06 (running for 00:05:24.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     69 |          310.295 | 276000 |           25.9351 |        -241.219 |              126.93 |        -86.4123 |             226.636 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000069)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000069)... Done. 0.0s
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=284000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=34.135147215676014 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000070)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000070)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:11 (running for 00:05:29.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     71 |          319.299 | 284000 |           34.1351 |        -241.109 |             131.861 |        -87.0406 |             230.423 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000071)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000071)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:16 (running for 00:05:34.61)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     72 |           323.75 | 288000 |           43.0254 |        -241.668 |             138.944 |        -87.4558 |             233.205 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=292000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=58.73071824293518 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000072)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000072)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:21 (running for 00:05:39.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     73 |          328.232 | 292000 |           58.7307 |        -242.567 |             150.038 |        -87.7272 |             238.987 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000073)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000073)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:26 (running for 00:05:44.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     74 |          332.714 | 296000 |           66.8029 |        -243.086 |             159.654 |        -88.4956 |             238.731 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=300000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=84.61652490672161 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000074)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000074)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:32 (running for 00:05:49.73)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     75 |          337.334 | 300000 |           84.6165 |        -243.625 |             170.762 |        -88.3028 |             245.782 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000075)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000075)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:37 (running for 00:05:54.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     76 |          341.842 | 304000 |            85.318 |        -244.949 |              173.41 |        -87.7607 |             244.618 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=308000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=81.02477053444733 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000076)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000076)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:42 (running for 00:05:59.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     77 |          346.329 | 308000 |           81.0248 |        -245.323 |             167.722 |        -87.1827 |             245.808 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000077)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000077)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:47 (running for 00:06:05.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     78 |          350.841 | 312000 |           83.8616 |        -245.013 |             174.578 |        -87.7181 |             242.015 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=316000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=95.18563020516653 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000078)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000078)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:52 (running for 00:06:10.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     79 |          355.377 | 316000 |           95.1856 |         -243.83 |             182.374 |        -87.1529 |             243.795 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000079)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000079)... Done. 0.0s
Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=324000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=95.60357876474507 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000080)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000080)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:45:57 (running for 00:06:15.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     81 |          364.377 | 324000 |           95.6036 |        -243.633 |             182.684 |        -89.7142 |             246.267 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000081)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000081)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:02 (running for 00:06:20.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     82 |          368.846 | 328000 |           85.4999 |        -243.618 |             176.354 |        -91.6178 |             244.382 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=332000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=112.61582400436836 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000082)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000082)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:07 (running for 00:06:25.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     83 |            373.3 | 332000 |           112.616 |        -243.973 |             195.008 |        -90.7881 |             252.369 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000083)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000083)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:12 (running for 00:06:30.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     84 |          377.791 | 336000 |           113.188 |        -243.618 |             196.964 |        -91.9254 |             251.767 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=340000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=124.29539200389888 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000084)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000084)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:17 (running for 00:06:35.37)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     85 |          382.258 | 340000 |           124.295 |        -243.471 |             205.857 |        -92.4247 |             254.334 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000085)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000085)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:22 (running for 00:06:40.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     86 |          386.746 | 344000 |           130.918 |        -242.646 |             210.409 |        -92.9217 |             256.078 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=348000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=118.84519142749352 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000086)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000086)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:27 (running for 00:06:45.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     87 |          391.298 | 348000 |           118.845 |        -242.638 |             204.156 |        -93.9083 |             251.236 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000087)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000087)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:32 (running for 00:06:50.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     88 |          395.752 | 352000 |           113.223 |        -242.934 |              197.21 |        -94.1277 |             253.074 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=356000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=130.75766966817272 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000088)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000088)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000089)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000089)...
[36m(_WandbLoggingActor pid=39612)[0m Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:37 (running for 00:06:55.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     90 |          404.636 | 360000 |           152.089 |         -242.98 |              230.19 |        -94.9293 |             259.808 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=364000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=168.64414022981208 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000090)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000090)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:43 (running for 00:07:00.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     91 |          409.069 | 364000 |           168.644 |        -243.393 |             240.268 |        -95.2235 |             266.993 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000091)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000091)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:48 (running for 00:07:05.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     92 |          413.556 | 368000 |           176.847 |        -243.523 |             244.798 |         -95.032 |             270.604 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=372000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=187.8648580897735 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000092)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000092)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:53 (running for 00:07:10.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     93 |          418.038 | 372000 |           187.865 |        -243.872 |             252.472 |        -95.2648 |              274.53 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000093)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000093)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:46:58 (running for 00:07:15.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     94 |          422.664 | 376000 |           186.245 |        -243.811 |             249.108 |        -94.6639 |             275.613 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=380000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=181.84405360910137 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000094)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000094)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:47:03 (running for 00:07:20.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     95 |          427.196 | 380000 |           181.844 |        -243.392 |             245.328 |        -94.9539 |             274.862 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000095)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000095)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:47:08 (running for 00:07:25.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     96 |          431.692 | 384000 |            188.41 |        -243.429 |             250.136 |        -95.3004 |             277.003 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=388000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=187.96244480279478 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000096)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000096)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:47:13 (running for 00:07:30.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     97 |          436.163 | 388000 |           187.962 |        -243.092 |             243.986 |        -95.3202 |             282.388 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000097)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000097)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:47:18 (running for 00:07:35.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |     98 |          440.608 | 392000 |            186.64 |        -242.705 |             243.104 |        -95.4687 |              281.71 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=396000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=195.1716319582663 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000098)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000098)... Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000099)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000099)... Done. 0.0s
== Status ==
Current time: 2025-07-04 17:47:23 (running for 00:07:41.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status   | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | RUNNING  | 192.168.0.25:39248 |    100 |          449.609 | 400000 |           181.478 |        -242.743 |             235.441 |        -95.4087 |             284.189 |
+---------------------+----------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+


Trial PPO_env_6e160_00000 reported num_env_steps_sampled_lifetime=404000.0,env_runners/episode_len_mean=2000.0,env_runners/episode_return_mean=200.826594779643 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m [DEBUG] on_train_result Ë¢´Ë∞ÉÁî®
2025-07-04 17:47:27,739	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-07-04_17-39-42' in 0.0526s.
== Status ==
Current time: 2025-07-04 17:47:27 (running for 00:07:45.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-04_17-39-41_246413_37479/artifacts/2025-07-04_17-39-42/PPO_2025-07-04_17-39-42/driver_artifacts
Number of trials: 1/1 (1 TERMINATED)
+---------------------+------------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
| Trial name          | status     | loc                |   iter |   total time (s) |     ts |   combined return |   return prey_1 |   return predator_0 |   return prey_0 |   return predator_1 |
|---------------------+------------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------|
| PPO_env_6e160_00000 | TERMINATED | 192.168.0.25:39248 |    101 |          454.051 | 404000 |           200.827 |        -242.748 |             244.119 |        -95.3544 |              294.81 |
+---------------------+------------+--------------------+--------+------------------+--------+-------------------+-----------------+---------------------+-----------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=39248)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000100)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-04_17-39-42/PPO_env_6e160_00000_0_2025-07-04_17-39-42/checkpoint_000100)... Done. 0.0s
[36m(_WandbLoggingActor pid=39612)[0m wandb: uploading artifact checkpoint_PPO_env_6e160_00000
2025-07-04 17:47:32,085	INFO tune.py:1041 -- Total run time: 469.80 seconds (465.39 seconds for the tuning loop).
[36m(_WandbLoggingActor pid=39612)[0m wandb: uploading history steps 98-100, summary, console lines 99-100
[36m(_WandbLoggingActor pid=39612)[0m wandb:
[36m(_WandbLoggingActor pid=39612)[0m wandb:
[36m(_WandbLoggingActor pid=39612)[0m wandb: Run history:
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    env_runners/agent_steps/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    env_runners/agent_steps/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/agent_steps/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/agent_steps/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  env_runners/connector_pipeline_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           env_runners/env_reset_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            env_runners/env_step_timer ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñá‚ñÑ‚ñÅ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÅ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñà‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÇ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 env_runners/episode_duration_sec_mean ‚ñà‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           env_runners/episode_len_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                          env_runners/episode_len_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           env_runners/episode_len_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/episode_return_max ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                       env_runners/episode_return_mean ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/episode_return_min ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ


ËÆ≠ÁªÉÂÆåÊàê
Ëé∑ÂèñÊúÄ‰Ω≥checkpoint...
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
Âä†ËΩΩÊâÄÊúâÊô∫ËÉΩ‰ΩìÁöÑRLModule...
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     env_runners/num_env_steps_sampled ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput ‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                              env_runners/num_episodes ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     env_runners/num_episodes_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  env_runners/rlmodule_inference_timer ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                    env_runners/sample ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     env_runners/time_between_sampling ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            env_runners/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                   fault_tolerance/num_healthy_workers ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                              iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñá‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_0/entropy ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/predator_0/mean_kl_loss ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                       learners/predator_0/policy_loss ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/predator_0/total_loss ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  learners/predator_0/vf_explained_var ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñá‚ñà‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_0/vf_loss ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñÇ‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñá‚ñÇ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÜ‚ñÖ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/predator_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_1/entropy ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/predator_1/mean_kl_loss ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                       learners/predator_1/policy_loss ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÅ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/predator_1/total_loss ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñá‚ñà‚ñá‚ñÅ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÅ‚ñÑ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  learners/predator_1/vf_explained_var ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_1/vf_loss ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÖ‚ñà‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÜ‚ñà‚ñà‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/predator_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_0/entropy ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                          learners/prey_0/mean_kl_loss ‚ñÇ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/prey_0/policy_loss ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            learners/prey_0/total_loss ‚ñÜ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/prey_0/vf_explained_var ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÅ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñà‚ñà‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_0/vf_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/prey_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_1/entropy ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÉ‚ñÇ‚ñÅ‚ñá‚ñá‚ñÉ‚ñÅ‚ñá‚ñá‚ñÜ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñá‚ñÖ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                          learners/prey_1/mean_kl_loss ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÜ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/prey_1/policy_loss ‚ñÅ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            learners/prey_1/total_loss ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÜ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/prey_1/vf_explained_var ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_1/vf_loss ‚ñà‚ñá‚ñÜ‚ñÅ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÖ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñá‚ñÑ‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÜ‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñà‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/prey_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 num_training_step_calls_per_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                 perf/cpu_util_percent ‚ñá‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñá‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                 perf/ram_util_percent ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                    time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                      time_this_iter_s ‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                          time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà2025-07-04 17:47:32,129	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!

[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      timers/env_runner_sampling_timer ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           timers/learner_update_timer ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            timers/restore_env_runners ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           timers/synch_env_connectors ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                  timers/synch_weights ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                             timers/training_iteration ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                  timers/training_step ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                             timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                    training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=39612)[0m wandb:
[36m(_WandbLoggingActor pid=39612)[0m wandb: Run summary:
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 244.11892
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 294.80972
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 -95.35438
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 -242.74766
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    env_runners/agent_steps/predator_0 500
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    env_runners/agent_steps/predator_1 500
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/agent_steps/prey_0 500
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/agent_steps/prey_1 500
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.00035
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           env_runners/env_reset_timer 0.00268
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            env_runners/env_step_timer 0.00042
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00011
[36m(_WandbLoggingActor pid=39612)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 2e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 1881.0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 1881.0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 env_runners/episode_duration_sec_mean 2.06428
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           env_runners/episode_len_max 2000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                          env_runners/episode_len_mean 2000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           env_runners/episode_len_min 2000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/episode_return_max 585.14818
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                       env_runners/episode_return_mean 200.82659
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        env_runners/episode_return_min -387.46164
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 244.11892
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 294.80972
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 -95.35438
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 -242.74766
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00023
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 8e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 3e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 101000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 101202
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 101202
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 101202
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 404000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 1192.36498
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                              env_runners/num_episodes 2
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     env_runners/num_episodes_lifetime 202
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 101000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 101202
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 101202
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 101202
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.0001
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                    env_runners/sample 2.08731
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     env_runners/time_between_sampling 3.11486
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 3e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 3e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 7e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            env_runners/weights_seq_no 100
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                              iterations_since_restore 101
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.08942
[36m(_WandbLoggingActor pid=39612)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03446
[36m(_WandbLoggingActor pid=39612)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 7e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.00259
[36m(_WandbLoggingActor pid=39612)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.00182
[36m(_WandbLoggingActor pid=39612)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.02713
[36m(_WandbLoggingActor pid=39612)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.02176
[36m(_WandbLoggingActor pid=39612)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.00133
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 940000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 94940000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 408585.48305
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 120320
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 12152320
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 2136199.64894
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 2107996.01584
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 578580
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 1.44163
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_0/entropy -0.29925
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 33.80311
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.01408
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 3038080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 13074.68653
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                       learners/predator_0/policy_loss -0.00081
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/predator_0/total_loss 0.06629
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  learners/predator_0/vf_explained_var 0.03454
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_0/vf_loss 9.36081
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 3284.18652
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/predator_0/weights_seq_no 101
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 1.70859
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05
ÊàêÂäüÂä†ËΩΩ predator_0 ÁöÑÊ®°Âûã
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_1/entropy 0.79406
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 22.69177
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.01284
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 3038080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 13074.72458
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/predator_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                       learners/predator_1/policy_loss -0.04557
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/predator_1/total_loss 0.02486
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                  learners/predator_1/vf_explained_var -0.00654
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/predator_1/vf_loss 9.69753
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 5276.66748
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/predator_1/weights_seq_no 101
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 1.28145
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_0/entropy 1.17432
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 11.56271
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.01439
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 3038080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 13074.68128
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/prey_0/policy_loss -0.11221
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            learners/prey_0/total_loss -0.05943
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/prey_0/vf_explained_var 0.04705
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_0/vf_loss 6.86952
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 55.6605
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/prey_0/weights_seq_no 101
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 0.64946
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1
ÊàêÂäüÂä†ËΩΩ predator_1 ÁöÑÊ®°Âûã
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_1/entropy 0.21428
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 16.7942
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.03495
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 3038080
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 13074.70373
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                              learners/prey_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           learners/prey_1/policy_loss 0.07167
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            learners/prey_1/total_loss 0.13668
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      learners/prey_1/vf_explained_var 0.05256
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                               learners/prey_1/vf_loss 9.97507
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 1445.14282
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        learners/prey_1/weights_seq_no 101
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                        num_env_steps_sampled_lifetime 404000
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                 num_training_step_calls_per_iteration 1
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                 perf/cpu_util_percent 7.93333
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                 perf/ram_util_percent 12.9
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                    time_since_restore 454.0513
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                      time_this_iter_s 4.4428
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                          time_total_s 454.0513
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                      timers/env_runner_sampling_timer 2.10627
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           timers/learner_update_timer 2.47778
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                            timers/restore_env_runners 1e-05
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                           timers/synch_env_connectors 0.00139
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                  timers/synch_weights 0.0036
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                             timers/training_iteration 4.58837
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                  timers/training_step 4.5881
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                             timestamp 1751618847
[36m(_WandbLoggingActor pid=39612)[0m wandb:                                                                                    training_iteration 101
[36m(_WandbLoggingActor pid=39612)[0m wandb:
[36m(_WandbLoggingActor pid=39612)[0m wandb: üöÄ View run PPO_env_6e160_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/6e160_00000
[36m(_WandbLoggingActor pid=39612)[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=39612)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 734 artifact file(s) and 0 other file(s)
[36m(_WandbLoggingActor pid=39612)[0m wandb: Find logs at: ./wandb/run-20250704_173949-6e160_00000/logs
ÊàêÂäüÂä†ËΩΩ prey_0 ÁöÑÊ®°Âûã
ÊàêÂäüÂä†ËΩΩ prey_1 ÁöÑÊ®°Âûã
ÊÄªÂÖ±Âä†ËΩΩ‰∫Ü 4 ‰∏™Êô∫ËÉΩ‰ΩìÊ®°Âûã
ÂºÄÂßãÊé®ÁêÜ...

=== Episode 1 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-2.7953753  2.8900814]
[WARNING]: Received an action [-2.7953753  2.8900814] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [18.808353   3.4600847]
[WARNING]: Received an action [18.808353   3.4600847] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.880557 -9.148382]
[WARNING]: Received an action [ 2.880557 -9.148382] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 19.547619 -21.559172]
[WARNING]: Received an action [ 19.547619 -21.559172] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.8634723 -0.7021496]
[WARNING]: Received an action [-1.8634723 -0.7021496] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 7.29448   -2.8116097]
[WARNING]: Received an action [ 7.29448   -2.8116097] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [7.914892  4.5556965]
[WARNING]: Received an action [7.914892  4.5556965] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 51.71844  -17.514633]
[WARNING]: Received an action [ 51.71844  -17.514633] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2012371 -3.7844925]
[WARNING]: Received an action [-1.2012371 -3.7844925] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.2211411  -0.19054717]
[WARNING]: Received an action [-1.2211411  -0.19054717] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.8873533 -5.834288 ]
[WARNING]: Received an action [-0.8873533 -5.834288 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [43.62989 24.42838]
[WARNING]: Received an action [43.62989 24.42838] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.23176801  0.90681696]
predator_1 ÊâßË°åÂä®‰Ωú: [11.175081   1.3455013]
[WARNING]: Received an action [11.175081   1.3455013] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.1259104 -4.844945 ]
[WARNING]: Received an action [ 0.1259104 -4.844945 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-10.635976  21.49305 ]
[WARNING]: Received an action [-10.635976  21.49305 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 4.125396  -1.0835018]
[WARNING]: Received an action [ 4.125396  -1.0835018] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-4.5994573 -1.0991439]
[WARNING]: Received an action [-4.5994573 -1.0991439] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-4.816118  -3.0645707]
[WARNING]: Received an action [-4.816118  -3.0645707] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [26.232147 23.069983]
[WARNING]: Received an action [26.232147 23.069983] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 2.573034 -8.609249]
[WARNING]: Received an action [ 2.573034 -8.609249] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 0.16141152 -1.3353909 ]
[WARNING]: Received an action [ 0.16141152 -1.3353909 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [2.2860272 0.7182735]
[WARNING]: Received an action [2.2860272 0.7182735] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-20.742426   6.586234]
[WARNING]: Received an action [-20.742426   6.586234] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.0945351 -1.89849  ]
[WARNING]: Received an action [ 1.0945351 -1.89849  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 4.6182637 -2.0677114]
[WARNING]: Received an action [ 4.6182637 -2.0677114] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.89606476 -0.27965212]
prey_1 ÊâßË°åÂä®‰Ωú: [-23.362476    6.8888273]
[WARNING]: Received an action [-23.362476    6.8888273] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.107917   2.5277195]
[WARNING]: Received an action [-2.107917   2.5277195] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 2.3931618 -1.3961974]
[WARNING]: Received an action [ 2.3931618 -1.3961974] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.1632056  -0.25705612]
[WARNING]: Received an action [ 2.1632056  -0.25705612] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [22.489847   8.1171875]
[WARNING]: Received an action [22.489847   8.1171875] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.7948616 -1.2721815]
[WARNING]: Received an action [ 1.7948616 -1.2721815] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 6.9801106 -2.1714108]
[WARNING]: Received an action [ 6.9801106 -2.1714108] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 9.039257  -1.5831344]
[WARNING]: Received an action [ 9.039257  -1.5831344] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-16.395416  -6.897795]
[WARNING]: Received an action [-16.395416  -6.897795] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.7842013 -3.3187203]
[WARNING]: Received an action [ 1.7842013 -3.3187203] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.258102  -1.3620263]
[WARNING]: Received an action [-2.258102  -1.3620263] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-2.2040071 -2.209622 ]
[WARNING]: Received an action [-2.2040071 -2.209622 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 7.6556425 -7.6547155]
[WARNING]: Received an action [ 7.6556425 -7.6547155] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7709402  3.2012308]
[WARNING]: Received an action [-1.7709402  3.2012308] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-4.3098764  -0.20015085]
[WARNING]: Received an action [-4.3098764  -0.20015085] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.8472824 -0.7081027]
[WARNING]: Received an action [ 3.8472824 -0.7081027] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [94.48483   8.859736]
[WARNING]: Received an action [94.48483   8.859736] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.8480636 -3.1917384]
[WARNING]: Received an action [ 1.8480636 -3.1917384] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-4.676441  -1.4940758]
[WARNING]: Received an action [-4.676441  -1.4940758] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [2.4382966 3.0358033]
[WARNING]: Received an action [2.4382966 3.0358033] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-19.47367   29.018377]
[WARNING]: Received an action [-19.47367   29.018377] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 2.6918366  -0.33839002]
[WARNING]: Received an action [ 2.6918366  -0.33839002] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.236519    0.51774645]
[WARNING]: Received an action [-2.236519    0.51774645] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 1 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 1 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -2.98
  predator_1: -3.00
  prey_0: -2.73
  prey_1: -6.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 2 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-0.7725172 -1.060844 ]
[WARNING]: Received an action [-0.7725172 -1.060844 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [3.2028594 6.9395523]
[WARNING]: Received an action [3.2028594 6.9395523] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [4.595491  2.0306654]
[WARNING]: Received an action [4.595491  2.0306654] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [15.847627 -4.989603]
[WARNING]: Received an action [15.847627 -4.989603] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.44587308 -0.53077006]
predator_1 ÊâßË°åÂä®‰Ωú: [ 0.09320635 -2.060163  ]
[WARNING]: Received an action [ 0.09320635 -2.060163  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.8064965 -1.3645877]
[WARNING]: Received an action [ 0.8064965 -1.3645877] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-29.152548  22.486723]
[WARNING]: Received an action [-29.152548  22.486723] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.01681806  0.09282975]
predator_1 ÊâßË°åÂä®‰Ωú: [-15.807612    -0.98453736]
[WARNING]: Received an action [-15.807612    -0.98453736] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-4.910412   -0.31003606]
[WARNING]: Received an action [-4.910412   -0.31003606] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [36.462692   2.9133584]
[WARNING]: Received an action [36.462692   2.9133584] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.13421726 -0.3904216 ]
predator_1 ÊâßË°åÂä®‰Ωú: [4.1582417 1.6177046]
[WARNING]: Received an action [4.1582417 1.6177046] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [2.521495  1.2916216]
[WARNING]: Received an action [2.521495  1.2916216] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-40.343117  11.274536]
[WARNING]: Received an action [-40.343117  11.274536] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.14222047 -0.0950202 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-1.2236717 -5.6581597]
[WARNING]: Received an action [-1.2236717 -5.6581597] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.11996771 -1.6892443 ]
[WARNING]: Received an action [ 0.11996771 -1.6892443 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [14.43544   -3.0240812]
[WARNING]: Received an action [14.43544   -3.0240812] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.506635   0.14651945]
predator_1 ÊâßË°åÂä®‰Ωú: [4.6890016 4.8784103]
[WARNING]: Received an action [4.6890016 4.8784103] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.51888037 -0.9351266 ]
prey_1 ÊâßË°åÂä®‰Ωú: [30.267385 18.532852]
[WARNING]: Received an action [30.267385 18.532852] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.29402238  0.16251275]
predator_1 ÊâßË°åÂä®‰Ωú: [-2.5635612  4.467872 ]
[WARNING]: Received an action [-2.5635612  4.467872 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.9172008 -3.027616 ]
[WARNING]: Received an action [ 1.9172008 -3.027616 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [5.4227915  0.36869174]
[WARNING]: Received an action [5.4227915  0.36869174] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.16352728 -0.22734174]
predator_1 ÊâßË°åÂä®‰Ωú: [0.9013368 4.437978 ]
[WARNING]: Received an action [0.9013368 4.437978 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [11.833325  -0.6755152]
[WARNING]: Received an action [11.833325  -0.6755152] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-3.1869605 -9.41565  ]
[WARNING]: Received an action [-3.1869605 -9.41565  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.07285626 -0.3481965 ]
predator_1 ÊâßË°åÂä®‰Ωú: [11.902681  -6.5069637]
[WARNING]: Received an action [11.902681  -6.5069637] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.4239572 -1.2204461]
[WARNING]: Received an action [ 1.4239572 -1.2204461] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [8.025064  3.9262066]
[WARNING]: Received an action [8.025064  3.9262066] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.3005156  -0.05746216]
predator_1 ÊâßË°åÂä®‰Ωú: [-15.507375    3.8634279]
[WARNING]: Received an action [-15.507375    3.8634279] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.1502979 -1.333519 ]
[WARNING]: Received an action [ 3.1502979 -1.333519 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-46.814423   -2.2581506]
[WARNING]: Received an action [-46.814423   -2.2581506] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.02413535  0.16511478]
predator_1 ÊâßË°åÂä®‰Ωú: [-4.11186   -2.7954974]
[WARNING]: Received an action [-4.11186   -2.7954974] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.4092011 -1.5454067]
[WARNING]: Received an action [ 3.4092011 -1.5454067] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-34.116898   -3.7236795]
[WARNING]: Received an action [-34.116898   -3.7236795] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.5775881  -0.39476967]
predator_1 ÊâßË°åÂä®‰Ωú: [-9.240598   0.5561793]
[WARNING]: Received an action [-9.240598   0.5561793] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.8246349 -2.7924178]
[WARNING]: Received an action [-0.8246349 -2.7924178] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-15.319849    3.2528136]
[WARNING]: Received an action [-15.319849    3.2528136] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.2047276   0.01420811]
predator_1 ÊâßË°åÂä®‰Ωú: [-6.9045     6.2058983]
[WARNING]: Received an action [-6.9045     6.2058983] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 2 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 2 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -1.26
  predator_1: -3.00
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 3 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-1.5277712 -0.2882687]
[WARNING]: Received an action [-1.5277712 -0.2882687] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 8.446882  -0.4531148]
[WARNING]: Received an action [ 8.446882  -0.4531148] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 5.6570177 -2.8816564]
[WARNING]: Received an action [ 5.6570177 -2.8816564] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ -3.882485 -14.10838 ]
[WARNING]: Received an action [ -3.882485 -14.10838 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [2.7244864 1.1636664]
[WARNING]: Received an action [2.7244864 1.1636664] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.9349642 -2.217473 ]
[WARNING]: Received an action [-2.9349642 -2.217473 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [7.733498  3.6195326]
[WARNING]: Received an action [7.733498  3.6195326] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [73.02492  13.060782]
[WARNING]: Received an action [73.02492  13.060782] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.606578 -2.859603]
[WARNING]: Received an action [-0.606578 -2.859603] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-5.1348057 -4.3309126]
[WARNING]: Received an action [-5.1348057 -4.3309126] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-1.4881338 -1.77373  ]
[WARNING]: Received an action [-1.4881338 -1.77373  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ -6.2883315 -25.956848 ]
[WARNING]: Received an action [ -6.2883315 -25.956848 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2339034 -1.6197933]
[WARNING]: Received an action [-1.2339034 -1.6197933] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [10.04883    1.4682217]
[WARNING]: Received an action [10.04883    1.4682217] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [3.8891392  0.04199028]
[WARNING]: Received an action [3.8891392  0.04199028] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [74.52993   5.730227]
[WARNING]: Received an action [74.52993   5.730227] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [2.139024  6.0940566]
[WARNING]: Received an action [2.139024  6.0940566] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-5.364669   -0.07202154]
[WARNING]: Received an action [-5.364669   -0.07202154] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.7574259 -1.2889183]
[WARNING]: Received an action [ 1.7574259 -1.2889183] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-13.177595  16.59092 ]
[WARNING]: Received an action [-13.177595  16.59092 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [2.141649 2.849101]
[WARNING]: Received an action [2.141649 2.849101] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.0100922  -0.04040873]
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.88864285 -8.188749  ]
[WARNING]: Received an action [ 0.88864285 -8.188749  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 6.5474067 -0.6323764]
[WARNING]: Received an action [ 6.5474067 -0.6323764] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.5763972 -1.4824624]
[WARNING]: Received an action [-0.5763972 -1.4824624] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 3.1489673 -3.7172465]
[WARNING]: Received an action [ 3.1489673 -3.7172465] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [7.6583257 7.166025 ]
[WARNING]: Received an action [7.6583257 7.166025 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-27.838089   8.213876]
[WARNING]: Received an action [-27.838089   8.213876] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.04586643 -3.2757652 ]
[WARNING]: Received an action [-0.04586643 -3.2757652 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-4.6979017  4.2827306]
[WARNING]: Received an action [-4.6979017  4.2827306] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-1.8330873  -0.57230175]
[WARNING]: Received an action [-1.8330873  -0.57230175] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-24.231882    2.0984373]
[WARNING]: Received an action [-24.231882    2.0984373] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.2900832  -0.35720444]
[WARNING]: Received an action [ 1.2900832  -0.35720444] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 3.2664907 -1.5848868]
[WARNING]: Received an action [ 3.2664907 -1.5848868] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 5.310623 -1.592006]
[WARNING]: Received an action [ 5.310623 -1.592006] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [27.679234  -6.6218157]
[WARNING]: Received an action [27.679234  -6.6218157] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.0695505 -2.2537017]
[WARNING]: Received an action [-1.0695505 -2.2537017] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-9.910403 -0.549443]
[WARNING]: Received an action [-9.910403 -0.549443] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-11.154981  12.321986]
[WARNING]: Received an action [-11.154981  12.321986] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [51.558468 29.264235]
[WARNING]: Received an action [51.558468 29.264235] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [1.3636744 3.5299008]
[WARNING]: Received an action [1.3636744 3.5299008] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.2164671  -0.36051157]
[WARNING]: Received an action [-2.2164671  -0.36051157] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.62346536  0.7689549 ]
prey_1 ÊâßË°åÂä®‰Ωú: [-35.173077     0.45148063]
[WARNING]: Received an action [-35.173077     0.45148063] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [2.401904  0.8146125]
[WARNING]: Received an action [2.401904  0.8146125] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-5.6815333 -0.6134956]
[WARNING]: Received an action [-5.6815333 -0.6134956] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.022157  -0.9337244]
[WARNING]: Received an action [ 2.022157  -0.9337244] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-51.78855    8.099349]
[WARNING]: Received an action [-51.78855    8.099349] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 4.55549   -1.0514519]
[WARNING]: Received an action [ 4.55549   -1.0514519] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-5.566991  -1.7778511]
[WARNING]: Received an action [-5.566991  -1.7778511] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 3 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 3 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.00
  predator_1: -2.76
  prey_0: 17.28
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 4 ===
predator_0 ÊâßË°åÂä®‰Ωú: [ 3.0002656 -4.276881 ]
[WARNING]: Received an action [ 3.0002656 -4.276881 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.7499651 -1.0058249]
[WARNING]: Received an action [ 1.7499651 -1.0058249] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-4.538271   0.5091872]
[WARNING]: Received an action [-4.538271   0.5091872] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [45.292755 -8.481588]
[WARNING]: Received an action [45.292755 -8.481588] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6579552 -4.360172 ]
[WARNING]: Received an action [-1.6579552 -4.360172 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [12.544632  -2.6904547]
[WARNING]: Received an action [12.544632  -2.6904547] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.3616097 -2.2481062]
[WARNING]: Received an action [ 1.3616097 -2.2481062] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-20.565372   9.389522]
[WARNING]: Received an action [-20.565372   9.389522] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.1174556 -2.7572086]
[WARNING]: Received an action [-1.1174556 -2.7572086] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.9995152   0.18418503]
[WARNING]: Received an action [-1.9995152   0.18418503] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.3598866 -1.8535218]
[WARNING]: Received an action [ 1.3598866 -1.8535218] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 7.1904826 25.32043  ]
[WARNING]: Received an action [ 7.1904826 25.32043  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [2.1977499 1.3513324]
[WARNING]: Received an action [2.1977499 1.3513324] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-6.969632   -0.35489762]
[WARNING]: Received an action [-6.969632   -0.35489762] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.5977619 -2.175205 ]
[WARNING]: Received an action [ 0.5977619 -2.175205 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [54.128277 10.272914]
[WARNING]: Received an action [54.128277 10.272914] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-3.7216234 -1.1448255]
[WARNING]: Received an action [-3.7216234 -1.1448255] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.17359054 -2.1205616 ]
[WARNING]: Received an action [-0.17359054 -2.1205616 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.2830486 -5.3426733]
[WARNING]: Received an action [ 2.2830486 -5.3426733] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-10.248025   5.274493]
[WARNING]: Received an action [-10.248025   5.274493] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 2.3879616 -3.1915593]
[WARNING]: Received an action [ 2.3879616 -3.1915593] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [27.392939   2.1365128]
[WARNING]: Received an action [27.392939   2.1365128] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 4.7660527 -2.134647 ]
[WARNING]: Received an action [ 4.7660527 -2.134647 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [55.90879  24.457525]
[WARNING]: Received an action [55.90879  24.457525] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.10186473  1.0574008 ]
[WARNING]: Received an action [-0.10186473  1.0574008 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.4635118   0.30678684]
[WARNING]: Received an action [-1.4635118   0.30678684] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.9753766  -0.71307516]
prey_1 ÊâßË°åÂä®‰Ωú: [-25.143513  -7.162892]
[WARNING]: Received an action [-25.143513  -7.162892] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.24587233 -2.8399398 ]
[WARNING]: Received an action [-0.24587233 -2.8399398 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.012698   -0.16693953]
[WARNING]: Received an action [-2.012698   -0.16693953] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 4.7866955 -1.6928641]
[WARNING]: Received an action [ 4.7866955 -1.6928641] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [15.391373 -4.321435]
[WARNING]: Received an action [15.391373 -4.321435] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [1.2152976 2.595609 ]
[WARNING]: Received an action [1.2152976 2.595609 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 0.7777684 -2.4826567]
[WARNING]: Received an action [ 0.7777684 -2.4826567] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.3606884  0.31091404]
[WARNING]: Received an action [1.3606884  0.31091404] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-0.29921907  7.7846284 ]
[WARNING]: Received an action [-0.29921907  7.7846284 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [1.6580259 6.8007298]
[WARNING]: Received an action [1.6580259 6.8007298] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-6.9980397  4.8742576]
[WARNING]: Received an action [-6.9980397  4.8742576] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.62793475 -2.7929454 ]
[WARNING]: Received an action [ 0.62793475 -2.7929454 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-39.090084   -3.7033696]
[WARNING]: Received an action [-39.090084   -3.7033696] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.2328393  1.4822016]
[WARNING]: Received an action [-0.2328393  1.4822016] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-4.136065   -0.04198518]
[WARNING]: Received an action [-4.136065   -0.04198518] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-1.084231 -2.928003]
[WARNING]: Received an action [-1.084231 -2.928003] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-5.6513     3.5336084]
[WARNING]: Received an action [-5.6513     3.5336084] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.16178036  1.4627445 ]
[WARNING]: Received an action [-0.16178036  1.4627445 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.695825    0.51933515]
[WARNING]: Received an action [-2.695825    0.51933515] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.8206416 -2.336013 ]
[WARNING]: Received an action [-0.8206416 -2.336013 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 7.151331 -7.896337]
[WARNING]: Received an action [ 7.151331 -7.896337] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.693109  -0.9295459]
predator_1 ÊâßË°åÂä®‰Ωú: [13.120114 -3.845899]
[WARNING]: Received an action [13.120114 -3.845899] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 4 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 4 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.00
  predator_1: -5.00
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 5 ===
predator_0 ÊâßË°åÂä®‰Ωú: [0.59278435 0.00359952]
predator_1 ÊâßË°åÂä®‰Ωú: [-4.474308  -1.6314545]
[WARNING]: Received an action [-4.474308  -1.6314545] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.44627878 -2.911776  ]
[WARNING]: Received an action [ 0.44627878 -2.911776  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-3.2460382 -9.1043415]
[WARNING]: Received an action [-3.2460382 -9.1043415] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.5699899  0.10475856]
predator_1 ÊâßË°åÂä®‰Ωú: [-4.5053005  1.247663 ]
[WARNING]: Received an action [-4.5053005  1.247663 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.6338941  0.10945278]
prey_1 ÊâßË°åÂä®‰Ωú: [20.057718  1.439459]
[WARNING]: Received an action [20.057718  1.439459] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.2559263 -0.3611088]
predator_1 ÊâßË°åÂä®‰Ωú: [3.7102368 2.6869707]
[WARNING]: Received an action [3.7102368 2.6869707] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.5562009  -0.13921398]
[WARNING]: Received an action [ 1.5562009  -0.13921398] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 15.417143 -11.32485 ]
[WARNING]: Received an action [ 15.417143 -11.32485 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.19642654 -0.46629378]
predator_1 ÊâßË°åÂä®‰Ωú: [ 3.6937122 -2.2197094]
[WARNING]: Received an action [ 3.6937122 -2.2197094] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.37888297  0.5779922 ]
prey_1 ÊâßË°åÂä®‰Ωú: [53.809406  2.264558]
[WARNING]: Received an action [53.809406  2.264558] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [1.1155736  0.07956672]
[WARNING]: Received an action [1.1155736  0.07956672] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.8568702  1.137861 ]
[WARNING]: Received an action [-2.8568702  1.137861 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.7706395  0.66439515]
prey_1 ÊâßË°åÂä®‰Ωú: [49.099747 11.569339]
[WARNING]: Received an action [49.099747 11.569339] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.35054505 -0.19462833]
predator_1 ÊâßË°åÂä®‰Ωú: [ 3.4795785 -1.2434138]
[WARNING]: Received an action [ 3.4795785 -1.2434138] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.6886282 -0.688461 ]
[WARNING]: Received an action [ 1.6886282 -0.688461 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-45.83911    3.234575]
[WARNING]: Received an action [-45.83911    3.234575] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.28999716 -0.5260668 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-4.138654  -1.6092005]
[WARNING]: Received an action [-4.138654  -1.6092005] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.3374673  -0.46050516]
[WARNING]: Received an action [ 1.3374673  -0.46050516] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-2.1738677  8.948132 ]
[WARNING]: Received an action [-2.1738677  8.948132 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.3134497   0.17292532]
predator_1 ÊâßË°åÂä®‰Ωú: [ 5.1448703 -2.736547 ]
[WARNING]: Received an action [ 5.1448703 -2.736547 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.0537243  0.25596774]
[WARNING]: Received an action [1.0537243  0.25596774] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [11.359767 16.449049]
[WARNING]: Received an action [11.359767 16.449049] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.03901038 -0.32320708]
predator_1 ÊâßË°åÂä®‰Ωú: [-3.156056  -3.1754918]
[WARNING]: Received an action [-3.156056  -3.1754918] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.5760609  0.17163837]
prey_1 ÊâßË°åÂä®‰Ωú: [1.5517287 5.239686 ]
[WARNING]: Received an action [1.5517287 5.239686 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.00125719 -0.19005659]
predator_1 ÊâßË°åÂä®‰Ωú: [-4.0867395  -0.21538693]
[WARNING]: Received an action [-4.0867395  -0.21538693] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.1925487  -0.10668087]
prey_1 ÊâßË°åÂä®‰Ωú: [-35.819298 -17.515562]
[WARNING]: Received an action [-35.819298 -17.515562] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.15333441 -0.0531231 ]
predator_1 ÊâßË°åÂä®‰Ωú: [ 2.0145044 -0.8875716]
[WARNING]: Received an action [ 2.0145044 -0.8875716] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.8897762 -0.8306823]
prey_1 ÊâßË°åÂä®‰Ωú: [-13.234434    6.5741363]
[WARNING]: Received an action [-13.234434    6.5741363] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.50711685 0.22450529]
predator_1 ÊâßË°åÂä®‰Ωú: [ 6.307121  -4.2258162]
[WARNING]: Received an action [ 6.307121  -4.2258162] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.5887252 0.9303214]
prey_1 ÊâßË°åÂä®‰Ωú: [28.788143 22.51672 ]
[WARNING]: Received an action [28.788143 22.51672 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.47078907 0.12075565]
predator_1 ÊâßË°åÂä®‰Ωú: [-1.9723457   0.27399045]
[WARNING]: Received an action [-1.9723457   0.27399045] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 5 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 5 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: 8.57
  predator_1: -3.00
  prey_0: -2.29
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 6 ===
predator_0 ÊâßË°åÂä®‰Ωú: [ 3.1178691  -0.37738892]
[WARNING]: Received an action [ 3.1178691  -0.37738892] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-2.7048073 -1.4639213]
[WARNING]: Received an action [-2.7048073 -1.4639213] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [2.5302622  0.12144005]
[WARNING]: Received an action [2.5302622  0.12144005] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-19.529177    1.8570352]
[WARNING]: Received an action [-19.529177    1.8570352] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-4.2885537  -0.00666124]
[WARNING]: Received an action [-4.2885537  -0.00666124] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 2.5605998  -0.09467977]
[WARNING]: Received an action [ 2.5605998  -0.09467977] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [4.278043   0.10240483]
[WARNING]: Received an action [4.278043   0.10240483] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-0.33833206 -6.566883  ]
[WARNING]: Received an action [-0.33833206 -6.566883  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-3.7202575  7.130266 ]
[WARNING]: Received an action [-3.7202575  7.130266 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.0061786  0.35989517]
[WARNING]: Received an action [1.0061786  0.35989517] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-1.6778055  -0.21936011]
[WARNING]: Received an action [-1.6778055  -0.21936011] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 5.6957726 -8.819899 ]
[WARNING]: Received an action [ 5.6957726 -8.819899 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 2.0768235 -0.6153174]
[WARNING]: Received an action [ 2.0768235 -0.6153174] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.80543673 0.7740976 ]
prey_0 ÊâßË°åÂä®‰Ωú: [0.23523447 1.4134567 ]
[WARNING]: Received an action [0.23523447 1.4134567 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-69.64945 -26.55004]
[WARNING]: Received an action [-69.64945 -26.55004] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 2.9621515 -1.1938239]
[WARNING]: Received an action [ 2.9621515 -1.1938239] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.7938752 -0.7155107]
[WARNING]: Received an action [ 1.7938752 -0.7155107] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 4.1554565 -3.050355 ]
[WARNING]: Received an action [ 4.1554565 -3.050355 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-22.517378  23.116997]
[WARNING]: Received an action [-22.517378  23.116997] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.296387  2.813793]
[WARNING]: Received an action [-2.296387  2.813793] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.369951  -2.2870162]
[WARNING]: Received an action [ 1.369951  -2.2870162] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.77691656 -3.154037  ]
[WARNING]: Received an action [ 0.77691656 -3.154037  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-9.346254   2.1634517]
[WARNING]: Received an action [-9.346254   2.1634517] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.1695027 -0.7877805]
[WARNING]: Received an action [-2.1695027 -0.7877805] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.6184592 -1.4185196]
[WARNING]: Received an action [ 1.6184592 -1.4185196] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-1.1249604  2.508565 ]
[WARNING]: Received an action [-1.1249604  2.508565 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-26.995892    1.3653951]
[WARNING]: Received an action [-26.995892    1.3653951] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-3.1783040e+00  1.5613437e-03]
[WARNING]: Received an action [-3.1783040e+00  1.5613437e-03] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [2.8912308  0.58766323]
[WARNING]: Received an action [2.8912308  0.58766323] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.8488097 -1.8461936]
[WARNING]: Received an action [-0.8488097 -1.8461936] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-6.1529856 -3.7250724]
[WARNING]: Received an action [-6.1529856 -3.7250724] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 5.561693   -0.72960943]
[WARNING]: Received an action [ 5.561693   -0.72960943] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.539706   0.32674372]
prey_0 ÊâßË°åÂä®‰Ωú: [ 4.0445127 -1.3925177]
[WARNING]: Received an action [ 4.0445127 -1.3925177] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [24.906199  5.716321]
[WARNING]: Received an action [24.906199  5.716321] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.7831473  0.52882856]
predator_1 ÊâßË°åÂä®‰Ωú: [ 0.685016 -1.921995]
[WARNING]: Received an action [ 0.685016 -1.921995] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.5002766 -2.203982 ]
[WARNING]: Received an action [ 1.5002766 -2.203982 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-13.091248   -2.6570926]
[WARNING]: Received an action [-13.091248   -2.6570926] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.7294774 -6.839578 ]
[WARNING]: Received an action [ 1.7294774 -6.839578 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.9857733 0.204804 ]
prey_0 ÊâßË°åÂä®‰Ωú: [1.6740706  0.08157563]
[WARNING]: Received an action [1.6740706  0.08157563] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [33.750053  -1.2316087]
[WARNING]: Received an action [33.750053  -1.2316087] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.7187381 -3.2516289]
[WARNING]: Received an action [ 1.7187381 -3.2516289] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.37492135 0.47555023]
prey_0 ÊâßË°åÂä®‰Ωú: [-1.6773779 -1.4499213]
[WARNING]: Received an action [-1.6773779 -1.4499213] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-21.215189    6.0872774]
[WARNING]: Received an action [-21.215189    6.0872774] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 4.637555   -0.36311483]
[WARNING]: Received an action [ 4.637555   -0.36311483] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [2.1482096 0.5712766]
[WARNING]: Received an action [2.1482096 0.5712766] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 6 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 6 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -3.99
  predator_1: -3.81
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 7 ===
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.28843534 -2.046302  ]
[WARNING]: Received an action [ 0.28843534 -2.046302  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 8.79844   -2.8913522]
[WARNING]: Received an action [ 8.79844   -2.8913522] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.9266763 -6.3585477]
[WARNING]: Received an action [ 3.9266763 -6.3585477] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 80.591896 -10.599468]
[WARNING]: Received an action [ 80.591896 -10.599468] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.8790543 -1.0297127]
[WARNING]: Received an action [-1.8790543 -1.0297127] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.7578208 -0.7615368]
[WARNING]: Received an action [ 1.7578208 -0.7615368] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.4235699 -5.04541  ]
[WARNING]: Received an action [ 0.4235699 -5.04541  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [35.111366  3.823435]
[WARNING]: Received an action [35.111366  3.823435] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.0992587 -4.31751  ]
[WARNING]: Received an action [ 1.0992587 -4.31751  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [5.631452  0.3450699]
[WARNING]: Received an action [5.631452  0.3450699] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.77754253 -0.10387087]
prey_1 ÊâßË°åÂä®‰Ωú: [67.20538  -7.893773]
[WARNING]: Received an action [67.20538  -7.893773] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.7299736 -2.1555054]
[WARNING]: Received an action [-1.7299736 -2.1555054] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-3.2448986   0.08089161]
[WARNING]: Received an action [-3.2448986   0.08089161] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.9206967 -5.0718374]
[WARNING]: Received an action [ 0.9206967 -5.0718374] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [13.704808 11.778924]
[WARNING]: Received an action [13.704808 11.778924] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.9634413 3.5718238]
[WARNING]: Received an action [0.9634413 3.5718238] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-6.395071 -4.06724 ]
[WARNING]: Received an action [-6.395071 -4.06724 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 7.7665944 -1.4337887]
[WARNING]: Received an action [ 7.7665944 -1.4337887] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-25.211344  -8.12656 ]
[WARNING]: Received an action [-25.211344  -8.12656 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.25999653 -1.6844265 ]
[WARNING]: Received an action [-0.25999653 -1.6844265 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [17.569838  -1.9755929]
[WARNING]: Received an action [17.569838  -1.9755929] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.4097261 -1.0629604]
[WARNING]: Received an action [ 1.4097261 -1.0629604] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [56.905075  3.420609]
[WARNING]: Received an action [56.905075  3.420609] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.9353695 -1.8211946]
[WARNING]: Received an action [-1.9353695 -1.8211946] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.0996163 0.5518176]
[WARNING]: Received an action [1.0996163 0.5518176] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.03080928 -2.4679456 ]
[WARNING]: Received an action [ 0.03080928 -2.4679456 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [13.876676  -3.2593997]
[WARNING]: Received an action [13.876676  -3.2593997] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.5050313 -0.8481915]
predator_1 ÊâßË°åÂä®‰Ωú: [-1.8328481 -1.7888606]
[WARNING]: Received an action [-1.8328481 -1.7888606] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [2.6079865 0.6692363]
[WARNING]: Received an action [2.6079865 0.6692363] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [17.168858 -0.308147]
[WARNING]: Received an action [17.168858 -0.308147] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.1439661 0.7384495]
predator_1 ÊâßË°åÂä®‰Ωú: [ 8.473402  -1.1656021]
[WARNING]: Received an action [ 8.473402  -1.1656021] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.00361139 -3.3494124 ]
[WARNING]: Received an action [ 0.00361139 -3.3494124 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [11.999958  -2.3230042]
[WARNING]: Received an action [11.999958  -2.3230042] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.0096512  2.9298005]
[WARNING]: Received an action [-1.0096512  2.9298005] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.9279796  1.0947937]
[WARNING]: Received an action [-1.9279796  1.0947937] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.752667  -2.2904406]
[WARNING]: Received an action [ 1.752667  -2.2904406] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 6.0046983 -7.5303607]
[WARNING]: Received an action [ 6.0046983 -7.5303607] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.6340797  0.7872405]
[WARNING]: Received an action [-2.6340797  0.7872405] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 9.031551  -5.1764274]
[WARNING]: Received an action [ 9.031551  -5.1764274] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.8319194  0.63540816]
[WARNING]: Received an action [1.8319194  0.63540816] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-5.7308116 15.159946 ]
[WARNING]: Received an action [-5.7308116 15.159946 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-2.2310822 -1.7893306]
[WARNING]: Received an action [-2.2310822 -1.7893306] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 5.880014 -3.285204]
[WARNING]: Received an action [ 5.880014 -3.285204] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-1.0700183  -0.58471525]
[WARNING]: Received an action [-1.0700183  -0.58471525] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-43.459328   8.650243]
[WARNING]: Received an action [-43.459328   8.650243] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 2.5189378 -1.8659949]
[WARNING]: Received an action [ 2.5189378 -1.8659949] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 5.8763547  -0.34152305]
[WARNING]: Received an action [ 5.8763547  -0.34152305] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 7 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 7 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -2.93
  predator_1: -3.00
  prey_0: -2.70
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 8 ===
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.51353997 -1.1295506 ]
[WARNING]: Received an action [ 0.51353997 -1.1295506 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-3.4659014  0.1965723]
[WARNING]: Received an action [-3.4659014  0.1965723] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.3686185  -0.22549702]
prey_1 ÊâßË°åÂä®‰Ωú: [2.440395  1.6285028]
[WARNING]: Received an action [2.440395  1.6285028] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [1.6751368 1.0314615]
[WARNING]: Received an action [1.6751368 1.0314615] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-1.796097  -3.0828743]
[WARNING]: Received an action [-1.796097  -3.0828743] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.7328639  -0.51152736]
prey_1 ÊâßË°åÂä®‰Ωú: [-3.6314998  1.3877017]
[WARNING]: Received an action [-3.6314998  1.3877017] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.16180101 -0.28879714]
predator_1 ÊâßË°åÂä®‰Ωú: [1.2917113  0.13965368]
[WARNING]: Received an action [1.2917113  0.13965368] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.10207808 0.10929677]
prey_1 ÊâßË°åÂä®‰Ωú: [0.9558161 1.865041 ]
[WARNING]: Received an action [0.9558161 1.865041 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.071704 -4.268577]
[WARNING]: Received an action [-1.071704 -4.268577] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 3.776825   -0.53497964]
[WARNING]: Received an action [ 3.776825   -0.53497964] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.01522335 -0.17134345]
prey_1 ÊâßË°åÂä®‰Ωú: [-0.27967405  2.109814  ]
[WARNING]: Received an action [-0.27967405  2.109814  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.5306436  -0.29380846]
[WARNING]: Received an action [ 1.5306436  -0.29380846] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 8.819689   -0.16467404]
[WARNING]: Received an action [ 8.819689   -0.16467404] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.45598045 -0.20338354]
prey_1 ÊâßË°åÂä®‰Ωú: [2.6701608 2.3590474]
[WARNING]: Received an action [2.6701608 2.3590474] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.18033203 0.54054296]
predator_1 ÊâßË°åÂä®‰Ωú: [15.72611   0.154421]
[WARNING]: Received an action [15.72611   0.154421] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [0.881112   0.24993992]
prey_1 ÊâßË°åÂä®‰Ωú: [3.6811361 1.2453327]
[WARNING]: Received an action [3.6811361 1.2453327] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.30363435 -0.42452097]
predator_1 ÊâßË°åÂä®‰Ωú: [-1.0912211   0.19541651]
[WARNING]: Received an action [-1.0912211   0.19541651] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.94194937 -0.6984604 ]
prey_1 ÊâßË°åÂä®‰Ωú: [1.5031139 1.9230311]
[WARNING]: Received an action [1.5031139 1.9230311] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [1.556293   0.18571065]
[WARNING]: Received an action [1.556293   0.18571065] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.4622686 -2.1330361]
[WARNING]: Received an action [ 1.4622686 -2.1330361] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.5590759  -0.74704015]
prey_1 ÊâßË°åÂä®‰Ωú: [3.0994093 1.692516 ]
[WARNING]: Received an action [3.0994093 1.692516 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [0.8817173  0.16162324]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.70029634 -1.4176602 ]
[WARNING]: Received an action [-0.70029634 -1.4176602 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.2866218 -0.27084  ]
prey_1 ÊâßË°åÂä®‰Ωú: [0.5101338 1.2673178]
[WARNING]: Received an action [0.5101338 1.2673178] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.49765342 -1.4549723 ]
[WARNING]: Received an action [ 0.49765342 -1.4549723 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-10.708566   2.554735]
[WARNING]: Received an action [-10.708566   2.554735] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.34135604 -0.6633524 ]
prey_1 ÊâßË°åÂä®‰Ωú: [-0.533746   1.7135217]
[WARNING]: Received an action [-0.533746   1.7135217] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.2663732 -3.995286 ]
[WARNING]: Received an action [-1.2663732 -3.995286 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.2495617 -1.2694759]
[WARNING]: Received an action [ 1.2495617 -1.2694759] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.5362052  -0.70549273]
prey_1 ÊâßË°åÂä®‰Ωú: [0.5083304 1.3085604]
[WARNING]: Received an action [0.5083304 1.3085604] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.5004688 -1.667732 ]
[WARNING]: Received an action [-0.5004688 -1.667732 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [0.0038662  0.17072254]
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.7337271 -0.4087703]
prey_1 ÊâßË°åÂä®‰Ωú: [0.5781068 1.7328178]
[WARNING]: Received an action [0.5781068 1.7328178] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 1.202985   -0.13872372]
[WARNING]: Received an action [ 1.202985   -0.13872372] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [7.2367115 0.4009316]
[WARNING]: Received an action [7.2367115 0.4009316] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 8 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 8 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: 3.42
  predator_1: 3.21
  prey_0: -1.76
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 9 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-2.3430514 -0.5353873]
[WARNING]: Received an action [-2.3430514 -0.5353873] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-7.0326385  1.0629152]
[WARNING]: Received an action [-7.0326385  1.0629152] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 2.8134375 -2.339448 ]
[WARNING]: Received an action [ 2.8134375 -2.339448 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-0.5486949 -1.0716333]
[WARNING]: Received an action [-0.5486949 -1.0716333] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [3.8267787  0.47980392]
[WARNING]: Received an action [3.8267787  0.47980392] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.9449787 0.8987094]
[WARNING]: Received an action [1.9449787 0.8987094] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.2464924 -3.879723 ]
[WARNING]: Received an action [ 3.2464924 -3.879723 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-35.932358   -1.6808999]
[WARNING]: Received an action [-35.932358   -1.6808999] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.6882255  -0.31291434]
predator_1 ÊâßË°åÂä®‰Ωú: [ 3.1157217  -0.48489267]
[WARNING]: Received an action [ 3.1157217  -0.48489267] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.76538986 -1.0651314 ]
[WARNING]: Received an action [ 0.76538986 -1.0651314 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-9.221276  -0.8573729]
[WARNING]: Received an action [-9.221276  -0.8573729] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 3.1630976 -2.8766475]
[WARNING]: Received an action [ 3.1630976 -2.8766475] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 1.4837816 -0.9288156]
[WARNING]: Received an action [ 1.4837816 -0.9288156] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-2.3960218 -3.1882648]
[WARNING]: Received an action [-2.3960218 -3.1882648] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-3.0656404  -0.51104116]
[WARNING]: Received an action [-3.0656404  -0.51104116] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4749463  2.7382329]
[WARNING]: Received an action [-1.4749463  2.7382329] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 0.7032313 -0.1716851]
prey_0 ÊâßË°åÂä®‰Ωú: [ 5.141469  -1.6886165]
[WARNING]: Received an action [ 5.141469  -1.6886165] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-2.164014   -0.07087672]
[WARNING]: Received an action [-2.164014   -0.07087672] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.142807   -0.95135605]
predator_1 ÊâßË°åÂä®‰Ωú: [ 5.808737  -3.5794551]
[WARNING]: Received an action [ 5.808737  -3.5794551] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.6124604 -5.5056076]
[WARNING]: Received an action [ 0.6124604 -5.5056076] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-14.917494    3.1274977]
[WARNING]: Received an action [-14.917494    3.1274977] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-4.222603  -0.8128822]
[WARNING]: Received an action [-4.222603  -0.8128822] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 4.7028694 -0.4484502]
[WARNING]: Received an action [ 4.7028694 -0.4484502] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [1.7877176 1.0870984]
[WARNING]: Received an action [1.7877176 1.0870984] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-2.515882  2.699152]
[WARNING]: Received an action [-2.515882  2.699152] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-4.380381    0.25158805]
[WARNING]: Received an action [-4.380381    0.25158805] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.7360942  -0.30743778]
prey_0 ÊâßË°åÂä®‰Ωú: [-3.715448  -2.7097092]
[WARNING]: Received an action [-3.715448  -2.7097092] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [10.145493    0.53969294]
[WARNING]: Received an action [10.145493    0.53969294] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [1.2329825 1.8379331]
[WARNING]: Received an action [1.2329825 1.8379331] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 3.4297698 -1.4957039]
[WARNING]: Received an action [ 3.4297698 -1.4957039] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 3.9456825 -4.112793 ]
[WARNING]: Received an action [ 3.9456825 -4.112793 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [9.177587  1.9585391]
[WARNING]: Received an action [9.177587  1.9585391] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [9.443631 3.139   ]
[WARNING]: Received an action [9.443631 3.139   ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 8.390654  -3.4466267]
[WARNING]: Received an action [ 8.390654  -3.4466267] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.8022786 -1.2740633]
[WARNING]: Received an action [-0.8022786 -1.2740633] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 7.878314   -0.51283616]
[WARNING]: Received an action [ 7.878314   -0.51283616] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 2.2576303 -7.876568 ]
[WARNING]: Received an action [ 2.2576303 -7.876568 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-0.3674996  -0.76634514]
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.96942115 -1.3229113 ]
[WARNING]: Received an action [ 0.96942115 -1.3229113 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-12.746347   -8.5875025]
[WARNING]: Received an action [-12.746347   -8.5875025] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.6916519  2.9207258]
[WARNING]: Received an action [-1.6916519  2.9207258] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [1.7525444  0.06245339]
[WARNING]: Received an action [1.7525444  0.06245339] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.40207392 -0.8986908 ]
prey_1 ÊâßË°åÂä®‰Ωú: [13.052204   2.7507505]
[WARNING]: Received an action [13.052204   2.7507505] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [3.112981  3.0998914]
[WARNING]: Received an action [3.112981  3.0998914] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-8.637877   1.5053837]
[WARNING]: Received an action [-8.637877   1.5053837] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 9 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 9 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -2.93
  predator_1: -2.84
  prey_0: -2.75
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50

=== Episode 10 ===
predator_0 ÊâßË°åÂä®‰Ωú: [-1.0104607  -0.93971604]
[WARNING]: Received an action [-1.0104607  -0.93971604] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [ 6.7080617  -0.70487785]
[WARNING]: Received an action [ 6.7080617  -0.70487785] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 5.7526875 -2.6265984]
[WARNING]: Received an action [ 5.7526875 -2.6265984] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [66.065475   6.2603636]
[WARNING]: Received an action [66.065475   6.2603636] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.97309613 -0.6957725 ]
predator_1 ÊâßË°åÂä®‰Ωú: [12.143816    0.07203609]
[WARNING]: Received an action [12.143816    0.07203609] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.19678974 -3.0207698 ]
[WARNING]: Received an action [ 0.19678974 -3.0207698 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-12.788245 -28.464962]
[WARNING]: Received an action [-12.788245 -28.464962] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.06304556 -0.72810155]
predator_1 ÊâßË°åÂä®‰Ωú: [-2.0202618  0.9314546]
[WARNING]: Received an action [-2.0202618  0.9314546] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.234011   1.9675416]
[WARNING]: Received an action [-0.234011   1.9675416] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-19.10887    4.870745]
[WARNING]: Received an action [-19.10887    4.870745] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.16655342 -0.03331009]
predator_1 ÊâßË°åÂä®‰Ωú: [3.7370243 0.7771836]
[WARNING]: Received an action [3.7370243 0.7771836] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.6292208 -1.3306289]
[WARNING]: Received an action [ 1.6292208 -1.3306289] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-2.3303413 -0.738666 ]
[WARNING]: Received an action [-2.3303413 -0.738666 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-1.4987303 -1.04307  ]
[WARNING]: Received an action [-1.4987303 -1.04307  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_1 ÊâßË°åÂä®‰Ωú: [-10.864269    -0.95434844]
[WARNING]: Received an action [-10.864269    -0.95434844] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.11013728 -2.552877  ]
[WARNING]: Received an action [ 0.11013728 -2.552877  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 1.1845672 -3.0470617]
[WARNING]: Received an action [ 1.1845672 -3.0470617] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.11536193 -0.6639167 ]
predator_1 ÊâßË°åÂä®‰Ωú: [ 4.354466  -2.6768637]
[WARNING]: Received an action [ 4.354466  -2.6768637] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.0958107 -0.5374279]
[WARNING]: Received an action [ 1.0958107 -0.5374279] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-21.795712 -15.521137]
[WARNING]: Received an action [-21.795712 -15.521137] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.5536262  -0.65710145]
predator_1 ÊâßË°åÂä®‰Ωú: [-3.4123378 -1.3971975]
[WARNING]: Received an action [-3.4123378 -1.3971975] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [-0.88117456 -1.619604  ]
[WARNING]: Received an action [-0.88117456 -1.619604  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-30.140167  13.801906]
[WARNING]: Received an action [-30.140167  13.801906] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.20259383 -0.5340791 ]
predator_1 ÊâßË°åÂä®‰Ωú: [-0.59796774 -1.0137619 ]
[WARNING]: Received an action [-0.59796774 -1.0137619 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.95576   -1.4577982]
[WARNING]: Received an action [ 1.95576   -1.4577982] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [ 27.75187  -17.432596]
[WARNING]: Received an action [ 27.75187  -17.432596] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.33575276 -0.7759565 ]
predator_1 ÊâßË°åÂä®‰Ωú: [ 8.299122  -2.1331728]
[WARNING]: Received an action [ 8.299122  -2.1331728] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.4666706 -2.0251935]
[WARNING]: Received an action [ 0.4666706 -2.0251935] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-34.317253  -4.857344]
[WARNING]: Received an action [-34.317253  -4.857344] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [ 0.13896248 -0.7451495 ]
predator_1 ÊâßË°åÂä®‰Ωú: [2.1267617 1.8019583]
[WARNING]: Received an action [2.1267617 1.8019583] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.5926462 -0.8190061]
[WARNING]: Received an action [ 1.5926462 -0.8190061] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [11.140587 17.7316  ]
[WARNING]: Received an action [11.140587 17.7316  ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.5238614 -0.5711898]
predator_1 ÊâßË°åÂä®‰Ωú: [-2.7358372  3.7217505]
[WARNING]: Received an action [-2.7358372  3.7217505] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 0.23865384 -0.4044091 ]
prey_1 ÊâßË°åÂä®‰Ωú: [ 6.9119015 -2.342197 ]
[WARNING]: Received an action [ 6.9119015 -2.342197 ] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.2728241 -0.6149791]
predator_1 ÊâßË°åÂä®‰Ωú: [ 2.957953  -1.9152687]
[WARNING]: Received an action [ 2.957953  -1.9152687] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_0 ÊâßË°åÂä®‰Ωú: [ 1.6476623 -0.6422449]
[WARNING]: Received an action [ 1.6476623 -0.6422449] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
prey_1 ÊâßË°åÂä®‰Ωú: [-28.797657   8.051668]
[WARNING]: Received an action [-28.797657   8.051668] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
predator_0 ÊâßË°åÂä®‰Ωú: [-0.6387142 -0.608618 ]
predator_1 ÊâßË°åÂä®‰Ωú: [12.399975    0.53810567]
[WARNING]: Received an action [12.399975    0.53810567] that was outside action space Box(-1.0, 1.0, (2,), float32). Environment is clipping to space
Episode 10 Âá∫Áé∞ÈîôËØØ: name 'gif_filename' is not defined
Ê≤°ÊúâÊçïËé∑Âà∞Â∏ßÔºåÊó†Ê≥ïÁîüÊàêGIF
Episode 10 ÂÆåÊàê
ÂêÑÊô∫ËÉΩ‰ΩìÊÄªÂ•ñÂä±:
  predator_0: -2.26
  predator_1: -3.00
  prey_0: -2.62
  prey_1: -5.50
ÊÄªÊ≠•Êï∞: 50
Êé®ÁêÜÂÆåÊàê!
[0m
