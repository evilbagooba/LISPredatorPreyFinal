['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑpolicies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
ÂàõÂª∫ÁöÑRL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: [33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: [33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64[0m
  gym.logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  logger.warn(
/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
ÂºÄÂßãËÆ≠ÁªÉ...
2025-07-02 02:40:56,905	INFO worker.py:1917 -- Started a local Ray instance.
2025-07-02 02:40:57,403	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
== Status ==
Current time: 2025-07-02 02:40:57 (running for 00:00:00.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_8b84f_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=3491689)[0m 2025-07-02 02:40:59,742	WARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
[36m(MultiAgentEnvRunner pid=3491784)[0m 2025-07-02 02:41:02,216	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-02 02:41:02 (running for 00:00:05.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 PENDING)
+---------------------+----------+-------+
| Trial name          | status   | loc   |
|---------------------+----------+-------|
| PPO_env_8b84f_00000 | PENDING  |       |
+---------------------+----------+-------+
[36m(PPO pid=3491689)[0m Install gputil for GPU system monitoring.
[36m(_WandbLoggingActor pid=3492003)[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(_WandbLoggingActor pid=3492003)[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Tracking run with wandb version 0.20.1
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Run data is saved locally in /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/wandb/run-20250702_024105-8b84f_00000
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Syncing run PPO_env_8b84f_00000
[36m(_WandbLoggingActor pid=3492003)[0m wandb: ‚≠êÔ∏è View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=3492003)[0m wandb: üöÄ View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/8b84f_00000
[33m(raylet)[0m [2025-07-02 02:41:06,897 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.81557 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


== Status ==
Current time: 2025-07-02 02:41:07 (running for 00:00:10.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+
| Trial name          | status   | loc                  |
|---------------------+----------+----------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |
+---------------------+----------+----------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-484.12920801258025,num_env_steps_sampled_lifetime=4000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000000)
[36m(PPO pid=3491689)[0m 2025-07-02 02:41:02,301	WARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8049x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000000)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:41:12 (running for 00:00:15.21)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      1 |          5.93619 | 4000 |          -484.129 |        -90.3594 |        -213.388 |            -99.9202 |            -80.4618 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-477.4653030671298,num_env_steps_sampled_lifetime=8000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000001)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8159x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000001)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:41:16,902 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.78394 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:41:17 (running for 00:00:20.27)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |   ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      2 |          10.9318 | 8000 |          -477.465 |        -80.9553 |        -208.949 |            -100.757 |            -86.8033 |
+---------------------+----------+----------------------+--------+------------------+------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-488.7672002298785,num_env_steps_sampled_lifetime=12000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000002)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7970x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000002)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:41:22 (running for 00:00:25.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      3 |          16.3154 | 12000 |          -488.767 |        -87.0776 |        -207.137 |            -103.011 |            -91.5416 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-458.36727413718677,num_env_steps_sampled_lifetime=16000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000003)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8022x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000003)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:41:26,907 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.75367 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:41:27 (running for 00:00:30.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      4 |          21.4945 | 16000 |          -458.367 |        -79.3476 |        -203.299 |            -91.6868 |            -84.0342 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-461.2967498635526,num_env_steps_sampled_lifetime=20000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000004)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7984x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000004)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:41:32 (running for 00:00:35.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      5 |           26.864 | 20000 |          -461.297 |           -83.2 |        -203.821 |            -88.6672 |            -85.6088 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:41:36,913 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.73768 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-458.34728268679254,num_env_steps_sampled_lifetime=24000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000005)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8032x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000005)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:41:37 (running for 00:00:40.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      6 |          32.1655 | 24000 |          -458.347 |        -85.5043 |        -200.793 |            -85.5473 |            -86.5027 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-455.38421679800143,num_env_steps_sampled_lifetime=28000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000006)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8040x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000006)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:41:42 (running for 00:00:45.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      7 |          37.3161 | 28000 |          -455.384 |         -85.868 |        -197.014 |            -84.6024 |            -87.9001 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491784)[0m
[33m(raylet)[0m [2025-07-02 02:41:46,918 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.70069 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:41:47 (running for 00:00:50.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      7 |          37.3161 | 28000 |          -455.384 |         -85.868 |        -197.014 |            -84.6024 |            -87.9001 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-453.0958744568953,num_env_steps_sampled_lifetime=32000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000007)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8024x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000007)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:41:52 (running for 00:00:55.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      8 |          43.2083 | 32000 |          -453.096 |        -88.5329 |        -193.102 |            -85.8512 |            -85.6102 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-452.5839547796425,num_env_steps_sampled_lifetime=36000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000008)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7936x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000008)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:41:56,924 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.67059 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:41:57 (running for 00:01:00.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |      9 |          49.0595 | 36000 |          -452.584 |        -89.4865 |         -190.19 |            -87.7472 |            -85.1606 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-449.0753373751119,num_env_steps_sampled_lifetime=40000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000009)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8112x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000009)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:42:03 (running for 00:01:05.64)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     10 |          54.4842 | 40000 |          -449.075 |        -91.2923 |        -188.806 |            -87.1913 |            -81.7853 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-448.3217014625274,num_env_steps_sampled_lifetime=44000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000010)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7896x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000010)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[33m(raylet)[0m [2025-07-02 02:42:06,928 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.64042 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:42:08 (running for 00:01:10.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     11 |          59.8293 | 44000 |          -448.322 |        -92.0511 |        -186.805 |            -84.8954 |            -84.5707 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-442.94940182191687,num_env_steps_sampled_lifetime=48000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000011)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8072x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000011)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:42:13 (running for 00:01:15.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     12 |          65.0854 | 48000 |          -442.949 |        -90.6918 |        -185.305 |            -82.7427 |            -84.2099 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-442.55385624150193,num_env_steps_sampled_lifetime=52000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000012)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7976x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000012)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:42:16,934 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.61707 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:42:18 (running for 00:01:20.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     13 |          70.5986 | 52000 |          -442.554 |        -91.4596 |        -185.559 |            -80.9364 |            -84.5986 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-445.59227336615083,num_env_steps_sampled_lifetime=56000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000013)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8056x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000013)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:42:23 (running for 00:01:25.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     14 |          75.9178 | 56000 |          -445.592 |        -91.6775 |         -186.57 |            -81.0216 |            -86.3228 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-445.13850260335664,num_env_steps_sampled_lifetime=60000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[33m(raylet)[0m [2025-07-02 02:42:26,938 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.58703 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000014)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8040x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000014)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:42:28 (running for 00:01:30.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     15 |          81.3663 | 60000 |          -445.139 |        -91.3557 |        -186.034 |             -80.607 |            -87.1421 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-445.69595334052525,num_env_steps_sampled_lifetime=64000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000015)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8000x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000015)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:42:33 (running for 00:01:35.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     16 |          86.4714 | 64000 |          -445.696 |        -91.0527 |        -186.807 |            -79.2987 |            -88.5378 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000016)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000016)...
[33m(raylet)[0m [2025-07-02 02:42:36,943 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.55724 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8433x across cluster][0m
== Status ==
Current time: 2025-07-02 02:42:38 (running for 00:01:40.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     17 |           91.303 | 68000 |          -448.019 |        -91.9456 |        -186.761 |            -79.8873 |            -89.4254 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-449.0195676537614,num_env_steps_sampled_lifetime=72000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000017)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7559x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000017)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:42:43 (running for 00:01:45.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     18 |          96.5062 | 72000 |           -449.02 |        -92.8209 |        -187.018 |            -79.5387 |            -89.6421 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:42:46,949 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.541 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-447.67381423191404,num_env_steps_sampled_lifetime=76000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000018)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8080x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000018)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:42:48 (running for 00:01:51.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     19 |          101.878 | 76000 |          -447.674 |         -92.495 |        -186.188 |            -79.9764 |            -89.0141 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000019)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000019)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8608x across cluster][0m
== Status ==
Current time: 2025-07-02 02:42:53 (running for 00:01:56.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     20 |          106.657 | 80000 |          -446.803 |        -92.3941 |          -186.5 |            -80.6772 |             -87.232 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:42:56,954 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.51077 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-444.90513538204937,num_env_steps_sampled_lifetime=84000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000020)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7448x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000020)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:42:58 (running for 00:02:01.04)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     21 |           111.89 | 84000 |          -444.905 |        -92.5119 |        -185.994 |            -81.1411 |            -85.2583 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-442.85118430408187,num_env_steps_sampled_lifetime=88000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000021)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7888x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000021)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:43:03 (running for 00:02:06.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     22 |          117.041 | 88000 |          -442.851 |        -93.1752 |        -183.804 |            -80.5605 |            -85.3113 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:43:06,959 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.4805 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-442.29489749600316,num_env_steps_sampled_lifetime=92000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000022)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8104x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000022)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:43:08 (running for 00:02:11.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     23 |          122.256 | 92000 |          -442.295 |        -92.7608 |        -183.683 |            -80.2825 |            -85.5689 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491784)[0m
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-441.56634845322577,num_env_steps_sampled_lifetime=96000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000023)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7966x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000023)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:43:13 (running for 00:02:16.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     24 |           127.46 | 96000 |          -441.566 |        -92.3512 |        -183.681 |            -79.5635 |            -85.9708 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:43:16,964 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.44302 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


== Status ==
Current time: 2025-07-02 02:43:18 (running for 00:02:21.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |    ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     24 |           127.46 | 96000 |          -441.566 |        -92.3512 |        -183.681 |            -79.5635 |            -85.9708 |
+---------------------+----------+----------------------+--------+------------------+-------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-440.4785911587667,num_env_steps_sampled_lifetime=100000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000024)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8042x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000024)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:43:23 (running for 00:02:26.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     25 |           132.81 | 100000 |          -440.479 |        -92.0332 |        -183.107 |            -79.9264 |            -85.4121 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-438.8000563474421,num_env_steps_sampled_lifetime=104000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000025)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8016x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000025)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:43:26,969 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.41309 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:43:28 (running for 00:02:31.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     26 |          138.011 | 104000 |            -438.8 |        -92.1259 |        -182.022 |              -79.17 |            -85.4823 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-435.2388629233391,num_env_steps_sampled_lifetime=108000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000026)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7947x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000026)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:43:33 (running for 00:02:36.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     27 |          143.325 | 108000 |          -435.239 |        -92.4777 |        -180.345 |            -77.9314 |            -84.4846 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-429.4273178096085,num_env_steps_sampled_lifetime=112000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000027)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8053x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000027)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:43:36,974 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.38317 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:43:38 (running for 00:02:41.51)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     28 |          148.573 | 112000 |          -429.427 |        -91.7232 |        -178.413 |             -76.065 |            -83.2256 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-431.1050486310902,num_env_steps_sampled_lifetime=116000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000028)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8112x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000028)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:43:43 (running for 00:02:46.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     29 |          153.794 | 116000 |          -431.105 |        -92.3321 |        -176.551 |            -77.3664 |            -84.8556 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-429.1028030138079,num_env_steps_sampled_lifetime=120000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000029)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8008x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000029)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:43:46,980 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.35321 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:43:49 (running for 00:02:51.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     30 |          158.751 | 120000 |          -429.103 |        -92.0674 |        -175.171 |            -77.4054 |            -84.4594 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-426.75230284246487,num_env_steps_sampled_lifetime=124000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000030)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8004x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000030)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:43:54 (running for 00:02:56.61)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     31 |          164.036 | 124000 |          -426.752 |        -92.1237 |        -174.062 |            -77.1488 |            -83.4182 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-423.90134489556425,num_env_steps_sampled_lifetime=128000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000031)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7974x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000031)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:43:56,985 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.32302 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:43:59 (running for 00:03:01.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     32 |          169.228 | 128000 |          -423.901 |        -92.6167 |         -172.32 |            -75.8905 |            -83.0736 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-422.58061716179856,num_env_steps_sampled_lifetime=132000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000032)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7962x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000032)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:04 (running for 00:03:06.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     33 |          174.216 | 132000 |          -422.581 |         -91.945 |        -171.417 |            -75.4379 |            -83.7807 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-419.946533297165,num_env_steps_sampled_lifetime=136000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000033)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8020x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000033)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:44:06,991 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.29953 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:44:09 (running for 00:03:11.74)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     34 |          179.471 | 136000 |          -419.947 |        -91.8378 |         -170.97 |            -73.7655 |            -83.3728 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-419.57073320658094,num_env_steps_sampled_lifetime=140000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000034)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8117x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000034)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types o
[36m(MultiAgentEnvRunner pid=3491785)[0m r ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-02 02:44:14 (running for 00:03:16.79)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     35 |          184.596 | 140000 |          -419.571 |        -91.6559 |        -170.209 |            -73.2036 |            -84.5021 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-417.7399179012308,num_env_steps_sampled_lifetime=144000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000035)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7938x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000035)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:44:16,996 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.26922 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:44:19 (running for 00:03:21.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     36 |          189.917 | 144000 |           -417.74 |        -91.3074 |        -169.835 |            -73.6299 |            -82.9676 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-417.9241877955381,num_env_steps_sampled_lifetime=148000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000036)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8016x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000036)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:24 (running for 00:03:26.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     37 |          195.189 | 148000 |          -417.924 |         -91.475 |        -169.322 |            -74.6994 |            -82.4282 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-415.78335343404683,num_env_steps_sampled_lifetime=152000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[33m(raylet)[0m [2025-07-02 02:44:27,001 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.25315 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000037)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8064x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000037)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:29 (running for 00:03:31.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     38 |          200.317 | 152000 |          -415.783 |        -90.7004 |        -168.048 |            -74.7704 |            -82.2644 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-413.99403196364636,num_env_steps_sampled_lifetime=156000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000038)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7960x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000038)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:34 (running for 00:03:36.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     39 |          205.736 | 156000 |          -413.994 |        -90.7937 |         -166.61 |            -74.8395 |            -81.7508 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:44:37,006 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.22307 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-413.4515819914162,num_env_steps_sampled_lifetime=160000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000039)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8038x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000039)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:39 (running for 00:03:41.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     40 |          210.999 | 160000 |          -413.452 |         -91.215 |        -165.428 |            -75.1757 |            -81.6331 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-412.040091694897,num_env_steps_sampled_lifetime=164000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000040)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8106x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000040)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:44 (running for 00:03:47.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     41 |          216.215 | 164000 |           -412.04 |        -91.1718 |        -163.579 |            -75.9765 |             -81.313 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491784)[0m
[33m(raylet)[0m [2025-07-02 02:44:47,012 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.18584 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-409.27632196544874,num_env_steps_sampled_lifetime=168000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000041)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8000x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000041)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:44:49 (running for 00:03:52.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     42 |          221.605 | 168000 |          -409.276 |        -90.2277 |        -162.986 |            -75.8144 |            -80.2486 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-406.03436185196404,num_env_steps_sampled_lifetime=172000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000042)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7888x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000042)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:54 (running for 00:03:57.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     43 |          226.848 | 172000 |          -406.034 |        -90.0517 |        -160.892 |            -76.3455 |             -78.745 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:44:57,017 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.15544 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-403.82669086474505,num_env_steps_sampled_lifetime=176000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000043)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8120x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000043)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:44:59 (running for 00:04:02.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     44 |          232.162 | 176000 |          -403.827 |        -90.0027 |         -158.65 |            -76.4966 |            -78.6776 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
[36m(MultiAgentEnvRunner pid=3491784)[0m
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-401.71860838623184,num_env_steps_sampled_lifetime=180000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000044)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7919x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000044)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:45:04 (running for 00:04:07.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     45 |          237.298 | 180000 |          -401.719 |        -89.0989 |        -156.345 |            -75.6384 |            -80.6368 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:45:07,022 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.12503 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-400.81387737837866,num_env_steps_sampled_lifetime=184000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000045)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8081x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000045)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:45:09 (running for 00:04:12.40)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     46 |          242.529 | 184000 |          -400.814 |        -88.4025 |        -154.692 |            -75.0042 |             -82.715 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:45:14 (running for 00:04:17.41)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     46 |          242.529 | 184000 |          -400.814 |        -88.4025 |        -154.692 |            -75.0042 |             -82.715 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-400.1467378887659,num_env_steps_sampled_lifetime=188000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000046)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8073x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000046)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:45:17,028 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.09492 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:45:19 (running for 00:04:22.43)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     47 |          247.763 | 188000 |          -400.147 |        -87.8945 |        -154.221 |            -75.1698 |            -82.8613 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-396.1908141431566,num_env_steps_sampled_lifetime=192000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000047)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7895x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000047)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:45:24 (running for 00:04:27.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     48 |           252.93 | 192000 |          -396.191 |        -87.4068 |        -151.777 |             -75.033 |            -81.9739 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-393.7373119775368,num_env_steps_sampled_lifetime=196000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000048)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8048x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000048)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:45:27,033 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.06463 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:45:29 (running for 00:04:32.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     49 |          258.166 | 196000 |          -393.737 |        -87.6993 |        -149.878 |            -74.5274 |             -81.633 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-393.03183768863323,num_env_steps_sampled_lifetime=200000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000049)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000049)...
[36m(MultiAgentEnvRunner pid=3491784)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7964x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:45:34 (running for 00:04:37.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     50 |          263.376 | 200000 |          -393.032 |        -88.1216 |        -148.791 |            -73.9506 |            -82.1685 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-391.56016219744214,num_env_steps_sampled_lifetime=204000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000050)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8132x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000050)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:45:37,039 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.04093 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:45:39 (running for 00:04:42.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     51 |          268.711 | 204000 |           -391.56 |        -88.0634 |        -146.979 |            -74.0448 |             -82.473 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-390.69900782149557,num_env_steps_sampled_lifetime=208000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000051)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7912x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000051)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:45:45 (running for 00:04:47.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     52 |          273.943 | 208000 |          -390.699 |         -87.803 |        -146.252 |            -73.4727 |            -83.1715 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-392.16670543791975,num_env_steps_sampled_lifetime=212000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000052)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8016x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000052)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:45:47,044 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 9.01086 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:45:50 (running for 00:04:52.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     53 |          279.003 | 212000 |          -392.167 |        -87.7623 |        -146.381 |            -73.9341 |            -84.0896 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-389.2637881610739,num_env_steps_sampled_lifetime=216000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000053)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8080x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000053)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:45:55 (running for 00:04:57.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     54 |           284.35 | 216000 |          -389.264 |        -88.0314 |        -144.929 |            -73.3041 |            -82.9991 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-385.89233624161477,num_env_steps_sampled_lifetime=220000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[33m(raylet)[0m [2025-07-02 02:45:57,049 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.99473 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000054)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8024x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000054)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:46:00 (running for 00:05:02.81)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     55 |          289.511 | 220000 |          -385.892 |        -87.1001 |        -142.637 |            -73.3263 |            -82.8288 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-385.83409249090096,num_env_steps_sampled_lifetime=224000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000055)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8008x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000055)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:05 (running for 00:05:07.82)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     56 |          294.802 | 224000 |          -385.834 |        -86.0484 |        -142.493 |            -74.0149 |            -83.2779 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:46:07,054 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.96431 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-385.98484792843783,num_env_steps_sampled_lifetime=228000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000056)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7992x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000056)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:10 (running for 00:05:12.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     57 |          299.989 | 228000 |          -385.985 |        -85.2147 |        -141.797 |             -75.815 |            -83.1585 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-384.77263688578364,num_env_steps_sampled_lifetime=232000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000057)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8106x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000057)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:15 (running for 00:05:17.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     58 |          305.234 | 232000 |          -384.773 |        -85.3177 |        -141.274 |            -75.1676 |            -83.0134 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:46:17,059 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.93385 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-385.791942064506,num_env_steps_sampled_lifetime=236000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000058)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7958x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000058)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and veloci
[36m(MultiAgentEnvRunner pid=3491785)[0m ty values
== Status ==
Current time: 2025-07-02 02:46:20 (running for 00:05:22.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     59 |          310.549 | 236000 |          -385.792 |        -85.0045 |        -140.776 |            -76.5141 |             -83.497 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-385.7326268603513,num_env_steps_sampled_lifetime=240000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000059)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8023x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000059)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:46:25 (running for 00:05:28.03)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     60 |          315.713 | 240000 |          -385.733 |        -84.6215 |        -140.527 |            -77.0611 |            -83.5233 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:46:27,064 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.8968 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-384.59707444152184,num_env_steps_sampled_lifetime=244000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000060)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7973x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000060)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:30 (running for 00:05:33.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     61 |          320.899 | 244000 |          -384.597 |        -84.5933 |        -140.643 |            -76.6004 |            -82.7608 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-385.480910250124,num_env_steps_sampled_lifetime=248000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000061)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8054x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000061)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:35 (running for 00:05:38.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     62 |          325.857 | 248000 |          -385.481 |        -85.0969 |        -140.824 |            -76.2743 |            -83.2861 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:46:37,070 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.86669 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-386.05501021929143,num_env_steps_sampled_lifetime=252000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000062)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8045x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000062)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:40 (running for 00:05:43.22)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     63 |          331.306 | 252000 |          -386.055 |        -84.6352 |        -141.178 |             -76.712 |            -83.5294 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-382.34288007467933,num_env_steps_sampled_lifetime=256000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000063)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8016x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000063)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:45 (running for 00:05:48.31)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     64 |          336.583 | 256000 |          -382.343 |        -84.0631 |        -138.052 |            -77.1917 |            -83.0362 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:46:47,075 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.83657 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-381.35773913579186,num_env_steps_sampled_lifetime=260000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000064)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7952x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000064)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:50 (running for 00:05:53.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     65 |          341.772 | 260000 |          -381.358 |        -83.7677 |        -137.896 |            -77.0937 |            -82.6004 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-379.15031855129587,num_env_steps_sampled_lifetime=264000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000065)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7974x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000065)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:46:55 (running for 00:05:58.41)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     66 |           346.88 | 264000 |           -379.15 |        -84.3681 |         -137.12 |            -76.1496 |            -81.5123 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:46:57,081 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.80637 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-378.71967507400905,num_env_steps_sampled_lifetime=268000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000066)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8114x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000066)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:00 (running for 00:06:03.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     67 |          351.985 | 268000 |           -378.72 |        -84.8814 |        -137.044 |            -75.9232 |            -80.8707 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-379.6442394249474,num_env_steps_sampled_lifetime=272000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000067)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8016x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000067)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:05 (running for 00:06:08.49)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     68 |           357.14 | 272000 |          -379.644 |        -84.4077 |        -136.904 |            -76.1833 |            -82.1493 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:47:07,086 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.77637 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-381.89300956061516,num_env_steps_sampled_lifetime=276000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000068)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7952x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000068)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:10 (running for 00:06:13.55)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     69 |          362.449 | 276000 |          -381.893 |        -84.6182 |        -138.152 |            -75.5981 |            -83.5248 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000069)


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8128x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000069)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:16 (running for 00:06:18.63)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     70 |           367.36 | 280000 |          -381.603 |        -85.4259 |        -138.236 |            -74.2073 |            -83.7336 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:47:17,091 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.74837 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-378.7936817659831,num_env_steps_sampled_lifetime=284000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000070)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7976x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000070)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:21 (running for 00:06:23.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     71 |          372.464 | 284000 |          -378.794 |         -84.867 |        -137.937 |            -73.4003 |            -82.5889 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:47:26 (running for 00:06:28.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     71 |          372.464 | 284000 |          -378.794 |         -84.867 |        -137.937 |            -73.4003 |            -82.5889 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-376.8680733384292,num_env_steps_sampled_lifetime=288000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000071)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7984x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000071)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:47:27,096 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.72277 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:47:31 (running for 00:06:33.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     72 |          377.615 | 288000 |          -376.868 |        -83.7423 |        -136.219 |            -74.0188 |            -82.8882 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-379.1763005060362,num_env_steps_sampled_lifetime=292000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000072)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8076x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000072)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:36 (running for 00:06:38.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     73 |          382.579 | 292000 |          -379.176 |        -84.0969 |        -136.753 |            -74.4546 |            -83.8722 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-380.9189142047152,num_env_steps_sampled_lifetime=296000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000073)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7916x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000073)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:47:37,101 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.69284 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:47:41 (running for 00:06:43.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     74 |          387.784 | 296000 |          -380.919 |        -83.4275 |        -137.487 |            -76.0779 |            -83.9267 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-383.7068460425255,num_env_steps_sampled_lifetime=300000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000074)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8096x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000074)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:46 (running for 00:06:48.88)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     75 |          393.106 | 300000 |          -383.707 |         -82.666 |        -140.522 |             -76.364 |            -84.1549 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000075)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000075)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8296x across cluster][0m
[33m(raylet)[0m [2025-07-02 02:47:47,106 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.66284 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:47:51 (running for 00:06:53.94)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     76 |          397.975 | 304000 |          -384.055 |         -82.305 |        -141.719 |            -75.6098 |            -84.4218 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-382.8983885432091,num_env_steps_sampled_lifetime=308000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000076)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7726x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000076)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:47:56 (running for 00:06:59.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     77 |          403.244 | 308000 |          -382.898 |        -82.6801 |        -140.453 |            -76.4961 |            -83.2696 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:47:57,111 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.64671 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-382.08557097747007,num_env_steps_sampled_lifetime=312000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000077)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7947x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000077)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:01 (running for 00:07:04.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     78 |          408.451 | 312000 |          -382.086 |        -82.8844 |         -139.77 |            -76.7038 |            -82.7273 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000078)


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8115x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000078)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:06 (running for 00:07:09.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     79 |          413.389 | 316000 |          -382.227 |        -82.8428 |        -138.965 |            -77.6981 |            -82.7213 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:48:07,115 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.6165 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-388.6512857312302,num_env_steps_sampled_lifetime=320000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000079)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7964x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000079)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:11 (running for 00:07:14.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     80 |          418.677 | 320000 |          -388.651 |         -83.596 |         -142.85 |            -78.5495 |            -83.6556 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-386.6612915934081,num_env_steps_sampled_lifetime=324000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000080)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7952x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000080)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:48:16 (running for 00:07:19.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     81 |          423.894 | 324000 |          -386.661 |         -83.725 |        -140.264 |            -78.8415 |            -83.8307 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:48:17,120 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.58598 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-385.1221700916919,num_env_steps_sampled_lifetime=328000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000081)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8093x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000081)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:21 (running for 00:07:24.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     82 |          429.046 | 328000 |          -385.122 |        -83.3501 |        -140.867 |            -77.8161 |            -83.0891 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-383.2351573493103,num_env_steps_sampled_lifetime=332000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000082)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8067x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000082)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:26 (running for 00:07:29.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     83 |          434.294 | 332000 |          -383.235 |        -82.3015 |        -138.927 |            -78.7334 |            -83.2737 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:48:27,125 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.54897 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-381.30940436137513,num_env_steps_sampled_lifetime=336000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000083)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7896x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000083)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:31 (running for 00:07:34.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     84 |          439.648 | 336000 |          -381.309 |         -81.864 |        -137.513 |            -78.6156 |            -83.3173 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-376.4131343219618,num_env_steps_sampled_lifetime=340000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000084)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7992x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000084)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:36 (running for 00:07:39.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     85 |           444.93 | 340000 |          -376.413 |        -80.9444 |        -135.305 |            -78.7372 |            -81.4261 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:48:37,130 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.51875 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-376.11780965893695,num_env_steps_sampled_lifetime=344000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000085)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8056x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000085)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:41 (running for 00:07:44.48)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     86 |          450.391 | 344000 |          -376.118 |        -80.3465 |        -132.998 |             -79.468 |            -83.3053 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-374.48753112372987,num_env_steps_sampled_lifetime=348000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000086)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7976x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000086)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:46 (running for 00:07:49.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     87 |          455.882 | 348000 |          -374.488 |        -79.1207 |        -133.034 |            -78.9055 |            -83.4269 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:48:47,134 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.48891 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


[36m(MultiAgentEnvRunner pid=3491785)[0m
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-372.87839574289467,num_env_steps_sampled_lifetime=352000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000087)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8022x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000087)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:52 (running for 00:07:54.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     88 |          461.271 | 352000 |          -372.878 |        -79.2417 |        -133.479 |            -77.5091 |             -82.649 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-374.8596214513725,num_env_steps_sampled_lifetime=356000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000088)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8034x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000088)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:48:57 (running for 00:07:59.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     89 |           466.33 | 356000 |           -374.86 |        -78.9396 |        -136.492 |            -76.6854 |            -82.7431 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:48:57,138 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.46521 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-376.88689074946507,num_env_steps_sampled_lifetime=360000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000089)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8040x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000089)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:49:02 (running for 00:08:04.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     90 |          471.794 | 360000 |          -376.887 |        -78.5337 |        -137.165 |            -77.4132 |            -83.7749 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-378.5217049707724,num_env_steps_sampled_lifetime=364000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
== Status ==
Current time: 2025-07-02 02:49:07 (running for 00:08:09.80)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     91 |          477.607 | 364000 |          -378.522 |        -77.7631 |        -138.841 |            -77.8204 |             -84.097 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:49:07,143 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.44901 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000090)


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7970x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000090)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:49:12 (running for 00:08:14.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     91 |          477.607 | 364000 |          -378.522 |        -77.7631 |        -138.841 |            -77.8204 |             -84.097 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-373.33973670624016,num_env_steps_sampled_lifetime=368000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000091)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8134x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000091)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[33m(raylet)[0m [2025-07-02 02:49:17,148 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.41832 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:49:17 (running for 00:08:19.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     92 |          483.432 | 368000 |           -373.34 |        -77.2978 |        -135.699 |            -76.1041 |            -84.2383 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-370.57846077137367,num_env_steps_sampled_lifetime=372000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000092)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8000x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000092)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:49:22 (running for 00:08:24.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     93 |          489.235 | 372000 |          -370.578 |        -76.1578 |        -134.609 |            -75.7886 |            -84.0229 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-368.7143071835819,num_env_steps_sampled_lifetime=376000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000093)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7976x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000093)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:49:27,153 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.38784 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:49:27 (running for 00:08:29.90)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     94 |          494.541 | 376000 |          -368.714 |        -75.4496 |        -134.835 |            -75.9347 |            -82.4948 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-366.7918948813109,num_env_steps_sampled_lifetime=380000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000094)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8048x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000094)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:49:32 (running for 00:08:35.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     95 |          500.331 | 380000 |          -366.792 |        -74.3501 |        -136.516 |             -76.358 |            -79.5678 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-368.57670236412247,num_env_steps_sampled_lifetime=384000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000095)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7986x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000095)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:49:37,159 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.35133 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:49:37 (running for 00:08:40.09)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     96 |          505.722 | 384000 |          -368.577 |        -74.1943 |        -137.228 |            -77.5158 |            -79.6387 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-370.1040053722055,num_env_steps_sampled_lifetime=388000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000096)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8022x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000096)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:49:42 (running for 00:08:45.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     97 |          511.209 | 388000 |          -370.104 |        -74.4536 |        -140.867 |            -75.5276 |            -79.2561 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-367.5637815411132,num_env_steps_sampled_lifetime=392000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000097)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7940x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000097)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:49:47,164 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.32765 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:49:47 (running for 00:08:50.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     98 |          516.566 | 392000 |          -367.564 |        -73.7418 |        -140.656 |            -74.2833 |            -78.8829 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491784)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-360.9738194966586,num_env_steps_sampled_lifetime=396000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000098)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8148x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000098)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:49:52 (running for 00:08:55.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |     99 |          522.058 | 396000 |          -360.974 |        -74.1083 |        -137.411 |            -71.7394 |            -77.7154 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:49:57,169 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.30923 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-353.17345210786704,num_env_steps_sampled_lifetime=400000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000099)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7920x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000099)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:49:57 (running for 00:09:00.36)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    100 |          527.578 | 400000 |          -353.173 |        -73.3511 |        -134.134 |             -69.556 |            -76.1323 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-351.1028626188514,num_env_steps_sampled_lifetime=404000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
== Status ==
Current time: 2025-07-02 02:50:02 (running for 00:09:05.42)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    101 |          532.718 | 404000 |          -351.103 |        -72.6377 |         -135.38 |            -69.6841 |            -73.4016 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000100)


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8080x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000100)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:50:07,174 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.28231 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:50:07 (running for 00:09:10.47)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    101 |          532.718 | 404000 |          -351.103 |        -72.6377 |         -135.38 |            -69.6841 |            -73.4016 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-348.77729033158823,num_env_steps_sampled_lifetime=408000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000101)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8001x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000101)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:50:12 (running for 00:09:15.56)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    102 |          538.112 | 408000 |          -348.777 |        -71.8651 |        -134.086 |              -69.12 |            -73.7057 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-346.3726995215298,num_env_steps_sampled_lifetime=412000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000102)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8071x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000102)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:50:17,179 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.25203 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:50:18 (running for 00:09:20.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    103 |          543.446 | 412000 |          -346.373 |        -71.8249 |        -133.498 |            -67.6649 |            -73.3844 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-346.92578474059906,num_env_steps_sampled_lifetime=416000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000103)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8009x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000103)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:50:23 (running for 00:09:25.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    104 |          548.709 | 416000 |          -346.926 |        -72.3028 |        -135.206 |            -66.1362 |            -73.2804 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-341.2356645899274,num_env_steps_sampled_lifetime=420000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000104)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7971x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000104)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:50:27,184 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.21503 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:50:28 (running for 00:09:30.69)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    105 |          554.112 | 420000 |          -341.236 |         -72.146 |        -132.613 |            -64.6939 |            -71.7827 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-345.00783384202265,num_env_steps_sampled_lifetime=424000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000105)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7964x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000105)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:50:33 (running for 00:09:35.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    106 |          559.623 | 424000 |          -345.008 |        -72.3943 |        -137.553 |            -63.7463 |            -71.3138 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-345.3480834828582,num_env_steps_sampled_lifetime=428000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000106)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8072x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000106)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:50:37,189 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.18509 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:50:38 (running for 00:09:40.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    107 |          564.967 | 428000 |          -345.348 |        -72.3807 |        -137.496 |            -63.6592 |            -71.8122 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-344.345599942206,num_env_steps_sampled_lifetime=432000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000107)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7952x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000107)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:50:43 (running for 00:09:45.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    108 |          570.392 | 432000 |          -344.346 |        -71.9604 |        -138.901 |            -62.7921 |            -70.6918 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-341.94040920608995,num_env_steps_sampled_lifetime=436000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000108)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8016x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000108)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:50:47,194 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.16201 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:50:48 (running for 00:09:50.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    109 |          575.855 | 436000 |           -341.94 |        -70.9861 |        -139.929 |            -62.0841 |            -68.9413 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-344.12715313728273,num_env_steps_sampled_lifetime=440000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000109)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8072x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000109)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:50:53 (running for 00:09:55.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    110 |          581.199 | 440000 |          -344.127 |        -69.7664 |        -142.901 |            -61.3937 |             -70.066 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-339.8222502941062,num_env_steps_sampled_lifetime=444000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[33m(raylet)[0m [2025-07-02 02:50:57,198 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.14481 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000110)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7970x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000110)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:50:58 (running for 00:10:00.93)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    111 |          586.525 | 444000 |          -339.822 |         -69.838 |        -140.751 |            -61.0931 |              -68.14 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-335.9373362477964,num_env_steps_sampled_lifetime=448000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000111)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8030x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000111)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:03 (running for 00:10:05.95)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    112 |          591.838 | 448000 |          -335.937 |        -70.0893 |        -137.846 |            -60.7599 |            -67.2418 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:51:07,203 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.11545 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-335.7232189822139,num_env_steps_sampled_lifetime=452000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000112)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8084x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000112)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:08 (running for 00:10:10.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    113 |          597.174 | 452000 |          -335.723 |        -69.0466 |        -138.107 |            -61.6857 |            -66.8841 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000113)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000113)...


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8100x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:13 (running for 00:10:16.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    114 |          602.122 | 456000 |          -335.707 |        -69.3054 |        -138.443 |            -61.4691 |            -66.4897 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:51:17,208 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.08522 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-332.07992239973487,num_env_steps_sampled_lifetime=460000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000114)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7944x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000114)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:18 (running for 00:10:21.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    115 |          607.406 | 460000 |           -332.08 |         -68.968 |         -139.22 |            -60.4476 |            -63.4441 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:51:23 (running for 00:10:26.18)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    115 |          607.406 | 460000 |           -332.08 |         -68.968 |         -139.22 |            -60.4476 |            -63.4441 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-329.8282537540434,num_env_steps_sampled_lifetime=464000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000115)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7880x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000115)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[33m(raylet)[0m [2025-07-02 02:51:27,214 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.04959 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:51:28 (running for 00:10:31.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    116 |          613.178 | 464000 |          -329.828 |        -68.6058 |        -138.998 |            -59.8847 |            -62.3402 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-331.6426579365701,num_env_steps_sampled_lifetime=468000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000116)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8096x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000116)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:33 (running for 00:10:36.29)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    117 |          618.814 | 468000 |          -331.643 |        -67.3364 |        -141.503 |            -60.2501 |             -62.553 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-326.99650128513355,num_env_steps_sampled_lifetime=472000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000117)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8024x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000117)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:51:37,219 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 8.01978 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:51:38 (running for 00:10:41.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    118 |          624.419 | 472000 |          -326.997 |        -66.9165 |        -139.166 |            -59.9475 |            -60.9662 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-325.6504104257972,num_env_steps_sampled_lifetime=476000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000118)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8016x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000118)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:43 (running for 00:10:46.45)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    119 |          629.782 | 476000 |           -325.65 |        -66.4743 |        -139.564 |            -58.6589 |            -60.9531 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-322.90296344605355,num_env_steps_sampled_lifetime=480000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000119)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000119)...
[36m(MultiAgentEnvRunner pid=3491784)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7923x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:51:47,223 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.99494 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:51:48 (running for 00:10:51.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    120 |          635.559 | 480000 |          -322.903 |        -67.0033 |        -134.958 |             -59.715 |            -61.2267 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-323.95829134188637,num_env_steps_sampled_lifetime=484000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000120)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8074x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000120)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:54 (running for 00:10:56.61)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    121 |          641.331 | 484000 |          -323.958 |        -67.2019 |        -138.506 |            -58.1358 |            -60.1147 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:51:57,228 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.9789 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-324.758020877574,num_env_steps_sampled_lifetime=488000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000121)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8035x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000121)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:51:59 (running for 00:11:01.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    122 |          647.309 | 488000 |          -324.758 |        -66.8745 |        -139.581 |            -58.9306 |             -59.372 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:52:04 (running for 00:11:06.76)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    122 |          647.309 | 488000 |          -324.758 |        -66.8745 |        -139.581 |            -58.9306 |             -59.372 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-323.6986967423574,num_env_steps_sampled_lifetime=492000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000122)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8074x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000122)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:52:07,234 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.94205 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:52:09 (running for 00:11:11.79)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    123 |          653.356 | 492000 |          -323.699 |        -67.2113 |        -140.371 |            -58.4453 |             -57.671 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-326.7558519193856,num_env_steps_sampled_lifetime=496000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000123)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7974x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000123)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:52:14 (running for 00:11:16.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    124 |          659.181 | 496000 |          -326.756 |        -67.0664 |        -142.343 |            -59.3728 |            -57.9739 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-325.9897920252049,num_env_steps_sampled_lifetime=500000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000124)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7984x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000124)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:52:17,239 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.91705 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:52:19 (running for 00:11:21.83)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    125 |           665.09 | 500000 |           -325.99 |         -66.819 |        -140.795 |            -60.0121 |            -58.3639 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-326.171061065369,num_env_steps_sampled_lifetime=504000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000125)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8048x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000125)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:52:24 (running for 00:11:26.91)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    126 |          670.755 | 504000 |          -326.171 |        -67.1004 |        -141.515 |            -58.6919 |            -58.8635 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:52:27,244 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.9011 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-328.0469297787164,num_env_steps_sampled_lifetime=508000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000126)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8007x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000126)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[36m(MultiAgentEnvRunner pid=3491784)[0m warning: velocites provided but types or ids not provided, returning only distance and vel
[36m(MultiAgentEnvRunner pid=3491784)[0m ocity values
== Status ==
Current time: 2025-07-02 02:52:29 (running for 00:11:32.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    127 |          676.457 | 508000 |          -328.047 |        -67.2063 |        -143.163 |            -59.0226 |            -58.6552 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-326.7728888834506,num_env_steps_sampled_lifetime=512000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000127)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8024x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000127)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:52:34 (running for 00:11:37.02)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    128 |          682.128 | 512000 |          -326.773 |        -65.7998 |        -143.121 |            -59.3891 |             -58.463 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:52:37,249 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.86409 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-328.3141334653017,num_env_steps_sampled_lifetime=516000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000128)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8013x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000128)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:52:39 (running for 00:11:42.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    129 |          687.617 | 516000 |          -328.314 |         -65.124 |        -147.008 |            -58.2679 |             -57.914 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:52:44 (running for 00:11:47.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    129 |          687.617 | 516000 |          -328.314 |         -65.124 |        -147.008 |            -58.2679 |             -57.914 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-325.9569644854179,num_env_steps_sampled_lifetime=520000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000129)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8019x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000129)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:52:47,254 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.83414 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:52:49 (running for 00:11:52.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    130 |          693.215 | 520000 |          -325.957 |        -64.5175 |        -146.549 |            -57.6983 |            -57.1919 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-319.3977243438759,num_env_steps_sampled_lifetime=524000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000130)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8048x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000130)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:52:54 (running for 00:11:57.25)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    131 |          699.115 | 524000 |          -319.398 |        -63.2204 |        -143.977 |            -55.7565 |            -56.4437 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-319.7604091737499,num_env_steps_sampled_lifetime=528000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000131)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7904x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000131)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:52:57,259 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.8108 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:52:59 (running for 00:12:02.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    132 |          705.015 | 528000 |           -319.76 |         -63.286 |        -145.079 |            -55.9527 |            -55.4428 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-318.09872297828326,num_env_steps_sampled_lifetime=532000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000132)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8126x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000132)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:53:04 (running for 00:12:07.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    133 |          710.927 | 532000 |          -318.099 |        -61.9593 |         -146.03 |            -55.2527 |            -54.8566 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:53:07,263 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.79452 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-315.07438669465444,num_env_steps_sampled_lifetime=536000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000133)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7901x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000133)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:53:09 (running for 00:12:12.44)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    134 |          717.007 | 536000 |          -315.074 |         -62.702 |        -143.114 |            -53.5701 |            -55.6889 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:53:14 (running for 00:12:17.53)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    134 |          717.007 | 536000 |          -315.074 |         -62.702 |        -143.114 |            -53.5701 |            -55.6889 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-314.95019407802,num_env_steps_sampled_lifetime=540000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_init
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000134)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8029x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000134)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:53:17,268 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.75737 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:53:20 (running for 00:12:22.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    135 |          723.303 | 540000 |           -314.95 |        -63.4413 |        -144.517 |            -51.8996 |            -55.0925 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-319.6315237818971,num_env_steps_sampled_lifetime=544000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000135)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8040x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000135)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:53:25 (running for 00:12:27.61)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    136 |            729.3 | 544000 |          -319.632 |        -62.7499 |        -151.446 |            -50.6884 |            -54.7474 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-323.4433746072207,num_env_steps_sampled_lifetime=548000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[33m(raylet)[0m [2025-07-02 02:53:27,276 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.74968 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000136)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8072x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000136)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:53:30 (running for 00:12:32.66)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    137 |          735.252 | 548000 |          -323.443 |        -62.7935 |        -155.796 |            -50.2757 |            -54.5782 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-322.0286015878755,num_env_steps_sampled_lifetime=552000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000137)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8000x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000137)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:53:35 (running for 00:12:37.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    138 |          741.037 | 552000 |          -322.029 |        -63.8899 |        -156.552 |            -48.9666 |            -52.6197 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:53:37,281 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.71807 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-322.19987667884476,num_env_steps_sampled_lifetime=556000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000138)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7996x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000138)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:53:40 (running for 00:12:42.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    139 |          746.737 | 556000 |            -322.2 |        -62.5066 |        -159.096 |            -48.8062 |             -51.791 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-316.89753457180103,num_env_steps_sampled_lifetime=560000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000139)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8068x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000139)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:53:45 (running for 00:12:47.85)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    140 |          752.382 | 560000 |          -316.898 |         -61.933 |        -155.268 |            -47.5582 |            -52.1388 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:53:47,286 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.68119 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-315.35429631354606,num_env_steps_sampled_lifetime=564000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000140)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7992x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000140)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:53:50 (running for 00:12:52.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    141 |          757.699 | 564000 |          -315.354 |        -61.9331 |         -154.92 |            -47.1879 |            -51.3132 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:53:55 (running for 00:12:58.00)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    141 |          757.699 | 564000 |          -315.354 |        -61.9331 |         -154.92 |            -47.1879 |            -51.3132 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-312.7950660047563,num_env_steps_sampled_lifetime=568000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000141)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8072x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000141)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:53:57,290 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.65104 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:54:00 (running for 00:13:03.04)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    142 |          763.162 | 568000 |          -312.795 |         -62.392 |        -154.697 |             -45.852 |             -49.854 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-316.1547047646575,num_env_steps_sampled_lifetime=572000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000142)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7904x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000142)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:54:05 (running for 00:13:08.10)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    143 |          768.402 | 572000 |          -316.155 |        -63.3231 |        -158.898 |            -45.0955 |            -48.8385 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-316.9576336145717,num_env_steps_sampled_lifetime=576000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000143)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8056x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000143)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:54:07,295 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.62749 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:54:10 (running for 00:13:13.12)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    144 |          774.032 | 576000 |          -316.958 |        -63.4411 |        -161.699 |            -43.8034 |            -48.0143 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-318.01653505404835,num_env_steps_sampled_lifetime=580000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000144)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7944x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000144)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:54:15 (running for 00:13:18.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    145 |          779.758 | 580000 |          -318.017 |        -62.9471 |        -164.754 |            -42.2899 |            -48.0261 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:54:17,300 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.61139 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-316.63001457543794,num_env_steps_sampled_lifetime=584000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000145)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8136x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000145)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:54:20 (running for 00:13:23.26)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    146 |          785.367 | 584000 |           -316.63 |        -62.6708 |        -161.894 |            -43.1912 |            -48.8738 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-312.4023697393102,num_env_steps_sampled_lifetime=588000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000146)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7952x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000146)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:54:25 (running for 00:13:28.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    147 |          791.183 | 588000 |          -312.402 |        -62.9553 |        -159.991 |            -41.5026 |            -47.9532 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:54:27,305 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.57437 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-312.6798320866357,num_env_steps_sampled_lifetime=592000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000147)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7973x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000147)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:54:30 (running for 00:13:33.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    148 |          796.905 | 592000 |           -312.68 |        -62.5122 |         -161.08 |            -41.6941 |            -47.3937 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-312.4754099937626,num_env_steps_sampled_lifetime=596000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000148)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8083x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000148)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:54:35 (running for 00:13:38.39)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    149 |          802.539 | 596000 |          -312.475 |        -61.8679 |        -161.939 |            -41.4837 |            -47.1844 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:54:37,310 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.54403 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


[36m(MultiAgentEnvRunner pid=3491785)[0m warning:
[36m(MultiAgentEnvRunner pid=3491785)[0m  velocites provided but types or ids not provided, returning only distance and velocity values
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-318.81937413673506,num_env_steps_sampled_lifetime=600000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000149)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7983x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000149)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:54:40 (running for 00:13:43.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    150 |          807.955 | 600000 |          -318.819 |        -62.4739 |        -168.067 |            -41.0043 |             -47.274 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:54:45 (running for 00:13:48.54)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    150 |          807.955 | 600000 |          -318.819 |        -62.4739 |        -168.067 |            -41.0043 |             -47.274 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-314.65989379966334,num_env_steps_sampled_lifetime=604000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000150)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8064x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000150)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:54:47,315 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.52207 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:54:50 (running for 00:13:53.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    151 |          813.595 | 604000 |           -314.66 |        -61.5474 |        -165.942 |             -40.258 |            -46.9122 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-314.34483322404157,num_env_steps_sampled_lifetime=608000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000151)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8008x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000151)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m war
[36m(MultiAgentEnvRunner pid=3491785)[0m ning: velocites provided but types or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-02 02:54:55 (running for 00:13:58.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    152 |          818.901 | 608000 |          -314.345 |        -61.3773 |        -167.963 |            -38.4185 |            -46.5857 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-314.0177346477794,num_env_steps_sampled_lifetime=612000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000152)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8023x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000152)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:54:57,320 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.49028 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:55:01 (running for 00:14:03.65)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    153 |          824.071 | 612000 |          -314.018 |        -61.9973 |        -168.368 |            -37.7244 |             -45.928 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-314.08079953444593,num_env_steps_sampled_lifetime=616000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000153)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8006x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000153)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:06 (running for 00:14:08.75)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    154 |           829.45 | 616000 |          -314.081 |        -61.4652 |        -168.517 |            -39.2609 |            -44.8381 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:55:07,325 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.47419 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-311.57399119059903,num_env_steps_sampled_lifetime=620000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000154)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8066x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000154)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:11 (running for 00:14:13.77)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    155 |          834.897 | 620000 |          -311.574 |        -61.2971 |        -167.186 |            -38.5021 |            -44.5891 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-311.62884203476153,num_env_steps_sampled_lifetime=624000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000155)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7917x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000155)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:16 (running for 00:14:18.84)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    156 |          840.535 | 624000 |          -311.629 |        -60.7596 |        -166.675 |            -39.3402 |            -44.8544 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:55:17,330 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.44359 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-313.6422219742654,num_env_steps_sampled_lifetime=628000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000156)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7993x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000156)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:21 (running for 00:14:23.92)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    157 |          846.252 | 628000 |          -313.642 |        -60.2871 |        -170.111 |            -38.3044 |            -44.9396 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-317.82577118681746,num_env_steps_sampled_lifetime=632000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000157)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8090x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000157)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:26 (running for 00:14:28.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    158 |          851.792 | 632000 |          -317.826 |        -61.6943 |        -173.964 |            -36.9769 |            -45.1901 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:55:27,335 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.40668 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-321.7941328937714,num_env_steps_sampled_lifetime=636000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000158)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7986x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000158)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:31 (running for 00:14:34.06)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    159 |          857.394 | 636000 |          -321.794 |        -61.6824 |        -177.799 |            -37.3595 |            -44.9531 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


== Status ==
Current time: 2025-07-02 02:55:36 (running for 00:14:39.07)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    159 |          857.394 | 636000 |          -321.794 |        -61.6824 |        -177.799 |            -37.3595 |            -44.9531 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-321.9823703484553,num_env_steps_sampled_lifetime=640000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000159)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7989x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000159)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:55:37,341 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.38405 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:55:41 (running for 00:14:44.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    160 |          863.624 | 640000 |          -321.982 |        -62.1277 |        -176.698 |            -37.8113 |            -45.3453 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-319.1627229711456,num_env_steps_sampled_lifetime=644000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000160)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7995x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000160)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:46 (running for 00:14:49.23)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    161 |          869.255 | 644000 |          -319.163 |        -61.9393 |        -175.697 |             -36.672 |            -44.8541 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:55:47,346 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.36784 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-320.059083180635,num_env_steps_sampled_lifetime=648000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000161)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8094x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000161)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:55:51 (running for 00:14:54.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    162 |          874.972 | 648000 |          -320.059 |        -61.9228 |        -176.687 |            -36.9743 |            -44.4746 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-322.6720279312394,num_env_steps_sampled_lifetime=652000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000162)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8040x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000162)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:55:56 (running for 00:14:59.34)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    163 |           880.77 | 652000 |          -322.672 |         -61.721 |        -178.315 |            -37.4486 |            -45.1874 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:55:57,351 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.33035 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-317.74312639172183,num_env_steps_sampled_lifetime=656000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000163)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7960x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000163)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:56:01 (running for 00:15:04.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    164 |          886.499 | 656000 |          -317.743 |        -62.3481 |        -175.496 |            -35.2497 |            -44.6493 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-322.32622314499355,num_env_steps_sampled_lifetime=660000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000164)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8000x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000164)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:56:06 (running for 00:15:09.38)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    165 |          891.991 | 660000 |          -322.326 |        -62.5651 |        -181.643 |            -34.5025 |            -43.6155 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:56:07,356 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.30031 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-320.7858687884941,num_env_steps_sampled_lifetime=664000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000165)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7974x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000165)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
== Status ==
Current time: 2025-07-02 02:56:11 (running for 00:15:14.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    166 |          897.509 | 664000 |          -320.786 |        -62.1892 |         -180.25 |            -34.9154 |            -43.4317 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
[36m(MultiAgentEnvRunner pid=3491784)[0m
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-321.45042597188484,num_env_steps_sampled_lifetime=668000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000166)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8018x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000166)...
== Status ==
Current time: 2025-07-02 02:56:16 (running for 00:15:19.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    167 |          903.092 | 668000 |           -321.45 |        -61.9003 |        -180.729 |            -34.3135 |            -44.5071 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:56:17,361 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.27655 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


[36m(MultiAgentEnvRunner pid=3491784)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:56:21 (running for 00:15:24.52)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    167 |          903.092 | 668000 |           -321.45 |        -61.9003 |        -180.729 |            -34.3135 |            -44.5071 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-319.988252553344,num_env_steps_sampled_lifetime=672000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_ini
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000167)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8105x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000167)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m warning: velocites provided but ty
[36m(MultiAgentEnvRunner pid=3491784)[0m pes or ids not provided, returning only distance and velocity values
== Status ==
Current time: 2025-07-02 02:56:26 (running for 00:15:29.57)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    168 |          908.322 | 672000 |          -319.988 |         -60.402 |        -180.755 |            -33.3154 |            -45.5154 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:56:27,366 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.2604 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-320.6912039762065,num_env_steps_sampled_lifetime=676000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000168)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8037x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000168)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and
[36m(MultiAgentEnvRunner pid=3491785)[0m velocity values
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:56:32 (running for 00:15:34.62)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    169 |          913.697 | 676000 |          -320.691 |        -60.1196 |        -181.586 |            -34.4067 |            -44.5793 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-319.36815624592583,num_env_steps_sampled_lifetime=680000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000169)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7928x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000169)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:56:37 (running for 00:15:39.68)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    170 |          919.229 | 680000 |          -319.368 |        -59.6783 |        -179.883 |            -34.6635 |            -45.1438 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:56:37,371 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.22976 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-316.01694606818876,num_env_steps_sampled_lifetime=684000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000170)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8075x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000170)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:56:42 (running for 00:15:44.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    171 |          924.568 | 684000 |          -316.017 |        -60.2082 |        -177.795 |            -34.9711 |            -43.0422 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-316.16708031745435,num_env_steps_sampled_lifetime=688000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000171)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8005x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000171)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:56:47 (running for 00:15:49.72)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    172 |          929.961 | 688000 |          -316.167 |        -59.8039 |        -177.004 |            -36.3834 |            -42.9757 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:56:47,376 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.19285 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-314.2297427029384,num_env_steps_sampled_lifetime=692000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000172)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8000x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000172)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:56:52 (running for 00:15:54.78)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    173 |          935.443 | 692000 |           -314.23 |        -60.1989 |        -175.791 |            -34.4604 |            -43.7793 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-313.7723893385962,num_env_steps_sampled_lifetime=696000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000173)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8064x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000173)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:56:57 (running for 00:15:59.87)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    174 |          940.897 | 696000 |          -313.772 |        -60.2192 |        -178.143 |            -32.6039 |            -42.8063 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:56:57,380 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.16232 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-309.41629199466206,num_env_steps_sampled_lifetime=700000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000174)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7950x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000174)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:57:02 (running for 00:16:04.96)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    175 |          946.214 | 700000 |          -309.416 |        -60.1742 |        -174.148 |            -32.8204 |             -42.274 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-311.5959479469066,num_env_steps_sampled_lifetime=704000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000175)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8002x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000175)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:57:07 (running for 00:16:09.97)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    176 |          951.177 | 704000 |          -311.596 |        -59.9139 |        -176.167 |            -32.5126 |             -43.002 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:57:07,385 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.13197 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-307.30918019701863,num_env_steps_sampled_lifetime=708000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000176)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8063x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000176)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:57:12 (running for 00:16:14.99)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    177 |          956.429 | 708000 |          -307.309 |        -59.3974 |        -173.672 |            -32.5592 |            -41.6809 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-309.2388041147043,num_env_steps_sampled_lifetime=712000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000177)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7977x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000177)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
[33m(raylet)[0m [2025-07-02 02:57:17,390 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.10851 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:57:17 (running for 00:16:20.04)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    178 |          961.732 | 712000 |          -309.239 |        -59.7936 |        -174.547 |            -34.2201 |             -40.678 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-306.29622522582184,num_env_steps_sampled_lifetime=716000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000178)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8040x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000178)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:57:22 (running for 00:16:25.08)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    179 |          967.505 | 716000 |          -306.296 |        -59.5383 |        -172.841 |            -33.1154 |            -40.8017 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-311.2336871351039,num_env_steps_sampled_lifetime=720000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[33m(raylet)[0m [2025-07-02 02:57:27,395 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.09294 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000179)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7958x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000179)...
== Status ==
Current time: 2025-07-02 02:57:27 (running for 00:16:30.15)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    180 |          973.021 | 720000 |          -311.234 |        -59.9845 |        -177.053 |            -33.9271 |            -40.2688 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000180)


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8026x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000180)...
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:57:32 (running for 00:16:35.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    181 |          977.961 | 724000 |          -314.168 |        -61.4992 |        -179.543 |            -33.2344 |            -39.8917 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:57:37,400 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.06336 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


== Status ==
Current time: 2025-07-02 02:57:37 (running for 00:16:40.16)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    181 |          977.961 | 724000 |          -314.168 |        -61.4992 |        -179.543 |            -33.2344 |            -39.8917 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-313.7907375604173,num_env_steps_sampled_lifetime=728000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000181)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8120x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000181)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:57:42 (running for 00:16:45.17)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    182 |          983.509 | 728000 |          -313.791 |        -61.6056 |        -178.746 |            -34.1347 |            -39.3045 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-314.1703251601561,num_env_steps_sampled_lifetime=732000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000182)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8024x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000182)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:57:47,405 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 7.0263 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:57:47 (running for 00:16:50.20)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    183 |          989.471 | 732000 |           -314.17 |        -61.4882 |        -178.992 |             -34.526 |            -39.1639 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-316.6751206905574,num_env_steps_sampled_lifetime=736000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000183)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7928x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000183)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491784)[0m
== Status ==
Current time: 2025-07-02 02:57:52 (running for 00:16:55.28)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    184 |           995.21 | 736000 |          -316.675 |        -61.6568 |        -182.049 |            -33.9843 |            -38.9855 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-315.8568377436706,num_env_steps_sampled_lifetime=740000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000184)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8024x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000184)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:57:57,410 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.99607 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:57:57 (running for 00:17:00.30)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    185 |           1000.9 | 740000 |          -315.857 |        -61.2809 |        -183.922 |            -33.4201 |            -37.2336 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-315.5209622722818,num_env_steps_sampled_lifetime=744000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000185)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7990x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000185)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:58:02 (running for 00:17:05.35)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    186 |          1006.19 | 744000 |          -315.521 |        -61.5478 |        -183.029 |            -33.5223 |            -37.4219 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-311.5599751753101,num_env_steps_sampled_lifetime=748000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000186)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8013x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000186)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:58:07,415 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.97246 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:58:07 (running for 00:17:10.46)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    187 |          1011.37 | 748000 |           -311.56 |        -61.6731 |        -180.559 |            -33.1887 |            -36.1395 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-306.08968352920607,num_env_steps_sampled_lifetime=752000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000187)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8045x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000187)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:58:12 (running for 00:17:15.50)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    188 |          1016.64 | 752000 |           -306.09 |        -61.2809 |        -174.652 |            -34.0119 |            -36.1447 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000188)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000188)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8280x across cluster][0m
[33m(raylet)[0m [2025-07-02 02:58:17,419 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.94231 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:58:17 (running for 00:17:20.58)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    189 |           1021.5 | 756000 |          -306.854 |        -60.8667 |        -177.113 |            -33.3407 |            -35.5335 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-305.1081734482199,num_env_steps_sampled_lifetime=760000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000189)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7840x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000189)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:58:22 (running for 00:17:25.59)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    190 |          1026.73 | 760000 |          -305.108 |        -60.8524 |        -174.324 |            -33.9483 |             -35.983 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-308.8155521944073,num_env_steps_sampled_lifetime=764000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000190)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7886x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000190)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:58:27,424 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.91217 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:58:28 (running for 00:17:30.69)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    191 |          1031.89 | 764000 |          -308.816 |        -60.9886 |        -177.933 |            -33.5536 |            -36.3405 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000191)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000191)... Done. 0.0s


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8274x across cluster][0m
== Status ==
Current time: 2025-07-02 02:58:33 (running for 00:17:35.70)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    192 |          1036.74 | 768000 |          -310.391 |        -61.4117 |        -179.053 |            -34.5142 |            -35.4117 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-310.6941746754263,num_env_steps_sampled_lifetime=772000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000192)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7888x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000192)... Done. 0.0s
[33m(raylet)[0m [2025-07-02 02:58:37,429 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.8823 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:58:38 (running for 00:17:40.86)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    193 |          1042.06 | 772000 |          -310.694 |        -62.7448 |        -178.255 |             -34.587 |            -35.1076 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only dis
[36m(MultiAgentEnvRunner pid=3491785)[0m tance and velocity values
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-309.99875307680355,num_env_steps_sampled_lifetime=776000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000193)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8023x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000193)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:58:43 (running for 00:17:45.89)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    194 |          1047.32 | 776000 |          -309.999 |        -63.1715 |        -177.346 |            -34.6465 |            -34.8344 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:58:47,434 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.86608 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-312.0129616271788,num_env_steps_sampled_lifetime=780000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000194)
[36m(MultiAgentEnvRunner pid=3491784)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 7875x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000194)...
[36m(_WandbLoggingActor pid=3492003)[0m Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:58:48 (running for 00:17:50.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    195 |          1052.47 | 780000 |          -312.013 |        -64.0178 |        -180.596 |             -33.524 |            -33.8751 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-315.14428736668697,num_env_steps_sampled_lifetime=784000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_i
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000195)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8085x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000195)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:58:53 (running for 00:17:55.98)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    196 |           1057.7 | 784000 |          -315.144 |         -64.112 |        -185.478 |            -30.7988 |            -34.7555 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[33m(raylet)[0m [2025-07-02 02:58:57,439 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.83537 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-318.4351512407607,num_env_steps_sampled_lifetime=788000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000196)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8008x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000196)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:58:58 (running for 00:18:01.11)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    197 |             1063 | 788000 |          -318.435 |        -63.4682 |        -189.835 |            -30.3748 |            -34.7575 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-320.0350158157768,num_env_steps_sampled_lifetime=792000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000197)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8006x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000197)... Done. 0.0s
== Status ==
Current time: 2025-07-02 02:59:03 (running for 00:18:06.14)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    198 |          1067.96 | 792000 |          -320.035 |        -62.9824 |        -188.542 |            -33.3368 |            -35.1738 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


[36m(MultiAgentEnvRunner pid=3491785)[0m
[33m(raylet)[0m [2025-07-02 02:59:07,444 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.80481 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
== Status ==
Current time: 2025-07-02 02:59:08 (running for 00:18:11.24)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    198 |          1067.96 | 792000 |          -320.035 |        -62.9824 |        -188.542 |            -33.3368 |            -35.1738 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-321.3707946920627,num_env_steps_sampled_lifetime=796000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000198)
[36m(MultiAgentEnvRunner pid=3491785)[0m warning: velocites provided but types or ids not provided, returning only distance and velocity values[32m [repeated 8002x across cluster][0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000198)... Done. 0.0s
[36m(MultiAgentEnvRunner pid=3491785)[0m
== Status ==
Current time: 2025-07-02 02:59:13 (running for 00:18:16.32)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 RUNNING)
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status   | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | RUNNING  | 192.168.0.25:3491689 |    199 |          1073.24 | 796000 |          -321.371 |        -62.9109 |        -189.656 |            -34.4295 |            -34.3747 |
+---------------------+----------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+


Trial PPO_env_8b84f_00000 reported env_runners/episode_return_mean=-319.3262257165216,num_env_steps_sampled_lifetime=800000.0,env_runners/episode_len_mean=2000.0 with parameters={'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'env', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 2, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'SYNC', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': None, 'train_batch_size': 4000, 'num_epochs': 30, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_in
[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=3491689)[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000199)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-07-02_02-40-57/PPO_env_8b84f_00000_0_2025-07-02_02-40-57/checkpoint_000199)... Done. 0.0s
2025-07-02 02:59:14,000	INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-07-02_02-40-57' in 0.0943s.
== Status ==
Current time: 2025-07-02 02:59:14 (running for 00:18:16.60)
Using FIFO scheduling algorithm.
Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)
Result logdir: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919/artifacts/2025-07-02_02-40-57/PPO_2025-07-02_02-40-57/driver_artifacts
Number of trials: 1/1 (1 TERMINATED)
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
| Trial name          | status     | loc                  |   iter |   total time (s) |     ts |   combined return |   return prey_0 |   return prey_1 |   return predator_0 |   return predator_1 |
|---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------|
| PPO_env_8b84f_00000 | TERMINATED | 192.168.0.25:3491689 |    200 |          1078.39 | 800000 |          -319.326 |        -62.6587 |        -189.824 |            -33.7726 |            -33.0709 |
+---------------------+------------+----------------------+--------+------------------+--------+-------------------+-----------------+-----------------+---------------------+---------------------+
[36m(_WandbLoggingActor pid=3492003)[0m wandb: uploading artifact checkpoint_PPO_env_8b84f_00000
[33m(raylet)[0m [2025-07-02 02:59:17,449 E 3490193 3490223] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-07-02_02-40-56_351449_3489919 is over 95% full, available space: 6.76791 GB; capacity: 456.175 GB. Object creation will fail if spilling is required.
[36m(_WandbLoggingActor pid=3492003)[0m wandb:
2025-07-02 02:59:18,161	INFO tune.py:1041 -- Total run time: 1100.77 seconds (1096.51 seconds for the tuning loop).


ËÆ≠ÁªÉÂÆåÊàê
[0m
[36m(_WandbLoggingActor pid=3492003)[0m wandb:
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Run history:
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    env_runners/agent_steps/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    env_runners/agent_steps/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/agent_steps/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/agent_steps/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  env_runners/connector_pipeline_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           env_runners/env_reset_timer ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            env_runners/env_step_timer ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñá‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ‚ñÅ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 env_runners/episode_duration_sec_mean ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           env_runners/episode_len_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                          env_runners/episode_len_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           env_runners/episode_len_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/episode_return_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                       env_runners/episode_return_mean ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/episode_return_min ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñà‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÜ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñÅ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     env_runners/num_env_steps_sampled ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                              env_runners/num_episodes ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     env_runners/num_episodes_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  env_runners/rlmodule_inference_timer ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                    env_runners/sample ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     env_runners/time_between_sampling ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            env_runners/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                   fault_tolerance/num_healthy_workers ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                              iterations_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_0/entropy ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/predator_0/mean_kl_loss ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                       learners/predator_0/policy_loss ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÑ‚ñá
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/predator_0/total_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÜ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñá
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  learners/predator_0/vf_explained_var ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñà‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñà‚ñÉ‚ñÜ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_0/vf_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/predator_0/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_1/entropy ‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÜ‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/predator_1/mean_kl_loss ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                       learners/predator_1/policy_loss ‚ñÇ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñà‚ñÜ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/predator_1/total_loss ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñà‚ñà‚ñà‚ñÑ‚ñÜ‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñÅ‚ñÖ‚ñÖ‚ñá
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  learners/predator_1/vf_explained_var ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÅ‚ñÖ‚ñÜ‚ñÇ‚ñá‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_1/vf_loss ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ‚ñÑ‚ñÜ‚ñá‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/predator_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_0/entropy ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÖ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                          learners/prey_0/mean_kl_loss ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÅ‚ñÖ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_0/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_0/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/prey_0/policy_loss ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñá‚ñÉ‚ñà‚ñá‚ñÖ‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñà‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            learners/prey_0/total_loss ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÅ‚ñá‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÇ‚ñÇ‚ñÜ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/prey_0/vf_explained_var ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñÇ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_0/vf_loss ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/prey_0/weights_seq_no ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÇ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_1/entropy ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñá‚ñÅ‚ñÅ‚ñá‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                          learners/prey_1/mean_kl_loss ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_1/num_module_steps_trained ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_1/num_trainable_parameters ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/prey_1/policy_loss ‚ñà‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñÅ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            learners/prey_1/total_loss ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÖ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/prey_1/vf_explained_var ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÉ‚ñÖ‚ñÇ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_1/vf_loss ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñÇ‚ñÖ‚ñà‚ñÇ‚ñà‚ñá‚ñÑ‚ñà‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÅ‚ñÜ‚ñÖ‚ñÉ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/prey_1/weights_seq_no ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        num_env_steps_sampled_lifetime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 num_training_step_calls_per_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                 perf/cpu_util_percent ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÑ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                 perf/ram_util_percent ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                    time_since_restore ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                      time_this_iter_s ‚ñÑ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñà‚ñá‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                          time_total_s ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      timers/env_runner_sampling_timer ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           timers/learner_update_timer ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            timers/restore_env_runners ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           timers/synch_env_connectors ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                  timers/synch_weights ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                             timers/training_iteration ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                  timers/training_step ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                             timestamp ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                    training_iteration ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
[36m(_WandbLoggingActor pid=3492003)[0m wandb:
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Run summary:
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 -33.7726
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 -33.0709
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 -62.65867
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 -189.82406
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    env_runners/agent_steps/predator_0 500
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    env_runners/agent_steps/predator_1 500
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/agent_steps/prey_0 500
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/agent_steps/prey_1 500
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.00038
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           env_runners/env_reset_timer 0.0042
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            env_runners/env_step_timer 0.00047
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00013
[36m(_WandbLoggingActor pid=3492003)[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 3e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 1881.0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 1881.0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 env_runners/episode_duration_sec_mean 2.41531
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           env_runners/episode_len_max 2000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                          env_runners/episode_len_mean 2000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           env_runners/episode_len_min 2000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/episode_return_max -157.84658
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                       env_runners/episode_return_mean -319.32623
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        env_runners/episode_return_min -421.18305
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 -33.7726
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 -33.0709
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 -62.65867
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 -189.82406
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00025
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 0.0001
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 3e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 200000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 200400
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 200400
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 200400
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 800000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 1048.86661
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                              env_runners/num_episodes 2
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     env_runners/num_episodes_lifetime 400
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 1000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1002
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1002
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1002
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 200000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 200400
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 200400
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 200400
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.00013
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                    env_runners/sample 2.51876
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     env_runners/time_between_sampling 3.25926
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 3e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 3e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 7e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            env_runners/weights_seq_no 199
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                              iterations_since_restore 200
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.0834
[36m(_WandbLoggingActor pid=3492003)[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03608
[36m(_WandbLoggingActor pid=3492003)[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 8e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.00268
[36m(_WandbLoggingActor pid=3492003)[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 3e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.002
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.02929
[36m(_WandbLoggingActor pid=3492003)[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.01146
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.0015
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 940000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 188000000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 350921.4557
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 120320
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 24064000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 2013185.42106
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 1975890.07227
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 578580
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 0.9742
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_0/entropy -0.43703
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 10.86837
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.015
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 11229.25211
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                       learners/predator_0/policy_loss 0.01147
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/predator_0/total_loss 0.04802
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  learners/predator_0/vf_explained_var 0.12478
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_0/vf_loss 4.38615
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 49.31016
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/predator_0/weights_seq_no 200
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 0.9742
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_1/entropy -0.50512
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 21.38189
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.01671
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 11229.3807
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/predator_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                       learners/predator_1/policy_loss 0.04066
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/predator_1/total_loss 0.08884
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                  learners/predator_1/vf_explained_var 0.12779
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/predator_1/vf_loss 6.38032
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 84.70052
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/predator_1/weights_seq_no 200
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 1.02631
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_0/entropy -0.9473
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 9.39077
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.01851
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_0/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 11229.16052
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_0/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/prey_0/policy_loss -0.13153
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            learners/prey_0/total_loss -0.09138
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/prey_0/vf_explained_var -0.10748
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_0/vf_loss 4.23016
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 20.561
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/prey_0/weights_seq_no 200
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 0.31245
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_1/entropy 5.97213
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 15.08731
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.026
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_1/num_module_steps_trained 30080
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 6016000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 11229.32169
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                              learners/prey_1/num_trainable_parameters 144645
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           learners/prey_1/policy_loss -0.03136
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            learners/prey_1/total_loss 0.01518
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      learners/prey_1/vf_explained_var -0.37989
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                               learners/prey_1/vf_loss 8.22533
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 446.75024
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        learners/prey_1/weights_seq_no 200
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                        num_env_steps_sampled_lifetime 800000
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                 num_training_step_calls_per_iteration 1
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                 perf/cpu_util_percent 12.0375
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                 perf/ram_util_percent 70.8125
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                    time_since_restore 1078.39152
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                      time_this_iter_s 5.14731
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                          time_total_s 1078.39152
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                      timers/env_runner_sampling_timer 2.55443
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           timers/learner_update_timer 2.93071
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                            timers/restore_env_runners 2e-05
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                           timers/synch_env_connectors 0.00162
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                  timers/synch_weights 0.00352
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                             timers/training_iteration 5.48949
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                  timers/training_step 5.48911
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                             timestamp 1751392753
[36m(_WandbLoggingActor pid=3492003)[0m wandb:                                                                                    training_iteration 200
[36m(_WandbLoggingActor pid=3492003)[0m wandb:
[36m(_WandbLoggingActor pid=3492003)[0m wandb: üöÄ View run PPO_env_8b84f_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/8b84f_00000
[36m(_WandbLoggingActor pid=3492003)[0m wandb: ‚≠êÔ∏è View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Synced 5 W&B file(s), 0 media file(s), 1427 artifact file(s) and 0 other file(s)
[36m(_WandbLoggingActor pid=3492003)[0m wandb: Find logs at: ./wandb/run-20250702_024105-8b84f_00000/logs
