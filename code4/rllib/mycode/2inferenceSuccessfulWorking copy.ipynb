{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b212c65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-02 17:17:17,784\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-08-02 17:17:18,067\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from ray.rllib.models.torch.torch_distributions import TorchDiagGaussian\n",
    "from ray.tune.result import TRAINING_ITERATION\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib.core import (\n",
    "    COMPONENT_LEARNER,\n",
    "    COMPONENT_LEARNER_GROUP,\n",
    "    COMPONENT_RL_MODULE,\n",
    ")\n",
    "from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "from ray.rllib.examples.envs.classes.multi_agent import MultiAgentPendulum\n",
    "from ray.rllib.utils.metrics import (\n",
    "    ENV_RUNNER_RESULTS,\n",
    "    EPISODE_RETURN_MEAN,\n",
    "    NUM_ENV_STEPS_SAMPLED_LIFETIME,\n",
    ")\n",
    "from ray.rllib.utils.numpy import convert_to_numpy\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    check,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "\n",
    "from pettingzoo.sisl import waterworld_v4\n",
    "\n",
    "from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "from ray.rllib.core.rl_module.multi_rl_module import MultiRLModuleSpec\n",
    "from ray.rllib.core.rl_module.rl_module import RLModuleSpec\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tree  # pip install dm_tree\n",
    "\n",
    "from ray.rllib.core import DEFAULT_MODULE_ID\n",
    "from ray.rllib.core.columns import Columns\n",
    "from ray.rllib.core.rl_module.rl_module import RLModule\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.numpy import convert_to_numpy, softmax\n",
    "from ray.rllib.utils.metrics import (\n",
    "    ENV_RUNNER_RESULTS,\n",
    "    EPISODE_RETURN_MEAN,\n",
    ")\n",
    "\n",
    "torch, _ = try_import_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ec5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "# class WandbLoggingCallback(DefaultCallbacks):\n",
    "#     def on_train_result(self, *, algorithm, result, **kwargs):\n",
    "#         # 提取 episode reward env_runners\n",
    "#         print(f\"[DEBUG] result keys: {list(result.keys())}\")\n",
    "#         print(f\"[DEBUG] result keys: {list(result['env_runners'])}\")\n",
    "\n",
    "#         print(\"[DEBUG] on_train_result 被调用\")\n",
    "#         mean_reward = result.get(\"episode_reward_mean\") or result.get(\"hist_stats\", {}).get(\"episode_reward_mean\")\n",
    "\n",
    "#         if mean_reward is not None:\n",
    "#             # Log 到 wandb\n",
    "#             wandb.log({\"episode_reward_mean\": mean_reward, \"training_iteration\": result.get(\"training_iteration\", 0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c240a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ac4a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "import sys\n",
    "sys.argv = [\n",
    "    'notebook_script.py',\n",
    "    '--enable-new-api-stack',\n",
    "    '--num-agents=4',\n",
    "    # 新增参数用于指定predator和prey的数量\n",
    "    '--n-predators=2',\n",
    "    '--wandb-key=fdd7656f474bba144dea1887bcdab534bc7df647',\n",
    "    '--wandb-project=waterworld-v4',\n",
    "    '--n-preys=2', \n",
    "    '--checkpoint-at-end',\n",
    "    '--stop-reward=200.0',\n",
    "    '--checkpoint-freq=1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8c303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = add_rllib_example_script_args(\n",
    "    default_iters=200,\n",
    "    default_timesteps=1000000,\n",
    "    default_reward=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41579dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--num-episodes-during-inference'], dest='num_episodes_during_inference', nargs=None, const=None, default=10, type=<class 'int'>, choices=None, required=False, help='Number of episodes to do inference over (after restoring from a checkpoint).', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加新的参数解析\n",
    "parser.add_argument(\n",
    "    \"--n-predators\",\n",
    "    type=int,\n",
    "    default=2,\n",
    "    help=\"Number of predator agents\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-preys\", \n",
    "    type=int,\n",
    "    default=2,\n",
    "    help=\"Number of prey agents\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use-onnx-for-inference\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to convert the loaded module to ONNX format and then perform \"\n",
    "    \"inference through this ONNX model.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--explore-during-inference\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether the trained policy should use exploration during action \"\n",
    "    \"inference.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num-episodes-during-inference\",\n",
    "    type=int,\n",
    "    default=10,\n",
    "    help=\"Number of episodes to do inference over (after restoring from a checkpoint).\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba78275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数解析完成: n_predators=2, n_preys=2, total_agents=4, algo=PPO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 验证参数\n",
    "assert args.n_predators > 0, \"Must set --n-predators > 0 when running this script!\"\n",
    "assert args.n_preys > 0, \"Must set --n-preys > 0 when running this script!\"\n",
    "assert (\n",
    "    args.enable_new_api_stack\n",
    "), \"Must set --enable-new-api-stack when running this script!\"\n",
    "\n",
    "# 计算总智能体数量\n",
    "total_agents = args.n_predators + args.n_preys\n",
    "print(f\"参数解析完成: n_predators={args.n_predators}, n_preys={args.n_preys}, total_agents={total_agents}, algo={args.algo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0164c6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbqr010817\u001b[0m (\u001b[33mbqr010817-kyushu-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/qrbao/Documents/code4/rllib/mycode/wandb/run-20250802_171727-jhr1ivtk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/jhr1ivtk' target=\"_blank\">fancy-water-259</a></strong> to <a href='https://wandb.ai/bqr010817-kyushu-university/waterworld-v4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bqr010817-kyushu-university/waterworld-v4' target=\"_blank\">https://wandb.ai/bqr010817-kyushu-university/waterworld-v4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/jhr1ivtk' target=\"_blank\">https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/jhr1ivtk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/jhr1ivtk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x78438675a3b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=args.wandb_project, config=vars(args))  # 放在main训练逻辑之前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ede832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 修改环境注册，传递predator和prey的数量\n",
    "register_env(\"env\", lambda _: PettingZooEnv(\n",
    "    waterworld_v4.env(\n",
    "        n_predators=args.n_predators,\n",
    "        n_preys=args.n_preys  # 注意：这里应该是n_preys而不是n_prey\n",
    "    )\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predator_0', 'predator_1', 'prey_0', 'prey_1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建新的policies字典，匹配环境中的agent命名\n",
    "predator_policies = [f\"predator_{i}\" for i in range(args.n_predators)]\n",
    "prey_policies = [f\"prey_{i}\" for i in range(args.n_preys)]\n",
    "all_policies = predator_policies + prey_policies\n",
    "print(all_policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a21dbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建的policies: ['predator_0', 'predator_1', 'prey_0', 'prey_1']\n",
      "创建的RL module specs: ['predator_0', 'predator_1', 'prey_0', 'prey_1']\n"
     ]
    }
   ],
   "source": [
    "# 创建RL module specs字典\n",
    "rl_module_specs = {p: RLModuleSpec() for p in all_policies}\n",
    "print(f\"创建的policies: {list(all_policies)}\")\n",
    "print(f\"创建的RL module specs: {list(rl_module_specs.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772efbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/qrbao/anaconda3/envs/rllib/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "base_config = (\n",
    "    get_trainable_cls(args.algo)\n",
    "    .get_default_config()\n",
    "    .environment(\"env\")\n",
    "    .multi_agent(\n",
    "        # 在新API中，只需要指定policy_mapping_fn\n",
    "        policies=set(all_policies),\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .training(\n",
    "        vf_loss_coeff=0.005,\n",
    "    )\n",
    "    .rl_module(\n",
    "        rl_module_spec=MultiRLModuleSpec(\n",
    "            rl_module_specs=rl_module_specs,\n",
    "        ),\n",
    "        model_config=DefaultModelConfig(vf_share_layers=True),\n",
    "    )\n",
    "    # .callbacks(WandbLoggingCallback)  # ✅ 加入回调\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73f56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 17:17:35,943\tINFO worker.py:1917 -- Started a local Ray instance.\n",
      "2025-08-02 17:17:36,390\tWARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:17:36 (running for 00:00:00.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "+---------------------+----------+-------+\n",
      "| Trial name          | status   | loc   |\n",
      "|---------------------+----------+-------|\n",
      "| PPO_env_25c2d_00000 | PENDING  |       |\n",
      "+---------------------+----------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO pid=324172)\u001b[0m 2025-08-02 17:17:38,479\tWARNING algorithm_config.py:5014 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(MultiAgentEnvRunner pid=324266)\u001b[0m 2025-08-02 17:17:40,733\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=324172)\u001b[0m Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:17:41 (running for 00:00:05.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+\n",
      "| Trial name          | status   | loc                 |\n",
      "|---------------------+----------+---------------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |\n",
      "+---------------------+----------+---------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: WARNING `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Currently logged in as: bqr010817 (bqr010817-kyushu-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Tracking run with wandb version 0.20.1\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/wandb/run-20250802_171743-25c2d_00000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Syncing run PPO_env_25c2d_00000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: 🚀 View run at https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/25c2d_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:17:46 (running for 00:00:10.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+\n",
      "| Trial name          | status   | loc                 |\n",
      "|---------------------+----------+---------------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |\n",
      "+---------------------+----------+---------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>env_runner_group                               </th><th>env_runners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       </th><th>fault_tolerance                                            </th><th>learners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </th><th style=\"text-align: right;\">  num_env_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_training_step_calls_per_iteration</th><th>perf                                                                              </th><th>timers                                                                                                                                                                                                                                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_env_25c2d_00000</td><td>{&#x27;actor_manager_num_outstanding_async_reqs&#x27;: 0}</td><td>{&#x27;env_to_module_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;batch_individual_items&#x27;: np.float64(1.3433776081919112e-05), &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: np.float64(9.578401654835024e-06), &#x27;agent_to_module_mapping&#x27;: np.float64(3.4989810536079796e-06), &#x27;numpy_to_tensor&#x27;: np.float64(2.3793233181814858e-05), &#x27;add_observations_from_episodes_to_batch&#x27;: np.float64(1.8918235243772694e-05), &#x27;add_states_from_episodes_to_batch&#x27;: np.float64(6.430604569865595e-06)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.00011728815027476453)}, &#x27;env_reset_timer&#x27;: np.float64(0.004206390003673732), &#x27;episode_duration_sec_mean&#x27;: 2.4907961133588103, &#x27;num_agent_steps_sampled_lifetime&#x27;: {&#x27;predator_1&#x27;: 37807.0, &#x27;predator_0&#x27;: 37732.0, &#x27;prey_1&#x27;: 35976.0, &#x27;prey_0&#x27;: 32707.0}, &#x27;module_episode_returns_mean&#x27;: {&#x27;predator_1&#x27;: 80.10318804068176, &#x27;predator_0&#x27;: 80.89028911796635, &#x27;prey_1&#x27;: 5.593495632635077, &#x27;prey_0&#x27;: 39.501010387778244}, &#x27;num_module_steps_sampled_lifetime&#x27;: {&#x27;predator_0&#x27;: 37732.0, &#x27;prey_1&#x27;: 35976.0, &#x27;prey_0&#x27;: 32707.0, &#x27;predator_1&#x27;: 37807.0}, &#x27;num_env_steps_sampled&#x27;: 4000.0, &#x27;agent_episode_returns_mean&#x27;: {&#x27;prey_0&#x27;: 39.501010387778244, &#x27;predator_1&#x27;: 80.10318804068176, &#x27;predator_0&#x27;: 80.89028911796635, &#x27;prey_1&#x27;: 5.593495632635077}, &#x27;env_step_timer&#x27;: np.float64(0.0006244127329904467), &#x27;module_to_env_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;remove_single_ts_time_rank_from_batch&#x27;: np.float64(1.1438115795139848e-06), &#x27;get_actions&#x27;: np.float64(8.79359404145158e-05), &#x27;normalize_and_clip_actions&#x27;: np.float64(3.6374516614796814e-05), &#x27;module_to_agent_unmapping&#x27;: np.float64(2.7477314209961845e-06), &#x27;un_batch_to_individual_items&#x27;: np.float64(1.3489444085736689e-05), &#x27;tensor_to_numpy&#x27;: np.float64(3.217228713262489e-05), &#x27;listify_data_for_vector_env&#x27;: np.float64(6.041157492678555e-06)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.00023506026660924747)}, &#x27;num_agent_steps_sampled&#x27;: {&#x27;predator_1&#x27;: 1002.0, &#x27;predator_0&#x27;: 1000.0, &#x27;prey_1&#x27;: 1002.0, &#x27;prey_0&#x27;: 1002.0}, &#x27;num_episodes&#x27;: 2.0, &#x27;agent_steps&#x27;: {&#x27;prey_0&#x27;: 467.5, &#x27;predator_1&#x27;: 500.0, &#x27;predator_0&#x27;: 500.0, &#x27;prey_1&#x27;: 464.9}, &#x27;episode_len_min&#x27;: 1501, &#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;batch_individual_items&#x27;: np.float64(2.6062014512717724e-05), &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: np.float64(1.9928003894165158e-05), &#x27;agent_to_module_mapping&#x27;: np.float64(5.398527719080448e-06), &#x27;numpy_to_tensor&#x27;: np.float64(7.099146023392677e-05), &#x27;add_states_from_episodes_to_batch&#x27;: np.float64(7.21248215995729e-06), &#x27;add_observations_from_episodes_to_batch&#x27;: np.float64(3.061548341065645e-05)}}, &#x27;num_episodes_lifetime&#x27;: 74.0, &#x27;weights_seq_no&#x27;: 35.0, &#x27;env_to_module_sum_episodes_length_in&#x27;: np.float64(1366.534406574458), &#x27;episode_return_min&#x27;: -84.76727611866065, &#x27;num_module_steps_sampled&#x27;: {&#x27;predator_1&#x27;: 1002.0, &#x27;predator_0&#x27;: 1000.0, &#x27;prey_1&#x27;: 1002.0, &#x27;prey_0&#x27;: 1002.0}, &#x27;rlmodule_inference_timer&#x27;: np.float64(0.0001141657641446096), &#x27;env_to_module_sum_episodes_length_out&#x27;: np.float64(1366.534406574458), &#x27;episode_return_mean&#x27;: 206.0879831790614, &#x27;connector_pipeline_timer&#x27;: np.float64(0.0003669440047815442), &#x27;episode_len_max&#x27;: 2000, &#x27;episode_len_mean&#x27;: 1932.4, &#x27;episode_return_max&#x27;: 540.3508868774368, &#x27;num_env_steps_sampled_lifetime&#x27;: 144000.0, &#x27;sample&#x27;: np.float64(2.6400521996452486), &#x27;time_between_sampling&#x27;: np.float64(4.377114626901259), &#x27;num_env_steps_sampled_lifetime_throughput&#x27;: np.float64(1107.409806242112)}</td><td>{&#x27;num_healthy_workers&#x27;: 2, &#x27;num_remote_worker_restarts&#x27;: 0}</td><td>{&#x27;predator_1&#x27;: {&#x27;vf_explained_var&#x27;: np.float32(0.020611227), &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;policy_loss&#x27;: np.float32(0.060595673), &#x27;vf_loss_unclipped&#x27;: np.float32(811.1757), &#x27;vf_loss&#x27;: np.float32(9.603533), &#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;num_trainable_parameters&#x27;: 144645, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;weights_seq_no&#x27;: 36.0, &#x27;total_loss&#x27;: np.float32(0.12056213), &#x27;mean_kl_loss&#x27;: np.float32(0.011801287), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(6.2505116), &#x27;entropy&#x27;: np.float32(1.9482784), &#x27;num_module_steps_trained_lifetime&#x27;: 1139072, &#x27;num_module_steps_trained&#x27;: 30208, &#x27;curr_kl_coeff&#x27;: 1.0125000476837158, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 11933.540129407007}, &#x27;prey_0&#x27;: {&#x27;policy_loss&#x27;: np.float32(-0.108806185), &#x27;vf_loss_unclipped&#x27;: np.float32(68.58441), &#x27;vf_loss&#x27;: np.float32(8.413092), &#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;num_trainable_parameters&#x27;: 144645, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;weights_seq_no&#x27;: 36.0, &#x27;total_loss&#x27;: np.float32(-0.05946529), &#x27;mean_kl_loss&#x27;: np.float32(0.009580824), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(2.9548683), &#x27;entropy&#x27;: np.float32(1.504042), &#x27;num_module_steps_trained_lifetime&#x27;: 1139072, &#x27;num_module_steps_trained&#x27;: 30208, &#x27;curr_kl_coeff&#x27;: 0.7593750357627869, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;vf_explained_var&#x27;: np.float32(-0.007822394), &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 11933.736474622032}, &#x27;__all_modules__&#x27;: {&#x27;learner_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;agent_to_module_mapping&#x27;: 0.0018995670013251193, &#x27;numpy_to_tensor&#x27;: 0.00145779555304108, &#x27;general_advantage_estimation&#x27;: 0.043094131560834456, &#x27;add_states_from_episodes_to_batch&#x27;: 7.796646939339906e-06, &#x27;add_one_ts_to_episodes_and_truncate&#x27;: 0.003401723225310948, &#x27;batch_individual_items&#x27;: 0.08989662367180681, &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: 2.540716453467961e-05, &#x27;add_columns_from_episodes_to_train_batch&#x27;: 0.038733550385951686, &#x27;add_observations_from_episodes_to_batch&#x27;: 9.189120698961721e-05}}, &#x27;connector_pipeline_timer&#x27;: 0.17893008619309408}, &#x27;num_trainable_parameters&#x27;: 578580, &#x27;num_non_trainable_parameters&#x27;: 0, &#x27;learner_connector_sum_episodes_length_out&#x27;: 4000.0, &#x27;num_module_steps_trained_lifetime&#x27;: 4556288, &#x27;num_module_steps_trained&#x27;: 120832, &#x27;num_env_steps_trained_lifetime&#x27;: 35596000, &#x27;num_env_steps_trained&#x27;: 944000, &#x27;learner_connector_sum_episodes_length_in&#x27;: 4000.0, &#x27;num_env_steps_trained_lifetime_throughput&#x27;: 372933.3184475834, &#x27;num_module_steps_trained_throughput&#x27;: 2078922.6995908984, &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 2113768.3627184294}, &#x27;prey_1&#x27;: {&#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;weights_seq_no&#x27;: 36.0, &#x27;total_loss&#x27;: np.float32(-0.05112382), &#x27;mean_kl_loss&#x27;: np.float32(0.033505864), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(5.928853), &#x27;vf_loss_unclipped&#x27;: np.float32(25.241398), &#x27;entropy&#x27;: np.float32(2.565145), &#x27;vf_loss&#x27;: np.float32(6.6567183), &#x27;num_module_steps_trained_lifetime&#x27;: 1139072, &#x27;num_module_steps_trained&#x27;: 30208, &#x27;curr_kl_coeff&#x27;: 0.5062500238418579, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;vf_explained_var&#x27;: np.float32(-0.018501878), &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;policy_loss&#x27;: np.float32(-0.09571563), &#x27;num_trainable_parameters&#x27;: 144645, &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 11933.641456071537}, &#x27;predator_0&#x27;: {&#x27;default_optimizer_learning_rate&#x27;: 5e-05, &#x27;num_trainable_parameters&#x27;: 144645, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;weights_seq_no&#x27;: 36.0, &#x27;total_loss&#x27;: np.float32(0.11655402), &#x27;mean_kl_loss&#x27;: np.float32(0.011620083), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(2.783734), &#x27;entropy&#x27;: np.float32(1.113735), &#x27;num_module_steps_trained_lifetime&#x27;: 1139072, &#x27;num_module_steps_trained&#x27;: 30208, &#x27;curr_kl_coeff&#x27;: 1.0125000476837158, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;vf_explained_var&#x27;: np.float32(-0.009889722), &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;policy_loss&#x27;: np.float32(0.05629824), &#x27;vf_loss_unclipped&#x27;: np.float32(774.2219), &#x27;vf_loss&#x27;: np.float32(9.69809), &#x27;num_module_steps_trained_lifetime_throughput&#x27;: 11933.656123720402}}</td><td style=\"text-align: right;\">                          144000</td><td style=\"text-align: right;\">                                      1</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(13.3125), &#x27;ram_util_percent&#x27;: np.float64(23.9875)}</td><td>{&#x27;training_iteration&#x27;: 5.826479364367092, &#x27;restore_env_runners&#x27;: 1.613147321514879e-05, &#x27;training_step&#x27;: 5.8262538328034434, &#x27;env_runner_sampling_timer&#x27;: 2.7430224047693557, &#x27;learner_update_timer&#x27;: 3.078540213118171, &#x27;synch_weights&#x27;: 0.00395395401678098, &#x27;synch_env_connectors&#x27;: 0.0014938705717566392}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=324172)\u001b[0m 2025-08-02 17:17:40,812\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000000)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:17:51 (running for 00:00:15.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      1 |          6.01957 | 4000 |          -3.85405 |            -21.1967 |            -15.7223 |         26.4824 |         6.58254 |\n",
      "+---------------------+----------+---------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000001)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000001)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:17:56 (running for 00:00:20.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |   ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      2 |          11.4894 | 8000 |          -19.0904 |            -21.1907 |            -12.8995 |         18.5733 |        -3.57358 |\n",
      "+---------------------+----------+---------------------+--------+------------------+------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000002)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000002)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:01 (running for 00:00:25.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      3 |          17.3569 | 12000 |          -25.6656 |             -18.532 |            -12.8568 |         8.85942 |        -3.13625 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000003)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000003)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:06 (running for 00:00:30.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      4 |          22.4906 | 16000 |           -28.734 |            -19.5374 |            -14.7207 |         7.26996 |        -1.74589 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000004)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000004)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:11 (running for 00:00:35.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      5 |          27.8778 | 20000 |          -22.5489 |            -18.0202 |            -13.0938 |         13.6067 |        -5.04158 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:16 (running for 00:00:40.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      5 |          27.8778 | 20000 |          -22.5489 |            -18.0202 |            -13.0938 |         13.6067 |        -5.04158 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000005)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000005)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:22 (running for 00:00:45.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      6 |          33.7252 | 24000 |          -19.0842 |            -16.5839 |            -11.3881 |         16.1939 |        -7.30607 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000006)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000006)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:27 (running for 00:00:50.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      7 |           39.128 | 28000 |          -22.2831 |            -17.2742 |            -11.8768 |         15.7927 |        -8.92481 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000007)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000007)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:32 (running for 00:00:55.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      8 |          44.7098 | 32000 |          -25.5486 |            -17.9351 |            -12.2018 |          14.791 |        -10.2027 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000008)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000008)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:37 (running for 00:01:00.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |      9 |          50.2968 | 36000 |           -28.636 |            -18.3935 |            -12.5599 |         15.0223 |        -12.7049 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000009)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000009)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:42 (running for 00:01:05.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     10 |          55.6454 | 40000 |          -28.7319 |            -17.1206 |            -11.2238 |         12.5228 |        -12.9102 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000010)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000010)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:47 (running for 00:01:10.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     11 |          61.1583 | 44000 |          -27.4331 |            -16.1276 |            -10.7054 |         10.2611 |        -10.8613 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000011)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000011)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:52 (running for 00:01:16.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     12 |          66.3094 | 48000 |          -22.9803 |            -15.6375 |             -10.581 |         13.5906 |        -10.3525 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000012)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000012)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:18:57 (running for 00:01:21.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     13 |           71.454 | 52000 |          -18.1907 |            -13.9565 |             -9.1796 |         16.3396 |        -11.3942 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000013)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000013)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:02 (running for 00:01:26.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     14 |          76.6045 | 56000 |          -14.1862 |            -12.3762 |            -7.95856 |         17.9933 |        -11.8448 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000014)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000014)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:07 (running for 00:01:31.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     15 |          81.7001 | 60000 |          -8.17057 |            -10.3696 |            -6.07314 |         18.5129 |        -10.2407 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000015)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000015)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:12 (running for 00:01:36.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     16 |           86.896 | 64000 |          0.356443 |            -7.37715 |            -3.32084 |         19.2901 |        -8.23565 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000016)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000016)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:17 (running for 00:01:41.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     17 |          92.0382 | 68000 |           6.52281 |            -5.18617 |            -1.35767 |         19.2043 |        -6.13767 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000017)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000017)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:22 (running for 00:01:46.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     18 |          97.1181 | 72000 |           17.3721 |            -0.37287 |             3.24705 |         20.1063 |        -5.60843 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000018)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000018)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:27 (running for 00:01:51.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     19 |          102.743 | 76000 |           26.9962 |             3.91346 |             7.60194 |         20.9216 |         -5.4408 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000019)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000019)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:32 (running for 00:01:56.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     20 |          108.341 | 80000 |            33.778 |              7.3527 |             10.6133 |         20.8158 |        -5.00386 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:37 (running for 00:02:01.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     20 |          108.341 | 80000 |            33.778 |              7.3527 |             10.6133 |         20.8158 |        -5.00386 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000020)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000020)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:42 (running for 00:02:06.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     21 |          114.019 | 84000 |           41.2493 |             10.4721 |             13.6177 |         20.9594 |        -3.80002 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000021)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000021)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:47 (running for 00:02:11.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     22 |          119.638 | 88000 |           48.0505 |             13.3265 |             16.4652 |         21.3901 |        -3.13127 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000022)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000022)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:52 (running for 00:02:16.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     23 |          124.805 | 92000 |           56.2605 |             16.0257 |             18.9764 |          22.553 |        -1.29466 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000023)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000023)... \n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:19:57 (running for 00:02:21.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |    ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     24 |          130.057 | 96000 |           63.8527 |             19.4647 |             22.2403 |         22.9706 |       -0.822898 |\n",
      "+---------------------+----------+---------------------+--------+------------------+-------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000024)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000024)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:02 (running for 00:02:26.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     25 |          135.242 | 100000 |           71.7586 |             24.1103 |             26.6546 |         22.3099 |        -1.31625 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000025)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000025)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:08 (running for 00:02:31.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     26 |          140.344 | 104000 |           75.6792 |             26.2063 |             28.3661 |         22.6117 |         -1.5048 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000026)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000026)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:13 (running for 00:02:36.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     27 |          145.982 | 108000 |           87.3643 |             30.6529 |             32.5147 |         25.9383 |        -1.74164 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000027)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000027)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:18 (running for 00:02:41.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     28 |          151.387 | 112000 |           100.456 |             36.8071 |             38.3081 |         27.4644 |        -2.12371 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000028)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000028)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:23 (running for 00:02:46.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     29 |          156.866 | 116000 |           115.981 |             43.5984 |             44.8244 |         29.4724 |        -1.91413 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000029)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000029)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:28 (running for 00:02:51.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     30 |           162.16 | 120000 |           120.567 |             46.5944 |              47.645 |         28.1562 |          -1.829 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000030)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000030)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:33 (running for 00:02:56.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     31 |          167.355 | 124000 |            135.02 |             51.7549 |             52.5059 |         30.5502 |        0.209003 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000031)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000031)... \n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:38 (running for 00:03:01.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     32 |          173.024 | 128000 |            153.41 |             59.1195 |             59.4583 |           33.36 |         1.47181 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000032)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000032)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:43 (running for 00:03:06.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     33 |          178.256 | 132000 |           161.833 |             62.3214 |             62.2506 |         33.6646 |         3.59586 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:48 (running for 00:03:11.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     33 |          178.256 | 132000 |           161.833 |             62.3214 |             62.2506 |         33.6646 |         3.59586 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000033)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000033)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:53 (running for 00:03:17.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     34 |          183.652 | 136000 |           179.582 |             68.9073 |              68.468 |         37.1765 |         5.03035 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000034)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000034)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:58 (running for 00:03:22.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status   | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | RUNNING  | 192.168.0.25:324172 |     35 |          189.161 | 140000 |           197.706 |             76.2764 |             75.7446 |         40.1817 |         5.50356 |\n",
      "+---------------------+----------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=env; env-runners=2; learners=0; multi-agent=True) pid=324172)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000035)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Adding directory to artifact (/home/qrbao/ray_results/PPO_2025-08-02_17-17-36/PPO_env_25c2d_00000_0_2025-08-02_17-17-36/checkpoint_000035)... \n",
      "2025-08-02 17:20:59,581\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/qrbao/ray_results/PPO_2025-08-02_17-17-36' in 0.0327s.\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-08-02 17:20:59 (running for 00:03:23.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 3.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /tmp/ray/session_2025-08-02_17-17-34_172592_322379/artifacts/2025-08-02_17-17-36/PPO_2025-08-02_17-17-36/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+---------------------+------------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "| Trial name          | status     | loc                 |   iter |   total time (s) |     ts |   combined return |   return predator_0 |   return predator_1 |   return prey_0 |   return prey_1 |\n",
      "|---------------------+------------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------|\n",
      "| PPO_env_25c2d_00000 | TERMINATED | 192.168.0.25:324172 |     36 |          194.505 | 144000 |           206.088 |             80.8903 |             80.1032 |          39.501 |          5.5935 |\n",
      "+---------------------+------------+---------------------+--------+------------------+--------+-------------------+---------------------+---------------------+-----------------+-----------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: uploading artifact checkpoint_PPO_env_25c2d_00000\n",
      "2025-08-02 17:21:03,634\tINFO tune.py:1041 -- Total run time: 207.26 seconds (203.16 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                \n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: \n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Run history:\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▇▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 ▅▃▁▁▂▃▃▃▃▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▆▅▆▇▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 █▄▅▅▄▃▂▂▁▁▂▂▂▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    env_runners/agent_steps/predator_0 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    env_runners/agent_steps/predator_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/agent_steps/prey_0 ▃▃▁▃▃▄▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇██████\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/agent_steps/prey_1 ██████████▇▇▇▇████▅▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  env_runners/connector_pipeline_timer ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           env_runners/env_reset_timer ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            env_runners/env_step_timer ▂▂▂▂▂▇▇▅▆█▃▁▁▁▁▁▁▁▇▁▆▁▁▁▂▁▇▂▇▂▃▇▂▂▂▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer ▁▁▂▁▂▂▃▂▁▂█▂▂▂▂▂▂▁▁▁▂▁▂▁▂▁▁▂▁▁▄▃▂▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch ▂▁▂▂▂▂▄▂▂▃█▂▂▂▂▂▃▂▁▂▁▁▂▁▂▁▁▂▂▂▄▃▃▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch ▁▁▃▂▂▁▅▃▂▃█▃▃▄▄▂▃▃▂▂▁▁▃▃▃▂▂▃▂▃▅▃▃▆▄▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ▂▁▂▂▂▂▃▂▁▂█▂▂▂▁▂▂▂▁▂▁▁▂▂▂▂▂▂▁▁▄▃▂▄▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping ▁▁▃▂▂▂▇▃▂▂█▂▃▂▂▂▃▂▁▂▁▁▂▂▃▃▂▃▂▂▄▄▂▄▃▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items ▁▂▂▂▂▂▄▂▂▃█▂▂▂▂▂▂▂▁▂▂▂▂▂▃▂▂▂▂▂▄▃▂▄▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor ▁▁▂▂▂▂▃▂▁▂█▂▁▁▂▁▂▁▁▁▁▁▂▁▂▁▁▂▂▁▄▃▂▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in ▅▁▃▃▃▄▅▆▇▇████████▅▅▂▃▃▃▃▃▃▄▄▅▅▅▆▆▆▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out ▅▁▃▃▃▄▅▆▇▇████████▅▅▂▃▃▃▃▃▃▄▄▅▅▅▆▆▆▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 env_runners/episode_duration_sec_mean ▄▃▁▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▅▆▆▆▆▇▆▆▆▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           env_runners/episode_len_max ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                          env_runners/episode_len_mean ▃▄▁▃▄▄▄▄▄▄▄▅▅▆▆▆▇▇▇▆▆▆▆▆▇▇▇▇▇▇▇█████\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           env_runners/episode_len_min ██████▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/episode_return_max ▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                       env_runners/episode_return_mean ▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/episode_return_min █▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▇▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 ▅▃▁▁▂▃▃▃▃▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▆▅▆▇▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 █▄▅▅▄▃▂▂▁▁▂▂▂▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer ▁▁▂▂▂▂▃▁▁▂█▁▂▂▂▁▂▁▁▁▂▁▁▁▂▁▁▂▂▁▄▃▂▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions ▁▁▂▂▂▁▃▁▁▂█▁▁▁▁▁▂▁▁▁▁▁▂▁▂▁▁▂▁▁▄▃▂▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env ▁▂▂▃▂▂▄▃▂▃█▃▃▃▃▃▃▂▂▂▂▃▂▂▂▃▂▃▃▂▄▄▄▄▄▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping ▃▂▃▃▃▃▃▃▂▃█▃▆▃▄▃▃▃▃▃▁▂▃▂▃▃▃▃▃▃▄▆▃▆▄▄\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions ▁▁▂▂▂▂▄▂▁▂█▁▂▂▂▁▂▁▁▁▂▁▁▁▂▂▂▃▂▁▄▃▃▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch ▂▁▂▃▂▁▃▁▁▂█▂▂▂▁▂▂▂▂▁▃▂▂▂▂▂▂▃▁▂▄▅▂▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy ▁▁▂▂▂▂▃▁▁▂█▂▂▁▂▂▂▁▁▁▁▁▁▁▂▁▁▂▂▁▄▃▂▃▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items ▃▂▂▂▂▁▃▁▂▃█▂▃▂▂▂▂▂▁▁▁▂▁▂▃▂▂▂▂▂▅▄▃▄▄▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 ▄▄▁▇▅▂▅▄▄▅▆▇▇▇▇▇▇▇██▇▄▇▇▇▇▃▅▇▇▇▄▇▇▇▇\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 ▇▇█▆▆▇▆▇▇▆▅▆▆▆▆▆▆▆▁▁▂▇▆▆▆▆▇▆▃▄▆▇▆▆▆▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     env_runners/num_env_steps_sampled ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput █████▆▄▅▅▃▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇█▇▇▆▆▅▄▄▄▃▄\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                              env_runners/num_episodes ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     env_runners/num_episodes_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 ▄▄▁▇▅▂▅▄▄▅▆▇▇▇▇▇▇▇██▇▄▇▇▇▇▃▅▇▇▇▄▇▇▇▇\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 ▇▇█▆▆▇▆▇▇▆▅▆▆▆▆▆▆▆▁▁▂▇▆▆▆▆▇▆▃▄▆▇▆▆▆▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  env_runners/rlmodule_inference_timer ▂▂▃▂▃▂▄▂▁▃█▂▂▂▂▂▂▂▁▁▁▁▂▂▃▂▁▃▂▂▅▃▃▄▄▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                    env_runners/sample █▇██▇▇▇▇▇▇▇▆▆▅▅▄▄▃▃▃▃▃▃▂▂▁▂▁▂▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     env_runners/time_between_sampling ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            env_runners/weights_seq_no ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                   fault_tolerance/num_healthy_workers ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                              iterations_since_restore ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer ███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch ███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch ███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad ▁▂▁▁▁▂▂▃▂▂▂▂▃▂▃▂▃▂▃▂▂▃▄▄▄▄▃▃▄▄▅▅▆▆▇█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping ▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇██\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items ███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation ███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor ███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▅▅\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput ▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇██████▇▇██▇▇▂▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput ▇▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████▇█▇▇██▇▇▂▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                learners/predator_0/curr_entropy_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/predator_0/curr_kl_coeff ▁▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅█████████████████\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy ▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_0/entropy ▆▆▆▆▆▆▆▇▆▆▆▅▅▅▄▅▄▄█▄▃▃▃▄▅█▃▂▄▄▁▅▂▁▂▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm ▂▂▂▂▂▃▁▂▂▁▃▃▂▃▃▂▂▄▄▅▂▆▄█▂█▃▄▄▅▃▅▆█▄▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/predator_0/mean_kl_loss ▆▆█▅▆▃▃▃▁▂▂▄▄▅▄▂▄▄▇▇▃▂▃▄▄▄▄▂▄▃▄▄▅▅▄▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_0/num_module_steps_trained ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▅▅\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_0/num_trainable_parameters ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                       learners/predator_0/policy_loss ▅▆▆▃▄▃▇▇▂▇▅▄▆▄▃▄▄▇▄▄▃▃▁█▂▅▆▄▇▂▄▅▄▃▄▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/predator_0/total_loss ▄▅▅▂▃▂▆▆▂▇▄▃▆▃▂▄▄▇▄▄▃▃▁█▂▅▆▄▇▂▄▅▄▃▄▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  learners/predator_0/vf_explained_var ▁▆▆▅▆▆▅▆▅▆▅▆▆▇▆▆▅▅█▆▆▆▅▆▆▆▆▅▆▆▅▆▆▅▆▅\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_0/vf_loss ▄▁▁▁▃▂▁▁▃▂▃▄▄▄▆▆▇▇▅▇▅▆█▆▆▄██▅▇█▇▇█▇█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▃▃▁▃▂▄▃▃▃▃▄▆▃▄▆▅▆▇▇█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/predator_0/weights_seq_no ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                learners/predator_1/curr_entropy_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/predator_1/curr_kl_coeff ▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▅▅▅▅█████████████████\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy ▁▁▁█▁█▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_1/entropy ▃▄▃▄▃▃▃▄▃▃▃▃▃▃▂▃▂▂▃▅█▂▂▂▃▃▂▁▇▃▂▂▁▁█▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm ▂▂▃▃▄▂▂▁▃▃▃▄▃▃▄▁▅▅▄▂▅▇▆▄█▂▅▅▄▄▅▄▆▅▄▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/predator_1/mean_kl_loss ▇▄▄▅▅▃▅▄▂▇▃▅▄▃▃▆▂▃▂█▂▁▂▁▃▂▅▂▃▃▁▂▂▂▂▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_1/num_module_steps_trained ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▅▅\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_1/num_trainable_parameters ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                       learners/predator_1/policy_loss ▃▄▆▅▁▄▆▅▄▄▅▃▅▆▃▄▅▄▃▆▇▄▄▅▃█▆▅▇▃▅▄▄▅▇▇\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/predator_1/total_loss ▃▄▅▅▁▄▅▄▄▄▄▃▅▆▄▄▅▅▃▆█▄▄▅▄█▇▅▇▄▅▅▄▅▇▇\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  learners/predator_1/vf_explained_var ▁▃▁▁▂▃▁▂▃▄▃▃▆▃▃▅▃▂▃▆█▃▂▃▅▃▃▃▆▃▃▃▃▃▆▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_1/vf_loss ▃▂▁▁▄▂▁▂▃▃▃▄▄▅▇▆▇▇▆▆▅▆▇▇▆▄██▆▇█▆▇█▆█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped ▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▃▃▂▃▂▄▃▃▄▂▄▆▃▄▆▅▇▇▆█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/predator_1/weights_seq_no ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                         learners/prey_0/curr_kl_coeff ▁▁▂▂▂▂▂▂▄▄▄▇▇▃▃▃▃▅▅▅▅▅▅▅▅▅██████████\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy ▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▁▁▁▁▁▁▁▁▁▁█▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_0/entropy ▅▅▅▅▄▄▄▄▅▄▃▅▅▃▃▇▄▄█▄▂▅▂▁▁▂▂▅▃▁▁▂▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm ▂▂▂▂▂▂▂▁▄▂▃▂▂▁▂▃▃▃▆▂▅▃▄▃▂▃▂▂▅▃▅█▄▁▅▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                          learners/prey_0/mean_kl_loss ▅▅▇▃▂▅▅▃█▂▃▅▂▁▂▂▃▆▂▂▄▃▄▂▁▃▅▃▂▃▁▃▁▁▁▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_0/num_module_steps_trained ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▅▅\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_0/num_trainable_parameters ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/prey_0/policy_loss ▃▅▂▃▅▃▃▆▃▅▃▅▆▆▅▆▅▁▃▆▄▄█▅▅▃▅▅▄▃▃▅▅▄▅▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            learners/prey_0/total_loss ▃▆▂▂▅▄▃▅▃▅▃▆▆▆▅▅▅▁▃▆▄▅█▅▅▃▅▅▄▃▃▅▅▄▅▄\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/prey_0/vf_explained_var ▂▃▅▄▁▃▄▂█▁▁▃▂▂▂▇▄▆▅▂▂▆▃▂▃▂▃▃▃▃▂▃▂▂▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_0/vf_loss ▄▆▁▃▄▅▅▄▃▃▆▅▅▄▄▃▄▄▅▄▅█▄▄▄▅▇▅▄▄▆▃▇▆▅▇\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped ▃▂▁▂▂▅▂▂▁▁▃▃▃▂▁▁▂▃▂▂▂▅▁▂▁▃▆▅▂▄▆▂█▄▃▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/prey_0/weights_seq_no ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                         learners/prey_1/curr_kl_coeff ▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▇▇▇▇▂▂▂▄▄▄▄▄▄▄▄▄▄█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy ▁▁▁▁▁██▁▁▁▁█▁▁▁▁█▁▁▁▁▁▁▁▁▁█▁▁██▁▁▁█▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_1/entropy ▆▅▅▆█▆█▇███▇▄▆▄▃▄▅▄▃▄▆▇▇▄▅▅▆▄▄▃▇▇▆▄▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm ▂▅▃▃▃▄▂▄▃▂▂▇▇▆▄▆▃▄▁▃▄▄▃▆▄▆▂▃▇▇▅▄▆▂▄█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                          learners/prey_1/mean_kl_loss ▃▄▂▅▂▄▂▂▂▃▅▃▂▃▃▂▃▃▇▂▂▁▁▄▂▆▂▂▄▂▄▃▁▄▄█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_1/num_module_steps_trained ▄▄█▁▃▆▃▄▅▃▂▁▁▁▁▁▁▁▆▅▆▅▁▁▁▁▅▄▃▂▁▅▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇████▇▅▅\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_1/num_trainable_parameters ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/prey_1/policy_loss ▅▆▂▃▁▆▄▅▄▅▄▃▄█▃▄▄▃▃▅▃▅▆▄▅▄█▇▅▅▆▄▄▂▂▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            learners/prey_1/total_loss ▅▆▂▃▁▆▄▄▄▆▄▃▄█▃▅▄▃▃▅▃▅▆▄▅▄█▇▅▆▇▄▄▂▂▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/prey_1/vf_explained_var ▄▄▂▃▅▇▇▄▅▄▇▁▃▄▂▃▃▃▂▄▃█▄▄▄▃▃▆▅▃▅▁▄▄▄▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_1/vf_loss ▆▆▄▄▅▁▄▂▄▇▂▄▂▃██▅█▆▇▆▅▆▅▄▇▃▂▃▅▆▇█▆█▆\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped ▂▂▂▂▂▁▂▂▁▄▂▁▁▁▇▇▄▆▃█▃▅▃▄▁▃▁▂▂▃▅▇▆▂▅▂\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/prey_1/weights_seq_no ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        num_env_steps_sampled_lifetime ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 num_training_step_calls_per_iteration ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                 perf/cpu_util_percent ▃▁▂▃▂▂▃▃▁▁▆▁▂▁▂▂▁▂▁▂▁▂▁▂▁▂▅▁▁▂▃▄▃▅▆█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                 perf/ram_util_percent ▁██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                    time_since_restore ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                      time_this_iter_s █▄▇▁▃▇▃▅▅▃▄▂▁▂▁▂▁▁▅▅▅▅▂▂▂▁▅▃▄▃▂▅▂▃▄▃\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                          time_total_s ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      timers/env_runner_sampling_timer ███▇▇▇▇▇▇▇▇▆▆▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           timers/learner_update_timer ███▇▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            timers/restore_env_runners ▇▇███▇█▇▇▆▆▅▇▇▇▇▇▆▆▇▆▆▅▅▅▄▃▃▃▂▂▂▂▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           timers/synch_env_connectors ▂▂▂▂▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▄▄▄▄▅▄▄▅▅▆▆▆█\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                  timers/synch_weights ███▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                             timers/training_iteration ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                  timers/training_step ███▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                             timestamp ▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅████████\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                    training_iteration ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: \n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Run summary:\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                             env_runner_group/actor_manager_num_outstanding_async_reqs 0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_0 80.89029\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     env_runners/agent_episode_returns_mean/predator_1 80.10319\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_0 39.50101\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                         env_runners/agent_episode_returns_mean/prey_1 5.5935\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    env_runners/agent_steps/predator_0 500\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    env_runners/agent_steps/predator_1 500\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/agent_steps/prey_0 467.5\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/agent_steps/prey_1 464.9\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  env_runners/connector_pipeline_timer 0.00037\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           env_runners/env_reset_timer 0.00421\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            env_runners/env_step_timer 0.00062\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          env_runners/env_to_module_connector/connector_pipeline_timer 0.00012\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:         env_runners/env_to_module_connector/timers/connectors/add_observations_from_episodes_to_batch 2e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:               env_runners/env_to_module_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:              env_runners/env_to_module_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                         env_runners/env_to_module_connector/timers/connectors/agent_to_module_mapping 0.0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                          env_runners/env_to_module_connector/timers/connectors/batch_individual_items 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 env_runners/env_to_module_connector/timers/connectors/numpy_to_tensor 2e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                      env_runners/env_to_module_sum_episodes_length_in 1366.53441\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     env_runners/env_to_module_sum_episodes_length_out 1366.53441\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 env_runners/episode_duration_sec_mean 2.4908\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           env_runners/episode_len_max 2000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                          env_runners/episode_len_mean 1932.4\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           env_runners/episode_len_min 1501\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/episode_return_max 540.35089\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                       env_runners/episode_return_mean 206.08798\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        env_runners/episode_return_min -84.76728\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_0 80.89029\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                    env_runners/module_episode_returns_mean/predator_1 80.10319\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_0 39.50101\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/module_episode_returns_mean/prey_1 5.5935\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          env_runners/module_to_env_connector/connector_pipeline_timer 0.00024\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                     env_runners/module_to_env_connector/timers/connectors/get_actions 9e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                     env_runners/module_to_env_connector/timers/connectors/listify_data_for_vector_env 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                       env_runners/module_to_env_connector/timers/connectors/module_to_agent_unmapping 0.0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                      env_runners/module_to_env_connector/timers/connectors/normalize_and_clip_actions 4e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:           env_runners/module_to_env_connector/timers/connectors/remove_single_ts_time_rank_from_batch 0.0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 env_runners/module_to_env_connector/timers/connectors/tensor_to_numpy 3e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                    env_runners/module_to_env_connector/timers/connectors/un_batch_to_individual_items 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_0 1000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        env_runners/num_agent_steps_sampled/predator_1 1002\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_0 1002\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            env_runners/num_agent_steps_sampled/prey_1 1002\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_0 37732\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               env_runners/num_agent_steps_sampled_lifetime/predator_1 37807\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_0 32707\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   env_runners/num_agent_steps_sampled_lifetime/prey_1 35976\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     env_runners/num_env_steps_sampled 4000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            env_runners/num_env_steps_sampled_lifetime 144000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 env_runners/num_env_steps_sampled_lifetime_throughput 1107.40981\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                              env_runners/num_episodes 2\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     env_runners/num_episodes_lifetime 74\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_0 1000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       env_runners/num_module_steps_sampled/predator_1 1002\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_0 1002\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                           env_runners/num_module_steps_sampled/prey_1 1002\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_0 37732\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                              env_runners/num_module_steps_sampled_lifetime/predator_1 37807\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_0 32707\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                  env_runners/num_module_steps_sampled_lifetime/prey_1 35976\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  env_runners/rlmodule_inference_timer 0.00011\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                    env_runners/sample 2.64005\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     env_runners/time_between_sampling 4.37711\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 env_runners/timers/connectors/add_observations_from_episodes_to_batch 3e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                       env_runners/timers/connectors/add_states_from_episodes_to_batch 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                      env_runners/timers/connectors/add_time_dim_to_batch_and_zero_pad 2e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 env_runners/timers/connectors/agent_to_module_mapping 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                  env_runners/timers/connectors/batch_individual_items 3e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                         env_runners/timers/connectors/numpy_to_tensor 7e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            env_runners/weights_seq_no 35\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                   fault_tolerance/num_healthy_workers 2\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                            fault_tolerance/num_remote_worker_restarts 0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                              iterations_since_restore 36\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                   learners/__all_modules__/learner_connector/connector_pipeline_timer 0.17893\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: learners/__all_modules__/learner_connector/timers/connectors/add_columns_from_episodes_to_train_batch 0.03873\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:  learners/__all_modules__/learner_connector/timers/connectors/add_observations_from_episodes_to_batch 9e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:      learners/__all_modules__/learner_connector/timers/connectors/add_one_ts_to_episodes_and_truncate 0.0034\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:        learners/__all_modules__/learner_connector/timers/connectors/add_states_from_episodes_to_batch 1e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:       learners/__all_modules__/learner_connector/timers/connectors/add_time_dim_to_batch_and_zero_pad 3e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                  learners/__all_modules__/learner_connector/timers/connectors/agent_to_module_mapping 0.0019\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                   learners/__all_modules__/learner_connector/timers/connectors/batch_individual_items 0.0899\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:             learners/__all_modules__/learner_connector/timers/connectors/general_advantage_estimation 0.04309\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                          learners/__all_modules__/learner_connector/timers/connectors/numpy_to_tensor 0.00146\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                     learners/__all_modules__/learner_connector_sum_episodes_length_in 4000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                    learners/__all_modules__/learner_connector_sum_episodes_length_out 4000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                        learners/__all_modules__/num_env_steps_trained 944000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/__all_modules__/num_env_steps_trained_lifetime 35596000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                    learners/__all_modules__/num_env_steps_trained_lifetime_throughput 372933.31845\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/__all_modules__/num_module_steps_trained 120832\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                            learners/__all_modules__/num_module_steps_trained_lifetime 4556288\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                 learners/__all_modules__/num_module_steps_trained_lifetime_throughput 2113768.36272\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          learners/__all_modules__/num_module_steps_trained_throughput 2078922.69959\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 learners/__all_modules__/num_non_trainable_parameters 0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/__all_modules__/num_trainable_parameters 578580\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                learners/predator_0/curr_entropy_coeff 0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/predator_0/curr_kl_coeff 1.0125\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   learners/predator_0/default_optimizer_learning_rate 5e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_0/diff_num_grad_updates_vs_sampler_policy 1\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_0/entropy 1.11373\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_0/gradients_default_optimizer_global_norm 2.78373\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/predator_0/mean_kl_loss 0.01162\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                      learners/predator_0/module_train_batch_size_mean 128\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_0/num_module_steps_trained 30208\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 learners/predator_0/num_module_steps_trained_lifetime 1139072\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                      learners/predator_0/num_module_steps_trained_lifetime_throughput 11933.65612\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_0/num_trainable_parameters 144645\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                       learners/predator_0/policy_loss 0.0563\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/predator_0/total_loss 0.11655\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  learners/predator_0/vf_explained_var -0.00989\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_0/vf_loss 9.69809\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 learners/predator_0/vf_loss_unclipped 774.22192\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/predator_0/weights_seq_no 36\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                learners/predator_1/curr_entropy_coeff 0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/predator_1/curr_kl_coeff 1.0125\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                   learners/predator_1/default_optimizer_learning_rate 5e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_1/diff_num_grad_updates_vs_sampler_policy 1\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_1/entropy 1.94828\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                           learners/predator_1/gradients_default_optimizer_global_norm 6.25051\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/predator_1/mean_kl_loss 0.0118\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                      learners/predator_1/module_train_batch_size_mean 128\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_1/num_module_steps_trained 30208\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                 learners/predator_1/num_module_steps_trained_lifetime 1139072\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                      learners/predator_1/num_module_steps_trained_lifetime_throughput 11933.54013\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/predator_1/num_trainable_parameters 144645\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                       learners/predator_1/policy_loss 0.0606\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/predator_1/total_loss 0.12056\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                  learners/predator_1/vf_explained_var 0.02061\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/predator_1/vf_loss 9.60353\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 learners/predator_1/vf_loss_unclipped 811.17572\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/predator_1/weights_seq_no 36\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/prey_0/curr_entropy_coeff 0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                         learners/prey_0/curr_kl_coeff 0.75938\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       learners/prey_0/default_optimizer_learning_rate 5e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_0/diff_num_grad_updates_vs_sampler_policy 1\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_0/entropy 1.50404\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_0/gradients_default_optimizer_global_norm 2.95487\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                          learners/prey_0/mean_kl_loss 0.00958\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/prey_0/module_train_batch_size_mean 128\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_0/num_module_steps_trained 30208\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/prey_0/num_module_steps_trained_lifetime 1139072\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          learners/prey_0/num_module_steps_trained_lifetime_throughput 11933.73647\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_0/num_trainable_parameters 144645\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/prey_0/policy_loss -0.10881\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            learners/prey_0/total_loss -0.05947\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/prey_0/vf_explained_var -0.00782\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_0/vf_loss 8.41309\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/prey_0/vf_loss_unclipped 68.58441\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/prey_0/weights_seq_no 36\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                    learners/prey_1/curr_entropy_coeff 0\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                         learners/prey_1/curr_kl_coeff 0.50625\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                       learners/prey_1/default_optimizer_learning_rate 5e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_1/diff_num_grad_updates_vs_sampler_policy 1\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_1/entropy 2.56515\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                               learners/prey_1/gradients_default_optimizer_global_norm 5.92885\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                          learners/prey_1/mean_kl_loss 0.03351\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                          learners/prey_1/module_train_batch_size_mean 128\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_1/num_module_steps_trained 30208\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                     learners/prey_1/num_module_steps_trained_lifetime 1139072\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                          learners/prey_1/num_module_steps_trained_lifetime_throughput 11933.64146\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                              learners/prey_1/num_trainable_parameters 144645\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           learners/prey_1/policy_loss -0.09572\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            learners/prey_1/total_loss -0.05112\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      learners/prey_1/vf_explained_var -0.0185\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                               learners/prey_1/vf_loss 6.65672\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                     learners/prey_1/vf_loss_unclipped 25.2414\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        learners/prey_1/weights_seq_no 36\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                        num_env_steps_sampled_lifetime 144000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                 num_training_step_calls_per_iteration 1\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                 perf/cpu_util_percent 13.3125\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                 perf/ram_util_percent 23.9875\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                    time_since_restore 194.50462\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                      time_this_iter_s 5.3433\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                          time_total_s 194.50462\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                      timers/env_runner_sampling_timer 2.74302\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           timers/learner_update_timer 3.07854\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                            timers/restore_env_runners 2e-05\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                           timers/synch_env_connectors 0.00149\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                  timers/synch_weights 0.00395\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                             timers/training_iteration 5.82648\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                  timers/training_step 5.82625\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                             timestamp 1754122859\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb:                                                                                    training_iteration 36\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: \n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: 🚀 View run PPO_env_25c2d_00000 at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4/runs/25c2d_00000\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: ⭐️ View project at: https://wandb.ai/bqr010817-kyushu-university/waterworld-v4\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 279 artifact file(s) and 0 other file(s)\n",
      "\u001b[36m(_WandbLoggingActor pid=324444)\u001b[0m wandb: Find logs at: ./wandb/run-20250802_171743-25c2d_00000/logs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练\n",
    "print(\"开始训练...\")\n",
    "run_rllib_example_script_experiment(base_config, args, keep_ray_up=True)\n",
    "# run_rllib_example_script_experiment(base_config, args, keep_ray_up=True)\n",
    "print(\"训练完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b2ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 训练\n",
    "# print(\"开始训练...\")\n",
    "# results = run_rllib_example_script_experiment(base_config, args, keep_ray_up=True)\n",
    "# print(\"训练完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb1d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取最佳checkpoint...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 获取最佳结果\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m获取最佳checkpoint...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mget_best_result(\n\u001b[1;32m      4\u001b[0m     metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mENV_RUNNER_RESULTS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPISODE_RETURN_MEAN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# 获取最佳结果\n",
    "print(\"获取最佳checkpoint...\")\n",
    "best_result = results.get_best_result(\n",
    "    metric=f\"{ENV_RUNNER_RESULTS}/{EPISODE_RETURN_MEAN}\", mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f75337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"加载所有智能体的RLModule...\")\n",
    "rl_modules = {}\n",
    "# 修改：使用新的智能体命名方式\n",
    "predator_agents = [f\"predator_{i}\" for i in range(args.n_predators)]\n",
    "prey_agents = [f\"prey_{i}\" for i in range(args.n_preys)]\n",
    "all_agent_names = predator_agents + prey_agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ed200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for agent_name in all_agent_names:\n",
    "    rl_module_path = os.path.join(\n",
    "        best_result.checkpoint.path,\n",
    "        \"learner_group\",\n",
    "        \"learner\",\n",
    "        \"rl_module\",\n",
    "        agent_name,\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(rl_module_path):\n",
    "        rl_modules[agent_name] = RLModule.from_checkpoint(rl_module_path)\n",
    "        print(f\"成功加载 {agent_name} 的模型\")\n",
    "    else:\n",
    "        print(f\"警告: 找不到 {agent_name} 的模型路径: {rl_module_path}\")\n",
    "print(f\"总共加载了 {len(rl_modules)} 个智能体模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed704b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 推理阶段\n",
    "print(\"开始推理...\")\n",
    "\n",
    "def get_action_from_rl_module(rl_module, observation, explore=False):\n",
    "    \"\"\"从RLModule获取动作\"\"\"\n",
    "    # 将观察转换为torch tensor并添加batch维度\n",
    "    input_dict = {Columns.OBS: torch.from_numpy(observation).unsqueeze(0)}\n",
    "    \n",
    "    if explore:\n",
    "        # 使用探索性前向传播\n",
    "        rl_module_out = rl_module.forward_exploration(input_dict)\n",
    "        action_dist_inputs = rl_module_out[\"action_dist_inputs\"][0]\n",
    "        action = TorchDiagGaussian.from_logits(action_dist_inputs.unsqueeze(0)).sample().squeeze(0).numpy()\n",
    "    else:\n",
    "        # 使用推理前向传播\n",
    "        rl_module_out = rl_module.forward_inference(input_dict)\n",
    "        action_dist_inputs = rl_module_out[\"action_dist_inputs\"][0]\n",
    "        action = TorchDiagGaussian.from_logits(action_dist_inputs.unsqueeze(0)).sample().squeeze(0).numpy()\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2908c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd924b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 运行推理episodes\n",
    "for episode in range(args.num_episodes_during_inference):\n",
    "    print(f\"\\n=== Episode {episode + 1} ===\")\n",
    "    \n",
    "    # 创建环境（使用新的参数方式）\n",
    "    env = waterworld_v4.env(\n",
    "        render_mode=\"human\",\n",
    "        n_predators=args.n_predators,  # 修改：使用新的参数\n",
    "        n_preys=args.n_preys,         # 修改：使用新的参数\n",
    "        n_evaders=5,  # 可以根据需要调整\n",
    "        n_poisons=10,  # 可以根据需要调整\n",
    "    )\n",
    "    env.reset(seed=42 + episode)\n",
    "    \n",
    "    episode_rewards = {agent: 0 for agent in env.agents}\n",
    "    step_count = 0\n",
    "    \n",
    "    try:\n",
    "        for agent in env.agent_iter():\n",
    "            observation, reward, termination, truncation, info = env.last()\n",
    "            \n",
    "            # 累积奖励\n",
    "            if agent in episode_rewards:\n",
    "                episode_rewards[agent] += reward\n",
    "            \n",
    "            if termination or truncation:\n",
    "                action = None\n",
    "                print(f\"{agent} 终止, 奖励: {reward}\")\n",
    "            else:\n",
    "                # 使用对应的RLModule获取动作\n",
    "                if agent in rl_modules:\n",
    "                    try:\n",
    "                        action = get_action_from_rl_module(\n",
    "                            rl_modules[agent], \n",
    "                            observation, \n",
    "                            explore=args.explore_during_inference\n",
    "                        )\n",
    "                        print(f\"{agent} 执行动作: {action}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"为 {agent} 获取动作时出错: {e}\")\n",
    "                        # 如果出错，使用随机动作作为备选\n",
    "                        action = env.action_space(agent).sample()\n",
    "                        print(f\"{agent} 使用随机动作: {action}\")\n",
    "                else:\n",
    "                    # 如果没有找到对应的模型，使用随机动作\n",
    "                    action = env.action_space(agent).sample()\n",
    "                    print(f\"{agent} 没有找到对应模型，使用随机动作: {action}\")\n",
    "            \n",
    "            env.step(action)\n",
    "            step_count += 1\n",
    "            \n",
    "            # 每100步输出一次进度\n",
    "            if step_count % 100 == 0:\n",
    "                print(f\"已执行 {step_count} 步\")\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"用户中断\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Episode {episode + 1} 出现错误: {e}\")\n",
    "    finally:\n",
    "        env.close()\n",
    "    \n",
    "    # 输出episode结果\n",
    "    print(f\"Episode {episode + 1} 完成\")\n",
    "    print(\"各智能体总奖励:\")\n",
    "    for agent, total_reward in episode_rewards.items():\n",
    "        print(f\"  {agent}: {total_reward:.2f}\")\n",
    "    print(f\"总步数: {step_count}\")\n",
    "\n",
    "print(\"推理完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理完每个 episode 后记录 reward\n",
    "wandb.log({\n",
    "    \"episode_index\": episode,\n",
    "    \"total_reward_mean\": np.mean(list(episode_rewards.values())),\n",
    "    \"total_reward_std\": np.std(list(episode_rewards.values())),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e366e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pettingzoo.sisl import waterworld_v4\n",
    "\n",
    "# env = waterworld_v4.env(render_mode=\"human\")\n",
    "# env.reset(seed=42)\n",
    "\n",
    "# for agent in env.agent_iter():\n",
    "#     observation, reward, termination, truncation, info = env.last()\n",
    "\n",
    "#     if termination or truncation:\n",
    "#         action = None\n",
    "#     else:\n",
    "#         # this is where you would insert your policy\n",
    "#         action = env.action_space(agent).sample()\n",
    "\n",
    "#     env.step(action)\n",
    "# env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
