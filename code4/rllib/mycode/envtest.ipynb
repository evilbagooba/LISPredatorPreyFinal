{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b8267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.test import parallel_api_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6fae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.test import api_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bd9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pettingzoo.sisl import waterworld_v4\n",
    "\n",
    "# agent_algos = [\"PPO\", \"PPO\", \"DQN\", \"DQN\", \"A2C\"]\n",
    "\n",
    "# env = waterworld_v4.env(\n",
    "#     render_mode=\"human\",\n",
    "#     n_predators=2,\n",
    "#     n_preys=3,\n",
    "#     n_evaders=5,\n",
    "#     n_obstacles=1,\n",
    "#     n_poisons=1,\n",
    "#     agent_algorithms=agent_algos\n",
    "# )\n",
    "# env.reset()\n",
    "# for agent in env.agent_iter():\n",
    "#     observation, reward, termination, truncation, info = env.last()\n",
    "#     print(observation)\n",
    "#     print(reward)\n",
    "\n",
    "\n",
    "#     if termination or truncation:\n",
    "#         action = None\n",
    "#     else:\n",
    "#         # this is where you would insert your policy\n",
    "#         action = env.action_space(agent).sample()\n",
    "\n",
    "#     env.step(action)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d5bf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 碰撞逻辑测试 ===\n",
      "Predators: predator_0 (PPO), predator_1 (PPO)\n",
      "Preys: prey_0 (DQN), prey_1 (DQN), prey_2 (A2C)\n",
      "\n",
      "预期效果：\n",
      "- predator捕获prey: predator +10, prey reset to 0\n",
      "- 相同算法相遇: 都 +3\n",
      "- 不同算法相遇: 无额外奖励\n",
      "predator_0 获得奖励: -0.24589176062865695\n",
      "predator_1 获得奖励: -0.07701686915435381\n",
      "prey_0 获得奖励: -0.17317188883761328\n",
      "prey_1 获得奖励: -0.054341336097980766\n",
      "prey_2 获得奖励: -0.1326365637915252\n",
      "predator_0 获得奖励: -0.2499999925494193\n",
      "predator_1 获得奖励: -0.23838034898570604\n",
      "prey_0 获得奖励: -0.2500000298023206\n",
      "prey_1 获得奖励: -0.08345091584661168\n",
      "prey_2 获得奖励: -0.4236262847270828\n",
      "predator_0 获得奖励: -0.1659079146187616\n",
      "predator_1 获得奖励: -0.1713005620995773\n",
      "prey_0 获得奖励: -0.13172834739247288\n",
      "prey_1 获得奖励: -0.22535546820303123\n",
      "prey_2 获得奖励: -0.3973600742288485\n",
      "predator_0 获得奖励: -0.13970417297630672\n",
      "predator_1 获得奖励: -0.2132379166454393\n",
      "prey_0 获得奖励: -0.02638912502494349\n",
      "prey_1 获得奖励: -0.12953787726875854\n",
      "prey_2 获得奖励: -0.07603224770572993\n",
      "predator_0 获得奖励: -0.045826043195811676\n",
      "predator_1 获得奖励: -0.22892201795723904\n",
      "prey_0 获得奖励: -0.137879822931988\n",
      "prey_1 获得奖励: -0.20752152385876985\n",
      "prey_2 获得奖励: -0.4999999701976767\n",
      "predator_0 获得奖励: -0.18513537502515504\n",
      "predator_1 获得奖励: -0.2499999776482572\n",
      "prey_0 获得奖励: -0.18748091560832705\n",
      "prey_1 获得奖励: -0.20387094418568688\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.2229597967230856\n",
      "predator_1 获得奖励: -0.14777913404511991\n",
      "prey_0 获得奖励: -0.1334250712580899\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.4954344054907822\n",
      "predator_0 获得奖励: -0.1684834445756808\n",
      "predator_1 获得奖励: -0.21499080826827643\n",
      "prey_0 获得奖励: -0.16310502700097193\n",
      "prey_1 获得奖励: -0.12553507307278772\n",
      "prey_2 获得奖励: -0.342250131074812\n",
      "predator_0 获得奖励: -0.07457261990154077\n",
      "predator_1 获得奖励: -0.23229270038175157\n",
      "prey_0 获得奖励: -0.24525821473910064\n",
      "prey_1 获得奖励: -0.23893735015808565\n",
      "prey_2 获得奖励: -0.48747204675983513\n",
      "predator_0 获得奖励: -0.17275686956940212\n",
      "predator_1 获得奖励: -0.02899249828642845\n",
      "prey_0 获得奖励: -0.19448189549778322\n",
      "prey_1 获得奖励: -0.24593761577385356\n",
      "prey_2 获得奖励: -0.45104622019994006\n",
      "predator_0 获得奖励: -0.12841856343526903\n",
      "predator_1 获得奖励: -0.03271171924986191\n",
      "prey_0 获得奖励: -0.08149422827842209\n",
      "prey_1 获得奖励: -0.0644700071593179\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.1801341766042381\n",
      "predator_1 获得奖励: -0.17571273104070445\n",
      "prey_0 获得奖励: -0.2499999925494193\n",
      "prey_1 获得奖励: -0.12999537616768847\n",
      "prey_2 获得奖励: -0.32572892086644784\n",
      "predator_0 获得奖励: -0.07284621329010908\n",
      "predator_1 获得奖励: -0.23479085428057317\n",
      "prey_0 获得奖励: -0.10203253660515374\n",
      "prey_1 获得奖励: -0.235502780120885\n",
      "prey_2 获得奖励: -0.2515263750663368\n",
      "predator_0 获得奖励: -0.17671766931758215\n",
      "predator_1 获得奖励: -0.25000001490116075\n",
      "prey_0 获得奖励: -0.11236039314291464\n",
      "prey_1 获得奖励: -0.1784528108431542\n",
      "prey_2 获得奖励: -0.4399375957700807\n",
      "predator_0 获得奖励: -0.2256720324946726\n",
      "predator_1 获得奖励: -0.25000001490116075\n",
      "prey_0 获得奖励: -0.13435828803623462\n",
      "prey_1 获得奖励: -0.2160253025943026\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.1310554430466546\n",
      "prey_0 获得奖励: -0.25000001490116075\n",
      "prey_1 获得奖励: -0.16345056443305128\n",
      "prey_2 获得奖励: -0.37705589040018145\n",
      "predator_0 获得奖励: -0.180301240076909\n",
      "predator_1 获得奖励: -0.12202457715618498\n",
      "prey_0 获得奖励: -0.18239550471389712\n",
      "prey_1 获得奖励: -0.16880401038396292\n",
      "prey_2 获得奖励: -0.4216293396781566\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.2499999925494193\n",
      "prey_0 获得奖励: -0.19124887769968185\n",
      "prey_1 获得奖励: -0.2181776170609473\n",
      "prey_2 获得奖励: -0.4553990358160682\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.11838299591119728\n",
      "prey_0 获得奖励: -0.22953786192551087\n",
      "prey_1 获得奖励: -0.04169741985139392\n",
      "prey_2 获得奖励: -0.3519311349754198\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.2499999925494193\n",
      "prey_0 获得奖励: -0.1412998273195776\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.12130563410826141\n",
      "predator_0 获得奖励: -0.22905676095546382\n",
      "predator_1 获得奖励: -0.22754956495416956\n",
      "prey_0 获得奖励: -0.25000001490116075\n",
      "prey_1 获得奖励: -0.22726792647428107\n",
      "prey_2 获得奖励: -0.23985144481679035\n",
      "predator_0 获得奖励: -0.24144967808870843\n",
      "predator_1 获得奖励: -0.1407346959890231\n",
      "prey_0 获得奖励: -0.14613726498230323\n",
      "prey_1 获得奖励: -0.2499999925494193\n",
      "prey_2 获得奖励: -0.4723303909002592\n",
      "predator_0 获得奖励: -0.15805759918704723\n",
      "predator_1 获得奖励: -0.10490851486938399\n",
      "prey_0 获得奖励: -0.23351875300528266\n",
      "prey_1 获得奖励: -0.23576938374301726\n",
      "prey_2 获得奖励: -0.5000000298023215\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.12473043044508624\n",
      "prey_0 获得奖励: -0.15847966078996342\n",
      "prey_1 获得奖励: -0.0606927000088218\n",
      "prey_2 获得奖励: -0.46619980426818586\n",
      "predator_0 获得奖励: -0.14382326860740055\n",
      "predator_1 获得奖励: -0.17204677602674848\n",
      "prey_0 获得奖励: -0.23248842232344463\n",
      "prey_1 获得奖励: -0.09154846690086735\n",
      "prey_2 获得奖励: -0.1379003486230723\n",
      "predator_0 获得奖励: -0.1953552580760198\n",
      "predator_1 获得奖励: -0.15452484600694838\n",
      "prey_0 获得奖励: -0.1705466000200432\n",
      "prey_1 获得奖励: -0.08202480960722554\n",
      "prey_2 获得奖励: -0.30611139537741733\n",
      "predator_0 获得奖励: -0.12582072888281448\n",
      "predator_1 获得奖励: -0.16688180364890737\n",
      "prey_0 获得奖励: -0.22014502625997187\n",
      "prey_1 获得奖励: -0.201089416196373\n",
      "prey_2 获得奖励: -0.16102574577155884\n",
      "predator_0 获得奖励: -0.05477953727316606\n",
      "predator_1 获得奖励: -0.2039221381066706\n",
      "prey_0 获得奖励: -0.1664005081547259\n",
      "prey_1 获得奖励: -0.1824673532653651\n",
      "prey_2 获得奖励: -0.42017216874648183\n",
      "predator_0 获得奖励: -0.20080755632894517\n",
      "predator_1 获得奖励: -0.1677780288405554\n",
      "prey_0 获得奖励: -0.24999998509883836\n",
      "prey_1 获得奖励: -0.09483641713938168\n",
      "prey_2 获得奖励: -0.3259714961586767\n",
      "predator_0 获得奖励: -0.20395374877584135\n",
      "predator_1 获得奖励: -0.13440226899180238\n",
      "prey_0 获得奖励: -0.1788427148469399\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.4999999701976767\n",
      "predator_0 获得奖励: -0.2080209127966268\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.19971648849068802\n",
      "prey_1 获得奖励: -0.09763084558021365\n",
      "prey_2 获得奖励: -0.31676749811713334\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.1931377450817623\n",
      "prey_0 获得奖励: -0.1830523197603299\n",
      "prey_1 获得奖励: -0.2406125232632511\n",
      "prey_2 获得奖励: -0.4999999552965144\n",
      "predator_0 获得奖励: -0.24982502148436414\n",
      "predator_1 获得奖励: -0.19173051653431752\n",
      "prey_0 获得奖励: -0.10160047481413714\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.1517528358831582\n",
      "predator_0 获得奖励: -0.13869778297075033\n",
      "predator_1 获得奖励: -0.2031177831248045\n",
      "prey_0 获得奖励: -0.1626181432057689\n",
      "prey_1 获得奖励: -0.1554129471623552\n",
      "prey_2 获得奖励: -0.31532555151431224\n",
      "predator_0 获得奖励: -0.24572685685041756\n",
      "predator_1 获得奖励: -0.14330165647000534\n",
      "prey_0 获得奖励: -0.23592792074702276\n",
      "prey_1 获得奖励: -0.15063597123762565\n",
      "prey_2 获得奖励: -0.34667870964664577\n",
      "predator_0 获得奖励: -0.13502282326105067\n",
      "predator_1 获得奖励: -0.10463485604011474\n",
      "prey_0 获得奖励: -0.1277431336296057\n",
      "prey_1 获得奖励: -0.13006009644217276\n",
      "prey_2 获得奖励: -0.4245796396745586\n",
      "predator_0 获得奖励: -0.06495016798988067\n",
      "predator_1 获得奖励: -0.17930543750271832\n",
      "prey_0 获得奖励: -0.10813390397471209\n",
      "prey_1 获得奖励: -0.0457432283613716\n",
      "prey_2 获得奖励: -0.4195683787874631\n",
      "predator_0 获得奖励: -0.09170325049981431\n",
      "predator_1 获得奖励: -0.198284595632622\n",
      "prey_0 获得奖励: -0.21756631897925385\n",
      "prey_1 获得奖励: -0.20261712956248437\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.22463120064219969\n",
      "predator_1 获得奖励: -0.15578719382200507\n",
      "prey_0 获得奖励: -0.15587211451654975\n",
      "prey_1 获得奖励: -0.20603445595587816\n",
      "prey_2 获得奖励: -0.3968502855490443\n",
      "predator_0 获得奖励: -0.22014867291701384\n",
      "predator_1 获得奖励: -0.17551073876358403\n",
      "prey_0 获得奖励: -0.21936647367345993\n",
      "prey_1 获得奖励: -0.08009751596836176\n",
      "prey_2 获得奖励: -0.4999999701976767\n",
      "predator_0 获得奖励: -0.09675573960487452\n",
      "predator_1 获得奖励: -0.24373325693874376\n",
      "prey_0 获得奖励: -0.2222566951439488\n",
      "prey_1 获得奖励: -0.20464468974223995\n",
      "prey_2 获得奖励: -0.4753376745545842\n",
      "predator_0 获得奖励: -0.047543321150747046\n",
      "predator_1 获得奖励: -0.21285152076164923\n",
      "prey_0 获得奖励: -0.21590314975577102\n",
      "prey_1 获得奖励: -0.1907153603310208\n",
      "prey_2 获得奖励: -0.25457755623603306\n",
      "predator_0 获得奖励: -0.18484189473540769\n",
      "predator_1 获得奖励: -0.19230683273801902\n",
      "prey_0 获得奖励: -0.1565070005658685\n",
      "prey_1 获得奖励: -0.18176944840531203\n",
      "prey_2 获得奖励: -0.3910578046641508\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.14404352478954516\n",
      "prey_0 获得奖励: -0.19799733191195282\n",
      "prey_1 获得奖励: -0.17312971461586707\n",
      "prey_2 获得奖励: -0.3587363830002446\n",
      "predator_0 获得奖励: -0.187986071685092\n",
      "predator_1 获得奖励: -0.1277616285128477\n",
      "prey_0 获得奖励: -0.1676508034535123\n",
      "prey_1 获得奖励: -0.2429706386357834\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.14117907933744905\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.20890063096380745\n",
      "prey_1 获得奖励: -0.08964380530729531\n",
      "prey_2 获得奖励: -0.3829935579891113\n",
      "predator_0 获得奖励: -0.16810766286693424\n",
      "predator_1 获得奖励: -0.2499999925494193\n",
      "prey_0 获得奖励: -0.03753796551785647\n",
      "prey_1 获得奖励: -0.11603357500515202\n",
      "prey_2 获得奖励: -0.3203958891273584\n",
      "predator_0 获得奖励: -0.24047268313388243\n",
      "predator_1 获得奖励: -0.2499999925494193\n",
      "prey_0 获得奖励: -0.1928057692757994\n",
      "prey_1 获得奖励: -0.21173473980477878\n",
      "prey_2 获得奖励: -0.1978717594062107\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.13338114513283877\n",
      "prey_0 获得奖励: -0.12644847926009362\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.13257959925877708\n",
      "predator_0 获得奖励: -0.19956675221852738\n",
      "predator_1 获得奖励: -0.1179001714621758\n",
      "prey_0 获得奖励: -0.22380969286215238\n",
      "prey_1 获得奖励: -0.16232602453162587\n",
      "prey_2 获得奖励: -0.20505131137487165\n",
      "predator_0 获得奖励: -0.18136011018240056\n",
      "predator_1 获得奖励: -0.1451036613804257\n",
      "prey_0 获得奖励: -0.19993862350269836\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.4623569035181875\n",
      "predator_0 获得奖励: -0.19864227062351758\n",
      "predator_1 获得奖励: -0.24999998509883836\n",
      "prey_0 获得奖励: -0.25\n",
      "prey_1 获得奖励: -0.16545634589742386\n",
      "prey_2 获得奖励: -0.42825891391275633\n",
      "predator_0 获得奖励: -0.22327685449917314\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.25\n",
      "prey_1 获得奖励: -0.22819321050266445\n",
      "prey_2 获得奖励: -0.4848846400109783\n",
      "predator_0 获得奖励: -0.0708595788094766\n",
      "predator_1 获得奖励: -0.10294420946961409\n",
      "prey_0 获得奖励: -0.10237373466082349\n",
      "prey_1 获得奖励: -0.16003568111736688\n",
      "prey_2 获得奖励: -0.37490034766136565\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.10658014140272004\n",
      "prey_0 获得奖励: -0.06805838670377794\n",
      "prey_1 获得奖励: -0.24883275678985817\n",
      "prey_2 获得奖励: -0.12628739474770861\n",
      "predator_0 获得奖励: -0.1547791994314455\n",
      "predator_1 获得奖励: -0.19766731721253422\n",
      "prey_0 获得奖励: -0.11276821178541886\n",
      "prey_1 获得奖励: -0.21108960919162528\n",
      "prey_2 获得奖励: -0.22679077355735014\n",
      "predator_0 获得奖励: -0.2481445961043488\n",
      "predator_1 获得奖励: -0.21492057640434936\n",
      "prey_0 获得奖励: -0.25\n",
      "prey_1 获得奖励: -0.23540751793197223\n",
      "prey_2 获得奖励: -0.30369719937276396\n",
      "predator_0 获得奖励: -0.10922112454819632\n",
      "predator_1 获得奖励: -0.19127139381663402\n",
      "prey_0 获得奖励: -0.08164672189971858\n",
      "prey_1 获得奖励: -0.20726534366408836\n",
      "prey_2 获得奖励: -0.41855916542865546\n",
      "predator_0 获得奖励: -0.09354370486754802\n",
      "predator_1 获得奖励: -0.12023036943298519\n",
      "prey_0 获得奖励: -0.1919135940828669\n",
      "prey_1 获得奖励: -0.19237984011140183\n",
      "prey_2 获得奖励: -0.22558260993650114\n",
      "predator_0 获得奖励: -0.12426464774343357\n",
      "predator_1 获得奖励: -0.12597064810183767\n",
      "prey_0 获得奖励: -0.23984384971641431\n",
      "prey_1 获得奖励: -0.1835693485195573\n",
      "prey_2 获得奖励: -0.48928528364041246\n",
      "predator_0 获得奖励: -0.20536784642473327\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.15683494985609134\n",
      "prey_1 获得奖励: -0.2435262196903761\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.21253403713607066\n",
      "predator_1 获得奖励: -0.19411465492243804\n",
      "prey_0 获得奖励: -0.13403056963781043\n",
      "prey_1 获得奖励: -0.22368430498489505\n",
      "prey_2 获得奖励: -0.12429351386099947\n",
      "predator_0 获得奖励: -0.21862595310734084\n",
      "predator_1 获得奖励: -0.24999998509883836\n",
      "prey_0 获得奖励: -0.010598843741930012\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.3255895224261164\n",
      "predator_0 获得奖励: -0.2499999925494193\n",
      "predator_1 获得奖励: -0.17696463355898645\n",
      "prey_0 获得奖励: -0.25000001490116075\n",
      "prey_1 获得奖励: -0.2499999925494193\n",
      "prey_2 获得奖励: -0.33707321388551154\n",
      "predator_0 获得奖励: -0.044368927399081444\n",
      "predator_1 获得奖励: -0.2088095298990879\n",
      "prey_0 获得奖励: -0.2246769596089314\n",
      "prey_1 获得奖励: -0.056299216541230795\n",
      "prey_2 获得奖励: 9.510000029802322\n",
      "predator_0 获得奖励: -0.21001337860270572\n",
      "predator_1 获得奖励: -0.2500000298023206\n",
      "prey_0 获得奖励: -0.15724972145635074\n",
      "prey_1 获得奖励: -0.14475648959260132\n",
      "prey_2 获得奖励: 9.698977604221167\n",
      "predator_0 获得奖励: -0.23746638028709044\n",
      "predator_1 获得奖励: -0.21267291845265085\n",
      "prey_0 获得奖励: -0.25\n",
      "prey_1 获得奖励: -0.1816565496375623\n",
      "prey_2 获得奖励: -0.4808036908307568\n",
      "predator_0 获得奖励: -0.2344024483184655\n",
      "predator_1 获得奖励: -0.21567049479483383\n",
      "prey_0 获得奖励: -0.15375021780394038\n",
      "prey_1 获得奖励: -0.131178836035724\n",
      "prey_2 获得奖励: -0.3599593760166256\n",
      "predator_0 获得奖励: -0.22688494132463713\n",
      "predator_1 获得奖励: -0.25000001490116075\n",
      "prey_0 获得奖励: -0.24264773354504524\n",
      "prey_1 获得奖励: -0.0953794816605932\n",
      "prey_2 获得奖励: -0.49116253472171445\n",
      "predator_0 获得奖励: -0.10153240436527049\n",
      "predator_1 获得奖励: -0.12754766192807399\n",
      "prey_0 获得奖励: -0.24999998509883836\n",
      "prey_1 获得奖励: -0.1604373256480299\n",
      "prey_2 获得奖励: -0.30937391964887545\n",
      "predator_0 获得奖励: -0.21906351715047653\n",
      "predator_1 获得奖励: -0.23311745717064913\n",
      "prey_0 获得奖励: -0.14560995421226353\n",
      "prey_1 获得奖励: -0.22374734069799623\n",
      "prey_2 获得奖励: -0.3831293779779559\n",
      "predator_0 获得奖励: -0.10298552274491253\n",
      "predator_1 获得奖励: -0.08700308633833401\n",
      "prey_0 获得奖励: -0.18329607388971125\n",
      "prey_1 获得奖励: -0.06273875231928512\n",
      "prey_2 获得奖励: -0.40703766830567845\n",
      "predator_0 获得奖励: -0.21302669446354322\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.24999998509883836\n",
      "prey_1 获得奖励: -0.06815876475626736\n",
      "prey_2 获得奖励: -0.44134038248055674\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.24411804094762676\n",
      "prey_0 获得奖励: -0.16862214883362045\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.12187667365636701\n",
      "predator_1 获得奖励: -0.0639894852967132\n",
      "prey_0 获得奖励: -0.11519063911646948\n",
      "prey_1 获得奖励: -0.13675680993155845\n",
      "prey_2 获得奖励: -0.32783353439863705\n",
      "predator_0 获得奖励: -0.22105894690988923\n",
      "predator_1 获得奖励: -0.24999998509883836\n",
      "prey_0 获得奖励: -0.14950144462740678\n",
      "prey_1 获得奖励: -0.2500000298023206\n",
      "prey_2 获得奖励: -0.24601276518394236\n",
      "predator_0 获得奖励: -0.12091978713492028\n",
      "predator_1 获得奖励: -0.24521163245574287\n",
      "prey_0 获得奖励: -0.25\n",
      "prey_1 获得奖励: -0.18578996294603123\n",
      "prey_2 获得奖励: -0.07212047562755014\n",
      "predator_0 获得奖励: -0.1572361937232616\n",
      "predator_1 获得奖励: -0.10539256982726786\n",
      "prey_0 获得奖励: -0.24780665051602693\n",
      "prey_1 获得奖励: -0.22369402251815726\n",
      "prey_2 获得奖励: -0.31623660355114463\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.03532497989876864\n",
      "prey_1 获得奖励: -0.24105410554624296\n",
      "prey_2 获得奖励: -0.455957471790538\n",
      "predator_0 获得奖励: -0.21345228072800126\n",
      "predator_1 获得奖励: -0.03946441474695725\n",
      "prey_0 获得奖励: -0.2314868358593264\n",
      "prey_1 获得奖励: -0.24315668577472116\n",
      "prey_2 获得奖励: -0.14676114320973405\n",
      "predator_0 获得奖励: -0.22379830745991508\n",
      "predator_1 获得奖励: -0.2420891977588549\n",
      "prey_0 获得奖励: -0.1462319806401511\n",
      "prey_1 获得奖励: -0.12084617609869211\n",
      "prey_2 获得奖励: -0.3493970833795578\n",
      "predator_0 获得奖励: -0.23594559693495387\n",
      "predator_1 获得奖励: -0.22111166217616543\n",
      "prey_0 获得奖励: -0.10719327879083665\n",
      "prey_1 获得奖励: -0.023741567629962632\n",
      "prey_2 获得奖励: -0.4438997412274563\n",
      "predator_0 获得奖励: -0.24936739037550687\n",
      "predator_1 获得奖励: -0.25000001490116075\n",
      "prey_0 获得奖励: -0.05144896216976944\n",
      "prey_1 获得奖励: -0.0412456358466827\n",
      "prey_2 获得奖励: -0.35306318847689067\n",
      "predator_0 获得奖励: -0.16384711773518207\n",
      "predator_1 获得奖励: -0.11732963842883279\n",
      "prey_0 获得奖励: -0.17897216798540194\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.36779627149200095\n",
      "predator_0 获得奖励: -0.09027706742261929\n",
      "predator_1 获得奖励: -0.18163321079996586\n",
      "prey_0 获得奖励: -0.24999998509883836\n",
      "prey_1 获得奖励: -0.18590294653130762\n",
      "prey_2 获得奖励: -0.24162340612818262\n",
      "predator_0 获得奖励: -0.10332862589801384\n",
      "predator_1 获得奖励: -0.2410853132154979\n",
      "prey_0 获得奖励: -0.17138200737109838\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.44546225188141064\n",
      "predator_0 获得奖励: -0.22797862968188692\n",
      "predator_1 获得奖励: -0.25000001490116075\n",
      "prey_0 获得奖励: -0.25\n",
      "prey_1 获得奖励: -0.1413254182787262\n",
      "prey_2 获得奖励: -0.5000000298023215\n",
      "predator_0 获得奖励: -0.17216893551231024\n",
      "predator_1 获得奖励: -0.24328715108379867\n",
      "prey_0 获得奖励: -0.25000001490116075\n",
      "prey_1 获得奖励: -0.23253165785798963\n",
      "prey_2 获得奖励: -0.12886941267846191\n",
      "predator_0 获得奖励: -0.24433313790477684\n",
      "predator_1 获得奖励: -0.19879168193318422\n",
      "prey_0 获得奖励: -0.12092583304321942\n",
      "prey_1 获得奖励: -0.1788993842460842\n",
      "prey_2 获得奖励: -0.4274146744699076\n",
      "predator_0 获得奖励: -0.2030111048572565\n",
      "predator_1 获得奖励: -0.06372686699764922\n",
      "prey_0 获得奖励: -0.23711169208733057\n",
      "prey_1 获得奖励: -0.16095071965153285\n",
      "prey_2 获得奖励: -0.33929263843734664\n",
      "predator_0 获得奖励: -0.16358214971189775\n",
      "predator_1 获得奖励: -0.2499999925494193\n",
      "prey_0 获得奖励: -0.1187845756990511\n",
      "prey_1 获得奖励: -0.20824401947686869\n",
      "prey_2 获得奖励: -0.38912284030799016\n",
      "predator_0 获得奖励: -0.2377293715136932\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.164182233262003\n",
      "prey_1 获得奖励: -0.054385562975821915\n",
      "prey_2 获得奖励: -0.17583819632524877\n",
      "predator_0 获得奖励: -0.24999998509883836\n",
      "predator_1 获得奖励: -0.24999998509883836\n",
      "prey_0 获得奖励: -0.2499999925494193\n",
      "prey_1 获得奖励: -0.24002220895449883\n",
      "prey_2 获得奖励: -0.4999999701976767\n",
      "predator_0 获得奖励: -0.07549720393124626\n",
      "predator_1 获得奖励: -0.2499999776482572\n",
      "prey_0 获得奖励: -0.23704709487290307\n",
      "prey_1 获得奖励: -0.18039855004534622\n",
      "prey_2 获得奖励: -0.37489778397160317\n",
      "predator_0 获得奖励: -0.24999998509883836\n",
      "predator_1 获得奖励: -0.2494263250910689\n",
      "prey_0 获得奖励: -0.25000001490116075\n",
      "prey_1 获得奖励: -0.226635049845394\n",
      "prey_2 获得奖励: -0.10273124305679586\n",
      "predator_0 获得奖励: -0.05188155452054473\n",
      "predator_1 获得奖励: -0.21233133466409712\n",
      "prey_0 获得奖励: -0.1868674017723428\n",
      "prey_1 获得奖励: -0.21989978320213863\n",
      "prey_2 获得奖励: -0.3681462736410821\n",
      "predator_0 获得奖励: -0.16253621999853698\n",
      "predator_1 获得奖励: -0.24999997019767584\n",
      "prey_0 获得奖励: -0.2040564656059119\n",
      "prey_1 获得奖励: -0.13396169843150027\n",
      "prey_2 获得奖励: -0.4009847745133444\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.24999998509883836\n",
      "prey_0 获得奖励: -0.1618496641377419\n",
      "prey_1 获得奖励: -0.060261588789278675\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.17055267233263322\n",
      "predator_1 获得奖励: -0.162992387769015\n",
      "prey_0 获得奖励: -0.21184609901047624\n",
      "prey_1 获得奖励: -0.19275961442760006\n",
      "prey_2 获得奖励: -0.4999999850988386\n",
      "predator_0 获得奖励: -0.21737646691725102\n",
      "predator_1 获得奖励: -0.205946952895197\n",
      "prey_0 获得奖励: -0.09228392504319866\n",
      "prey_1 获得奖励: -0.22971008994154316\n",
      "prey_2 获得奖励: -0.045166863613931685\n",
      "predator_0 获得奖励: -0.21173473100770945\n",
      "predator_1 获得奖励: -0.2329593982265093\n",
      "prey_0 获得奖励: -0.11953686657344535\n",
      "prey_1 获得奖励: -0.2016895448269546\n",
      "prey_2 获得奖励: -0.5000000298023215\n",
      "predator_0 获得奖励: -0.19728513186856542\n",
      "predator_1 获得奖励: -0.060021016530491446\n",
      "prey_0 获得奖励: -0.18426925083456303\n",
      "prey_1 获得奖励: -0.05100557864376832\n",
      "prey_2 获得奖励: -0.2760815576604093\n",
      "predator_0 获得奖励: -0.10151533260335642\n",
      "predator_1 获得奖励: -0.1350430245848597\n",
      "prey_0 获得奖励: -0.15831440673399746\n",
      "prey_1 获得奖励: -0.12520706639333842\n",
      "prey_2 获得奖励: -0.30138942614203257\n",
      "predator_0 获得奖励: -0.2478243813666976\n",
      "predator_1 获得奖励: -0.20466281072212872\n",
      "prey_0 获得奖励: -0.2420111906581397\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.08778297401370315\n",
      "predator_1 获得奖励: -0.24999998509883836\n",
      "prey_0 获得奖励: -0.14478943291891888\n",
      "prey_1 获得奖励: -0.1924734144306786\n",
      "prey_2 获得奖励: -0.31991040182442504\n",
      "predator_0 获得奖励: -0.24999998509883836\n",
      "predator_1 获得奖励: -0.22065214395369676\n",
      "prey_0 获得奖励: -0.2500000298023206\n",
      "prey_1 获得奖励: -0.11682457356235317\n",
      "prey_2 获得奖励: -0.4214301766522019\n",
      "predator_0 获得奖励: -0.24722284576713016\n",
      "predator_1 获得奖励: -0.22360431706152079\n",
      "prey_0 获得奖励: -0.22561445510083078\n",
      "prey_1 获得奖励: -0.1940875550772237\n",
      "prey_2 获得奖励: -0.4193353504590783\n",
      "predator_0 获得奖励: -0.23678509220068492\n",
      "predator_1 获得奖励: -0.13686265864757194\n",
      "prey_0 获得奖励: -0.040650339087423035\n",
      "prey_1 获得奖励: -0.10592671589130079\n",
      "prey_2 获得奖励: -0.2924479369347221\n",
      "predator_0 获得奖励: -0.14309688152394776\n",
      "predator_1 获得奖励: -0.235286078305862\n",
      "prey_0 获得奖励: -0.08463355270191637\n",
      "prey_1 获得奖励: -0.051089132914033934\n",
      "prey_2 获得奖励: -0.32405003213763095\n",
      "predator_0 获得奖励: -0.047369229051402596\n",
      "predator_1 获得奖励: -0.25000001490116075\n",
      "prey_0 获得奖励: -0.24571878386362273\n",
      "prey_1 获得奖励: -0.20577103856673754\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.18021507144928892\n",
      "predator_1 获得奖励: -0.15824383929955332\n",
      "prey_0 获得奖励: -0.24999998509883836\n",
      "prey_1 获得奖励: -0.20248550840022772\n",
      "prey_2 获得奖励: -0.18645504001998053\n",
      "predator_0 获得奖励: -0.12893312347499242\n",
      "predator_1 获得奖励: -0.20163449546723222\n",
      "prey_0 获得奖励: -0.17668144937025165\n",
      "prey_1 获得奖励: -0.2472070835592982\n",
      "prey_2 获得奖励: -0.40372504000676845\n",
      "predator_0 获得奖励: -0.0279999631625757\n",
      "predator_1 获得奖励: -0.24371216370288934\n",
      "prey_0 获得奖励: -0.12736549893808732\n",
      "prey_1 获得奖励: -0.2499999925494193\n",
      "prey_2 获得奖励: -0.4999999701976767\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.04049410088574478\n",
      "prey_0 获得奖励: -0.23920503929608627\n",
      "prey_1 获得奖励: -0.10473469197166814\n",
      "prey_2 获得奖励: -0.5000000298023215\n",
      "predator_0 获得奖励: -0.16458917843322168\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.2075374819901616\n",
      "prey_1 获得奖励: -0.2302019870683067\n",
      "prey_2 获得奖励: -0.21308938643394248\n",
      "predator_0 获得奖励: -0.14826443270311326\n",
      "predator_1 获得奖励: -0.22642229115515886\n",
      "prey_0 获得奖励: -0.2499999776482572\n",
      "prey_1 获得奖励: -0.21975802726101792\n",
      "prey_2 获得奖励: -0.36683105861964366\n",
      "predator_0 获得奖励: -0.17088385928509225\n",
      "predator_1 获得奖励: -0.23991200286717532\n",
      "prey_0 获得奖励: -0.25000001490116075\n",
      "prey_1 获得奖励: -0.21959606109940377\n",
      "prey_2 获得奖励: -0.30341211564404247\n",
      "predator_0 获得奖励: -0.20440826005389134\n",
      "predator_1 获得奖励: -0.2444557216502718\n",
      "prey_0 获得奖励: -0.20925168740368086\n",
      "prey_1 获得奖励: -0.13516509242156277\n",
      "prey_2 获得奖励: -0.452422501819343\n",
      "predator_0 获得奖励: -0.1700576754775556\n",
      "predator_1 获得奖励: -0.16846930970488339\n",
      "prey_0 获得奖励: -0.18229365120670357\n",
      "prey_1 获得奖励: -0.12684786908157092\n",
      "prey_2 获得奖励: -0.4836860802779093\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.10479173772928295\n",
      "prey_0 获得奖励: -0.24999998509883836\n",
      "prey_1 获得奖励: -0.11786578892588383\n",
      "prey_2 获得奖励: -0.4999999850988386\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.14481839446730893\n",
      "prey_0 获得奖励: -0.18056191314504186\n",
      "prey_1 获得奖励: -0.17375632742811478\n",
      "prey_2 获得奖励: -0.32172122402268144\n",
      "predator_0 获得奖励: -0.1654663930208166\n",
      "predator_1 获得奖励: -0.19961592407830017\n",
      "prey_0 获得奖励: -0.0372623799743554\n",
      "prey_1 获得奖励: -0.20699012995768307\n",
      "prey_2 获得奖励: -0.4338484007722053\n",
      "predator_0 获得奖励: -0.1970860258554276\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.22657272710408305\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.21665340694024038\n",
      "predator_0 获得奖励: -0.10925623286704125\n",
      "predator_1 获得奖励: -0.19577138399441352\n",
      "prey_0 获得奖励: -0.12736621553211255\n",
      "prey_1 获得奖励: -0.22079096371177107\n",
      "prey_2 获得奖励: -0.3885058714645112\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.04873097530323405\n",
      "prey_0 获得奖励: -0.160236419988311\n",
      "prey_1 获得奖励: -0.10986972789923798\n",
      "prey_2 获得奖励: -0.4999999701976767\n",
      "predator_0 获得奖励: -0.20590017953047815\n",
      "predator_1 获得奖励: -0.16721455787354259\n",
      "prey_0 获得奖励: -0.15919140614628532\n",
      "prey_1 获得奖励: -0.17417326427489807\n",
      "prey_2 获得奖励: -0.3483764068861176\n",
      "predator_0 获得奖励: -0.17434539340199032\n",
      "predator_1 获得奖励: -0.25\n",
      "prey_0 获得奖励: -0.21805992441413885\n",
      "prey_1 获得奖励: -0.22266943373883374\n",
      "prey_2 获得奖励: -0.40604472476100567\n",
      "predator_0 获得奖励: -0.2499999925494193\n",
      "predator_1 获得奖励: -0.18884053441639378\n",
      "prey_0 获得奖励: -0.20914219752715515\n",
      "prey_1 获得奖励: -0.20174801369697293\n",
      "prey_2 获得奖励: -0.37917503183520296\n",
      "predator_0 获得奖励: -0.24612630144427106\n",
      "predator_1 获得奖励: -0.04556619844417875\n",
      "prey_0 获得奖励: -0.10192344332120996\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.3981288948946498\n",
      "predator_0 获得奖励: -0.24783470811945704\n",
      "predator_1 获得奖励: -0.06824614479521993\n",
      "prey_0 获得奖励: -0.150800616745105\n",
      "prey_1 获得奖励: -0.21198978038213412\n",
      "prey_2 获得奖励: -0.2962456356403127\n",
      "predator_0 获得奖励: -0.10610489262873617\n",
      "predator_1 获得奖励: -0.16132690992659784\n",
      "prey_0 获得奖励: -0.21946036426341267\n",
      "prey_1 获得奖励: -0.09003696190955135\n",
      "prey_2 获得奖励: -0.5000000298023215\n",
      "predator_0 获得奖励: -0.21805367165677692\n",
      "predator_1 获得奖励: -0.19367967913785597\n",
      "prey_0 获得奖励: -0.21546158818105499\n",
      "prey_1 获得奖励: -0.24999998509883836\n",
      "prey_2 获得奖励: -0.342445923493632\n",
      "predator_0 获得奖励: -0.160494586569561\n",
      "predator_1 获得奖励: -0.08187347520798877\n",
      "prey_0 获得奖励: -0.1985158863088426\n",
      "prey_1 获得奖励: -0.18318237724026346\n",
      "prey_2 获得奖励: -0.22943914896269338\n",
      "predator_0 获得奖励: -0.2499999776482572\n",
      "predator_1 获得奖励: -0.2063839979255036\n",
      "prey_0 获得奖励: -0.18559139119242385\n",
      "prey_1 获得奖励: -0.16086024147493233\n",
      "prey_2 获得奖励: -0.20858215235497612\n",
      "predator_0 获得奖励: -0.21725841743450588\n",
      "predator_1 获得奖励: -0.14582688595506893\n",
      "prey_0 获得奖励: -0.03210222577119794\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.41290374778313316\n",
      "predator_0 获得奖励: -0.22580233016817958\n",
      "predator_1 获得奖励: -0.19252293707075863\n",
      "prey_0 获得奖励: -0.1676125631092313\n",
      "prey_1 获得奖励: -0.25000001490116075\n",
      "prey_2 获得奖励: -0.28440035612644693\n",
      "predator_0 获得奖励: -0.25000001490116075\n",
      "predator_1 获得奖励: -0.15502554220623974\n",
      "prey_0 获得奖励: -0.23109646352602428\n",
      "prey_1 获得奖励: -0.12777199380794332\n",
      "prey_2 获得奖励: -0.4791114523077217\n",
      "predator_0 获得奖励: -0.2168836763526282\n",
      "predator_1 获得奖励: -0.12132151779145015\n",
      "prey_0 获得奖励: -0.20912181042874126\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.5\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.18690331207897717\n",
      "prey_0 获得奖励: -0.1504782012989644\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.32174289964742003\n",
      "predator_0 获得奖励: -0.15036985328203292\n",
      "predator_1 获得奖励: -0.06460987162370331\n",
      "prey_0 获得奖励: -0.1970850146039123\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.4928850196547462\n",
      "predator_0 获得奖励: -0.20000981366399226\n",
      "predator_1 获得奖励: -0.20804778238887212\n",
      "prey_0 获得奖励: -0.20251886088638982\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.2724213246634514\n",
      "predator_0 获得奖励: -0.19063109481948784\n",
      "predator_1 获得奖励: -0.23284546535516953\n",
      "prey_0 获得奖励: -0.23505682316593843\n",
      "prey_1 获得奖励: -0.25\n",
      "prey_2 获得奖励: -0.34802439838620763\n",
      "predator_0 获得奖励: -0.2112230822523408\n",
      "predator_1 获得奖励: -0.15164263489583676\n",
      "prey_0 获得奖励: -0.25\n",
      "prey_1 获得奖励: -0.24999998509883836\n",
      "prey_2 获得奖励: -0.25207942192468974\n",
      "predator_0 获得奖励: -0.25\n",
      "predator_1 获得奖励: -0.2020182904706332\n",
      "prey_0 获得奖励: -0.20288138269019546\n",
      "prey_1 获得奖励: -0.22069507347881803\n",
      "prey_2 获得奖励: -0.22614113495009538\n",
      "predator_0 获得奖励: -0.2093455144418061\n",
      "predator_1 获得奖励: -0.24999998509883836\n",
      "prey_0 获得奖励: -0.106307027392786\n",
      "prey_1 获得奖励: -0.08810264393026966\n",
      "prey_2 获得奖励: -0.35345341466999153\n",
      "predator_0 获得奖励: -0.09774607818539974\n",
      "predator_1 获得奖励: -0.1856595048880753\n",
      "prey_0 获得奖励: -0.10474768268063611\n",
      "prey_1 获得奖励: -0.23776465057385957\n",
      "prey_2 获得奖励: -0.2719943519033919\n",
      "predator_0 获得奖励: -0.1859222830628385\n",
      "predator_1 获得奖励: -0.11949226984206396\n",
      "prey_0 获得奖励: -0.1853897031366486\n",
      "prey_1 获得奖励: -0.24003486567553867\n",
      "prey_2 获得奖励: -0.3919355152866417\n",
      "predator_0 获得奖励: -0.06510437329577398\n",
      "predator_1 获得奖励: -0.12341851544157234\n",
      "prey_0 获得奖励: -0.22896381181723383\n",
      "prey_1 获得奖励: -0.23581785490465623\n",
      "prey_2 获得奖励: -0.3344621308612779\n",
      "predator_0 获得奖励: -0.226239590892765\n",
      "predator_1 获得奖励: -0.20465025999827194\n",
      "prey_0 获得奖励: -0.25000001490116075\n",
      "prey_1 获得奖励: -0.24702804565764286\n",
      "prey_2 获得奖励: -0.37332378715134706\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m             env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     43\u001b[0m     env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 44\u001b[0m \u001b[43mtest_predator_prey_collision\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m, in \u001b[0;36mtest_predator_prey_collision\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space(agent)\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m---> 41\u001b[0m         \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcingWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py:47\u001b[0m, in \u001b[0;36mBaseWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActionType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/clip_out_of_bounds.py:52\u001b[0m, in \u001b[0;36mClipOutOfBoundsWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     43\u001b[0m     EnvLogger\u001b[38;5;241m.\u001b[39mwarn_action_out_of_bound(\n\u001b[1;32m     44\u001b[0m         action\u001b[38;5;241m=\u001b[39maction, action_space\u001b[38;5;241m=\u001b[39mspace, backup_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclipping to space\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\n\u001b[1;32m     47\u001b[0m         action,  \u001b[38;5;66;03m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m         space\u001b[38;5;241m.\u001b[39mlow,  \u001b[38;5;66;03m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         space\u001b[38;5;241m.\u001b[39mhigh,  \u001b[38;5;66;03m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py:47\u001b[0m, in \u001b[0;36mBaseWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActionType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld.py:246\u001b[0m, in \u001b[0;36mraw_env.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_rewards()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld.py:216\u001b[0m, in \u001b[0;36mraw_env.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld_base.py:889\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m         gymnasium\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    888\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling render method without specifying any render mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 889\u001b[0m         )\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_predator_prey_collision():\n",
    "    \"\"\"测试新的碰撞逻辑\"\"\"\n",
    "    from pettingzoo.sisl import waterworld_v4\n",
    "    \n",
    "    agent_algos = [\"PPO\", \"PPO\", \"DQN\", \"DQN\", \"A2C\"]\n",
    "    \n",
    "    env = waterworld_v4.env(\n",
    "        render_mode=\"human\",\n",
    "        n_predators=2,\n",
    "        n_preys=3,\n",
    "        n_evaders=5,\n",
    "        n_obstacles=1,\n",
    "        n_poisons=1,\n",
    "        agent_algorithms=agent_algos,\n",
    "        predator_catch_reward=10.0,  # predator捕获prey奖励\n",
    "        same_algo_reward=3.0,        # 相同算法相遇奖励\n",
    "    )\n",
    "    \n",
    "    env.reset(seed=42)\n",
    "    \n",
    "    print(\"=== 碰撞逻辑测试 ===\")\n",
    "    print(\"Predators: predator_0 (PPO), predator_1 (PPO)\")  \n",
    "    print(\"Preys: prey_0 (DQN), prey_1 (DQN), prey_2 (A2C)\")\n",
    "    print(\"\\n预期效果：\")\n",
    "    print(\"- predator捕获prey: predator +10, prey reset to 0\")\n",
    "    print(\"- 相同算法相遇: 都 +3\")\n",
    "    print(\"- 不同算法相遇: 无额外奖励\")\n",
    "    \n",
    "    # 运行几步测试\n",
    "    for _ in range(50):\n",
    "        for agent in env.agent_iter():\n",
    "            observation, reward, termination, truncation, info = env.last()\n",
    "            \n",
    "            if reward != 0:\n",
    "                print(f\"{agent} 获得奖励: {reward}\")\n",
    "            \n",
    "            if termination or truncation:\n",
    "                action = None\n",
    "            else:\n",
    "                action = env.action_space(agent).sample()\n",
    "            env.step(action)\n",
    "    \n",
    "    env.close()\n",
    "test_predator_prey_collision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a107a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API test\n",
      "Finished test_observation\n",
      "Finished test_observation_action_spaces\n",
      "Finished play test\n",
      "Finished test_rewards_terminations_truncations\n",
      "Passed API test\n"
     ]
    }
   ],
   "source": [
    "api_test(env, num_cycles=1000, verbose_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "162c296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A2C': 0, 'DQN': 1, 'PPO': 2}\n"
     ]
    }
   ],
   "source": [
    "from pettingzoo.sisl import waterworld_v4\n",
    "agent_algos = [\"PPO\", \"PPO\", \"DQN\", \"DQN\", \"A2C\"]\n",
    "algo_name_to_id = {name: idx for idx, name in enumerate(sorted(set(agent_algos)))}\n",
    "print(algo_name_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08920543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API test\n",
      "Finished test_observation\n",
      "Finished test_observation_action_spaces\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[38;5;241m=\u001b[39m waterworld_v4\u001b[38;5;241m.\u001b[39menv(render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m,n_predators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,n_preys\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,n_evaders\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,n_obstacles\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,n_poisons\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,agent_algorithms\u001b[38;5;241m=\u001b[39magent_algos)\n\u001b[1;32m      2\u001b[0m env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mapi_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# for agent in env.agent_iter():\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     observation, reward, termination, truncation, info = env.last()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     print(reward)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     env.step(action)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# env.close()\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/test/api_test.py:625\u001b[0m, in \u001b[0;36mapi_test\u001b[0;34m(env, num_cycles, verbose_progress)\u001b[0m\n\u001b[1;32m    621\u001b[0m test_observation_action_spaces(env, agent_0)\n\u001b[1;32m    623\u001b[0m progress_report(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished test_observation_action_spaces\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 625\u001b[0m \u001b[43mplay_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_cycles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m progress_report(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished play test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env\u001b[38;5;241m.\u001b[39mrewards, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrewards must be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/test/api_test.py:478\u001b[0m, in \u001b[0;36mplay_test\u001b[0;34m(env, observation_0, num_cycles)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    474\u001b[0m     accumulated_rewards[agent] \u001b[38;5;241m==\u001b[39m reward\n\u001b[1;32m    475\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward returned by last is not the accumulated rewards in its rewards dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    476\u001b[0m accumulated_rewards[agent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 478\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, rew \u001b[38;5;129;01min\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    481\u001b[0m     accumulated_rewards[a] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rew\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcingWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py:47\u001b[0m, in \u001b[0;36mBaseWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActionType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/clip_out_of_bounds.py:52\u001b[0m, in \u001b[0;36mClipOutOfBoundsWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     43\u001b[0m     EnvLogger\u001b[38;5;241m.\u001b[39mwarn_action_out_of_bound(\n\u001b[1;32m     44\u001b[0m         action\u001b[38;5;241m=\u001b[39maction, action_space\u001b[38;5;241m=\u001b[39mspace, backup_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclipping to space\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\n\u001b[1;32m     47\u001b[0m         action,  \u001b[38;5;66;03m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m         space\u001b[38;5;241m.\u001b[39mlow,  \u001b[38;5;66;03m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         space\u001b[38;5;241m.\u001b[39mhigh,  \u001b[38;5;66;03m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/utils/wrappers/base.py:47\u001b[0m, in \u001b[0;36mBaseWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActionType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld.py:246\u001b[0m, in \u001b[0;36mraw_env.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_rewards()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld.py:216\u001b[0m, in \u001b[0;36mraw_env.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code4/rllib/env/PettingZoo/pettingzoo/sisl/waterworld/waterworld_base.py:791\u001b[0m, in \u001b[0;36mWaterworldBase.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen\u001b[38;5;241m.\u001b[39mfill((\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m))\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFPS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m observation \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen)\n\u001b[1;32m    794\u001b[0m new_observation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(observation)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "env = waterworld_v4.env(render_mode=\"human\",n_predators=2,n_preys=2,n_evaders=5,n_obstacles=1,n_poisons=1,agent_algorithms=agent_algos)\n",
    "env.reset(seed=42)\n",
    "api_test(env, num_cycles=1000, verbose_progress=True)\n",
    "# for agent in env.agent_iter():\n",
    "#     observation, reward, termination, truncation, info = env.last()\n",
    "#     print(reward)\n",
    "\n",
    "\n",
    "#     if termination or truncation:\n",
    "#         action = None\n",
    "#     else:\n",
    "#         # this is where you would insert your policy\n",
    "#         action = env.action_space(agent).sample()\n",
    "\n",
    "#     env.step(action)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68677f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"\"\"测试算法ID映射功能\"\"\"\n",
    "# from pettingzoo.sisl import waterworld_v4\n",
    "\n",
    "# # 定义算法列表\n",
    "# agent_algos = [\"PPO\", \"PPO\", \"DQN\", \"DQN\", \"A2C\"]\n",
    "\n",
    "# # 创建环境\n",
    "# env = waterworld_v4.env(\n",
    "#     render_mode=\"human\",\n",
    "#     n_predators=2,\n",
    "#     n_preys=3,\n",
    "#     n_evaders=5,\n",
    "#     n_obstacles=1,\n",
    "#     n_poisons=1,\n",
    "#     agent_algorithms=agent_algos\n",
    "# )\n",
    "\n",
    "# # 完整的测试示例：\n",
    "# def test_algorithm_mapping():\n",
    "#     # 重置环境\n",
    "#     env.reset(seed=42)\n",
    "    \n",
    "#     print(\"=== 算法映射信息 ===\")\n",
    "#     print(f\"原始算法列表: {agent_algos}\")\n",
    "#     print(f\"算法名称到ID映射: {env.env.algo_name_to_id}\")\n",
    "#     print(f\"每个agent的算法ID: {env.env.agent_algo_ids}\")\n",
    "    \n",
    "#     print(\"\\n=== 每个Agent的算法信息 ===\")\n",
    "#     for i in range(len(agent_algos)):\n",
    "#         algo_name = env.env.get_agent_algorithm(i)\n",
    "#         algo_id = env.env.get_agent_algorithm_id(i)\n",
    "#         print(f\"Agent {i}: 算法={algo_name}, ID={algo_id}\")\n",
    "    \n",
    "#     print(\"\\n=== 反向查找测试 ===\")\n",
    "#     for algo_id in env.env.algo_name_to_id.values():\n",
    "#         algo_name = env.env.get_algorithm_by_id(algo_id)\n",
    "#         print(f\"ID {algo_id} -> 算法 {algo_name}\")\n",
    "\n",
    "# # 运行测试\n",
    "# test_algorithm_mapping()\n",
    "\n",
    "# # # 如果想要在观测中验证算法ID\n",
    "# # def verify_algorithm_ids_in_observation():\n",
    "# #     env.reset(seed=42)\n",
    "    \n",
    "# #     for agent in env.agent_iter():\n",
    "# #         observation, reward, termination, truncation, info = env.last()\n",
    "# #         if observation is not None:\n",
    "# #             # 提取算法ID部分（观测向量的特定位置）\n",
    "# #             n_sensors = 30  # 默认传感器数量\n",
    "# #             algo_id_start = 9 * n_sensors  # 算法ID开始的位置\n",
    "# #             algo_id_end = 10 * n_sensors   # 算法ID结束的位置\n",
    "            \n",
    "# #             algo_ids_in_obs = observation[algo_id_start:algo_id_end]\n",
    "# #             detected_algo_ids = set(algo_ids_in_obs[algo_ids_in_obs >= 0])\n",
    "            \n",
    "# #             print(f\"\\n{agent} 观测到的算法IDs: {detected_algo_ids}\")\n",
    "            \n",
    "# #             # 将ID转换为算法名称\n",
    "# #             detected_algos = [env.env.get_algorithm_by_id(int(aid)) for aid in detected_algo_ids]\n",
    "# #             print(f\"{agent} 观测到的算法: {detected_algos}\")\n",
    "# #             break\n",
    "        \n",
    "# #         if termination or truncation:\n",
    "# #             action = None\n",
    "# #         else:\n",
    "# #             action = env.action_space(agent).sample()\n",
    "# #         env.step(action)\n",
    "\n",
    "# # # 验证观测中的算法ID\n",
    "# # verify_algorithm_ids_in_observation()\n",
    "\n",
    "# # env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43343be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 20:22:37,193\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-06-30 20:22:37,517\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数解析完成: n_predators=2, n_preys=3, total_agents=5, algo=PPO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbqr010817\u001b[0m (\u001b[33mbqr010817-kyushu-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 133\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m参数解析完成: n_predators=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mn_predators\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_preys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mn_preys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, total_agents=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_agents\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, algo=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39malgo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwandb_project\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 放在main训练逻辑之前\u001b[39;00m\n\u001b[1;32m    136\u001b[0m agent_algos \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDQN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDQN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA2C\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    138\u001b[0m register_env(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m _: PettingZooEnv(\n\u001b[1;32m    139\u001b[0m     waterworld_v4\u001b[38;5;241m.\u001b[39menv(\n\u001b[1;32m    140\u001b[0m         render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m ))\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1609\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_settings\u001b[38;5;241m.\u001b[39mx_server_side_derived_summary:\n\u001b[1;32m   1607\u001b[0m             init_telemetry\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mserver_side_derived_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1609\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_printer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wl:\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:874\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self, settings, config, run_printer)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m previous_run\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 874\u001b[0m service \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_service\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msending inform_init request\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    876\u001b[0m service\u001b[38;5;241m.\u001b[39minform_init(\n\u001b[1;32m    877\u001b[0m     settings\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mto_proto(),\n\u001b[1;32m    878\u001b[0m     run_id\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mrun_id,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    879\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/wandb_setup.py:336\u001b[0m, in \u001b[0;36m_WandbSetup.ensure_service\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m service_connection\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m \u001b[43mservice_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_service\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py:37\u001b[0m, in \u001b[0;36mconnect_to_service\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_start_and_connect_service\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py:72\u001b[0m, in \u001b[0;36m_start_and_connect_service\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Starts a service process and returns a connection to it.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03mAn atexit hook is registered to tear down the service process and wait for\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03mit to complete. The hook does not run in processes started using the\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mmultiprocessing module.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m proc \u001b[38;5;241m=\u001b[39m service\u001b[38;5;241m.\u001b[39m_Service(settings)\n\u001b[0;32m---> 72\u001b[0m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m port \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39msock_port\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m port\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/service/service.py:242\u001b[0m, in \u001b[0;36m_Service.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/service/service.py:234\u001b[0m, in \u001b[0;36m_Service._launch_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_startup_debug_print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_ports\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_ports\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_proc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    236\u001b[0m     _sentry\u001b[38;5;241m.\u001b[39mreraise(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/rllib/lib/python3.10/site-packages/wandb/sdk/service/service.py:110\u001b[0m, in \u001b[0;36m_Service._wait_for_ports\u001b[0;34m(self, fname, proc)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceStartProcessError(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe wandb service process exited with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproc\u001b[38;5;241m.\u001b[39mreturncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsure that `sys.executable` is a valid python interpreter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(fname):\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from ray.rllib.models.torch.torch_distributions import TorchDiagGaussian\n",
    "from ray.tune.result import TRAINING_ITERATION\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "from ray.rllib.core import (\n",
    "    COMPONENT_LEARNER,\n",
    "    COMPONENT_LEARNER_GROUP,\n",
    "    COMPONENT_RL_MODULE,\n",
    ")\n",
    "from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "from ray.rllib.examples.envs.classes.multi_agent import MultiAgentPendulum\n",
    "from ray.rllib.utils.metrics import (\n",
    "    ENV_RUNNER_RESULTS,\n",
    "    EPISODE_RETURN_MEAN,\n",
    "    NUM_ENV_STEPS_SAMPLED_LIFETIME,\n",
    ")\n",
    "from ray.rllib.utils.numpy import convert_to_numpy\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    check,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "\n",
    "from pettingzoo.sisl import waterworld_v4\n",
    "\n",
    "from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "from ray.rllib.core.rl_module.multi_rl_module import MultiRLModuleSpec\n",
    "from ray.rllib.core.rl_module.rl_module import RLModuleSpec\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import PettingZooEnv\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.tune.registry import get_trainable_cls, register_env\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tree  # pip install dm_tree\n",
    "\n",
    "from ray.rllib.core import DEFAULT_MODULE_ID\n",
    "from ray.rllib.core.columns import Columns\n",
    "from ray.rllib.core.rl_module.rl_module import RLModule\n",
    "from ray.rllib.utils.framework import try_import_torch\n",
    "from ray.rllib.utils.numpy import convert_to_numpy, softmax\n",
    "from ray.rllib.utils.metrics import (\n",
    "    ENV_RUNNER_RESULTS,\n",
    "    EPISODE_RETURN_MEAN,\n",
    ")\n",
    "\n",
    "torch, _ = try_import_torch()\n",
    "\n",
    "\n",
    "\n",
    "# 设置参数\n",
    "import sys\n",
    "sys.argv = [\n",
    "    'notebook_script.py',\n",
    "    '--enable-new-api-stack',\n",
    "    '--num-agents=5',\n",
    "    # 新增参数用于指定predator和prey的数量\n",
    "    '--n-predators=2',\n",
    "    '--wandb-key=fdd7656f474bba144dea1887bcdab534bc7df647',\n",
    "    '--wandb-project=waterworld-v4',\n",
    "    '--n-preys=3', \n",
    "    '--checkpoint-at-end',\n",
    "    '--stop-reward=200.0',\n",
    "    '--checkpoint-freq=1',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser = add_rllib_example_script_args(\n",
    "    default_iters=200,\n",
    "    default_timesteps=1000000,\n",
    "    default_reward=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 添加新的参数解析\n",
    "parser.add_argument(\n",
    "    \"--n-predators\",\n",
    "    type=int,\n",
    "    default=2,\n",
    "    help=\"Number of predator agents\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-preys\", \n",
    "    type=int,\n",
    "    default=3,\n",
    "    help=\"Number of prey agents\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--use-onnx-for-inference\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether to convert the loaded module to ONNX format and then perform \"\n",
    "    \"inference through this ONNX model.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--explore-during-inference\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Whether the trained policy should use exploration during action \"\n",
    "    \"inference.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num-episodes-during-inference\",\n",
    "    type=int,\n",
    "    default=10,\n",
    "    help=\"Number of episodes to do inference over (after restoring from a checkpoint).\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 验证参数\n",
    "assert args.n_predators > 0, \"Must set --n-predators > 0 when running this script!\"\n",
    "assert args.n_preys > 0, \"Must set --n-preys > 0 when running this script!\"\n",
    "assert (\n",
    "    args.enable_new_api_stack\n",
    "), \"Must set --enable-new-api-stack when running this script!\"\n",
    "\n",
    "# 计算总智能体数量\n",
    "total_agents = args.n_predators + args.n_preys\n",
    "print(f\"参数解析完成: n_predators={args.n_predators}, n_preys={args.n_preys}, total_agents={total_agents}, algo={args.algo}\")\n",
    "import wandb\n",
    "\n",
    "wandb.init(project=args.wandb_project, config=vars(args))  # 放在main训练逻辑之前\n",
    "\n",
    "\n",
    "agent_algos = [\"PPO\", \"PPO\", \"DQN\", \"DQN\", \"A2C\"]\n",
    "\n",
    "register_env(\"env\", lambda _: PettingZooEnv(\n",
    "    waterworld_v4.env(\n",
    "        render_mode=\"human\",\n",
    "        n_predators=2,\n",
    "        n_preys=3,\n",
    "        n_evaders=5,\n",
    "        n_obstacles=1,\n",
    "        n_poisons=1,\n",
    "        agent_algorithms=agent_algos\n",
    "    )\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 创建新的policies字典，匹配环境中的agent命名\n",
    "predator_policies = [f\"predator_{i}\" for i in range(args.n_predators)]\n",
    "prey_policies = [f\"prey_{i}\" for i in range(args.n_preys)]\n",
    "all_policies = predator_policies + prey_policies\n",
    "print(all_policies)\n",
    "\n",
    "\n",
    "\n",
    "# 创建RL module specs字典\n",
    "rl_module_specs = {p: RLModuleSpec() for p in all_policies}\n",
    "\n",
    "\n",
    "\n",
    "base_config = (\n",
    "    get_trainable_cls(args.algo)\n",
    "    .get_default_config()\n",
    "    .environment(\"env\")\n",
    "    .debugging(\n",
    "        log_level=\"DEBUG\",  # 设置为DEBUG级别\n",
    "        log_sys_usage=True,  # 记录系统使用情况\n",
    "        seed=1234  # 设置随机种子便于复现\n",
    "    )\n",
    "    .multi_agent(\n",
    "        # 在新API中，只需要指定policy_mapping_fn\n",
    "        policies=set(all_policies),\n",
    "        policy_mapping_fn=(lambda aid, *args, **kwargs: aid),\n",
    "    )\n",
    "    .training(\n",
    "        vf_loss_coeff=0.005,\n",
    "    )\n",
    "    .rl_module(\n",
    "        rl_module_spec=MultiRLModuleSpec(\n",
    "            rl_module_specs=rl_module_specs,\n",
    "        ),\n",
    "        model_config=DefaultModelConfig(vf_share_layers=True),\n",
    "    )\n",
    "    # .callbacks(WandbLoggingCallback)  # ✅ 加入回调\n",
    ")\n",
    "\n",
    "\n",
    "# 训练\n",
    "print(\"开始训练...\")\n",
    "results = run_rllib_example_script_experiment(base_config, args, keep_ray_up=True)\n",
    "print(\"训练完成\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
