"""
Stage 1.2: Predatorå¼•å¯¼è®­ç»ƒ
è®­ç»ƒæ‰€æœ‰ç®—æ³•çš„Predatorå¯¹æŠ—å›ºå®šçš„Preyæ± v1
"""

import argparse
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.trainer import MultiAgentTrainer
from src.utils.config_loader import get_training_config, get_env_config  # â† æ·»åŠ  get_env_config

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='Stage 1.2: Predatorå¼•å¯¼è®­ç»ƒ')
    
    parser.add_argument('--mode', type=str, default='prod',
                        choices=['debug', 'dryrun','test',  'prod'],
                        help='è¿è¡Œæ¨¡å¼')
    
    parser.add_argument('--algos', type=str, nargs='+',
                        default=['PPO', 'A2C', 'SAC', 'TD3'],
                        help='è¦è®­ç»ƒçš„ç®—æ³•åˆ—è¡¨')
    
    parser.add_argument('--prey-pool', type=str, default='outputs/fixed_pools/prey_pool_v1',
                        help='Preyå›ºå®šæ± è·¯å¾„')
    
    parser.add_argument('--device', type=str, default='auto',
                        help='è®¡ç®—è®¾å¤‡')
    
    parser.add_argument('--timesteps', type=int, default=None,
                        help='æ€»è®­ç»ƒæ­¥æ•°ï¼ˆè¦†ç›–é…ç½®ï¼‰')
    
    return parser.parse_args()


def train_one_predator_algo(algo: str, args, stage_config: dict):
    """è®­ç»ƒå•ä¸ªPredatorç®—æ³•"""
    
    print(f"\n{'='*70}")
    print(f"{'è®°å½•' if algo == 'RANDOM' else 'è®­ç»ƒ'} {algo}_predator vs prey_pool_v1")
    print(f"{'='*70}\n")
    
    # æ„å»ºå¯¹æ‰‹é…ç½®
    opponent_config = {
        'type': 'mixed_pool',
        'side': 'prey',
        'pool_path': args.prey_pool,
        'mix_strategy': {
            'fixed_ratio': 0.7,
            'sampling': 'uniform'
        },
        'freeze': True
    }
    
    # âœ… æ·»åŠ è¿™æ®µï¼šç¡®å®šè®­ç»ƒæ­¥æ•°
    if algo == 'RANDOM':
        # RANDOM åªéœ€è¦è¿è¡Œè¶³å¤Ÿçš„ episodes æ¥è®°å½•åŸºçº¿
        timesteps = 50000  # å¤§çº¦ 50 ä¸ª episodes
    else:
        # æ­£å¸¸ç®—æ³•çš„è®­ç»ƒæ­¥æ•°
        timesteps = args.timesteps
    # âœ… æ ¹æ®æ¨¡å¼é€‰æ‹©ç¯å¢ƒé…ç½®
    if args.mode == 'test':
        env_config_name = 'waterworld_fast'
        print(f"ğŸƒ æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨å¿«é€Ÿç¯å¢ƒ: max_cycles=500")
    else:
        env_config_name = 'waterworld_standard'
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MultiAgentTrainer(
        train_side='predator',
        train_algo=algo,
        opponent_config=opponent_config,
        experiment_name=f"{algo}_predator_guided",
        env_config=get_env_config(env_config_name),  # âœ… ä½¿ç”¨åŠ¨æ€ç¯å¢ƒ
        stage_name=stage_config['stage']['name'],
        generation=stage_config['stage']['generation'],
        version='v1',
        run_mode=args.mode,
        total_timesteps=timesteps,  # âœ… ä½¿ç”¨ timesteps è€Œä¸æ˜¯ args.timesteps
        device=args.device
    )
    
    # è·å–å†»ç»“æ¡ä»¶
    freeze_config = stage_config.get('freeze_on_success', {})
    freeze_criteria = freeze_config.get('criteria', {})
    
    # è¿è¡Œè®­ç»ƒ
    # RANDOM ä¸éœ€è¦ä¿å­˜åˆ°æ± 
    save_to_pool = freeze_config.get('enabled', False) if algo != 'RANDOM' else False
    
    eval_results = trainer.run(
        save_to_pool=save_to_pool,
        pool_name=freeze_config.get('save_to_pool'),
        check_freeze=freeze_config.get('enabled', False) if algo != 'RANDOM' else False,
        freeze_criteria=freeze_criteria
    )
    
    return eval_results

def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # æ£€æŸ¥prey_poolæ˜¯å¦å­˜åœ¨
    prey_pool_path = Path(args.prey_pool)
    if not prey_pool_path.exists():
        print(f"âŒ Preyå›ºå®šæ± ä¸å­˜åœ¨: {prey_pool_path}")
        print(f"è¯·å…ˆè¿è¡Œ Stage 1.1 è®­ç»ƒ")
        sys.exit(1)
    
    # åŠ è½½Stage 1.2é…ç½®
    stage_config = get_training_config('stage1_2_pred_guided')
    
    # è·å–ç®—æ³•åˆ—è¡¨
    algos_to_train = args.algos or stage_config.get('algorithms_to_train', ['PPO', 'A2C', 'SAC', 'TD3'])
    
    print(f"\n{'='*70}")
    print(f"ğŸ¯ Stage 1.2: Predatorå¼•å¯¼è®­ç»ƒ")
    print(f"{'='*70}")
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"è®­ç»ƒç®—æ³•: {', '.join(algos_to_train)}")
    print(f"Preyæ± è·¯å¾„: {args.prey_pool}")
    print(f"{'='*70}\n")
    
    # ========== æ–°å¢ï¼šå…ˆè¿è¡Œ RANDOM ä½œä¸ºåŸºçº¿ ==========
    print(f"\n{'='*70}")
    print(f"æ­¥éª¤ 0: è®°å½• RANDOM Baseline")
    print(f"{'='*70}\n")
    
    # å°† RANDOM æ·»åŠ åˆ°è®­ç»ƒåˆ—è¡¨çš„æœ€å‰é¢
    all_algos = ['RANDOM'] + algos_to_train
    
    # ========== è®­ç»ƒæ‰€æœ‰ç®—æ³•ï¼ˆåŒ…æ‹¬ RANDOMï¼‰==========
    results = {}
    for algo in all_algos:
        try:
            eval_results = train_one_predator_algo(algo, args, stage_config)
            results[algo] = eval_results
        except KeyboardInterrupt:
            print(f"\nâš ï¸  {algo} è®­ç»ƒè¢«ä¸­æ–­")
            break
        except Exception as e:
            print(f"\nâŒ {algo} è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ========== æ‰“å°æ±‡æ€»ï¼ˆçªå‡ºæ˜¾ç¤ºä¸ RANDOM çš„å¯¹æ¯”ï¼‰==========
    print(f"\n{'='*70}")
    print(f"âœ… Stage 1.2 å®Œæˆ")
    print(f"{'='*70}")
    
    # æ˜¾ç¤º RANDOM åŸºçº¿
    if 'RANDOM' in results and results['RANDOM']:
        baseline_reward = results['RANDOM'].get('mean_reward', 0)
        print(f"\nğŸ“Š Random Baseline: {baseline_reward:.2f}")
        
        print(f"\nè®­ç»ƒç»“æœï¼ˆç›¸å¯¹äº Randomï¼‰:")
        for algo in algos_to_train:  # åªæ˜¾ç¤ºè®­ç»ƒçš„ç®—æ³•
            if algo in results and results[algo]:
                reward = results[algo].get('mean_reward', 0)
                improvement = ((reward - baseline_reward) / abs(baseline_reward) * 100) if baseline_reward != 0 else 0
                status = "âœ…" if improvement > 0 else "âŒ"
                print(f"  {status} {algo}: {reward:.2f} ({improvement:+.1f}% vs Random)")
    else:
        print(f"\nè®­ç»ƒç»“æœ:")
        for algo, result in results.items():
            if result:
                reward = result.get('mean_reward', 0)
                if isinstance(reward, (int, float)):
                    print(f"  {algo}: å¹³å‡å¥–åŠ± = {reward:.2f}")
                else:
                    print(f"  {algo}: å¹³å‡å¥–åŠ± = {reward}")
    
    print(f"{'='*70}\n")


if __name__ == "__main__":
    main()